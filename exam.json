{
  "Exam1": {
    "id": 1,
    "quesNum": 75,
    "Question1": {
      "Question": "A company is developing a serverless application that consists of various AWS Lambda functions behind Amazon API Gateway APIs. A developer needs to automate the deployment of Lambda function code. The developer will deploy updated Lambda functions with AWS CodeDeploy. The deployment must minimize the exposure of potential errors to end users. When the application is in production, the application cannot experience downtime outside the specified maintenance window. <br>Which deployment configuration will meet these requirements with the LEAST deployment time?",
      "Option1": "Use the AWS CodeDeploy in-place deployment configuration for the Lambda functions. Shift all traffic immediately after deployment.",
      "Option2": "Use the AWS CodeDeploy linear deployment configuration to shift 10% of the traffic every minute.",
      "Option3": "Use the AWS CodeDeploy all-at-once deployment configuration to shift all traffic to the updated versions immediately.",
      "Option4": "Use the AWS CodeDeploy predefined canary deployment configuration to shift 10% of the traffic immediately and shift the remaining traffic after 5 minutes.",
      "Correct Answer": 4
    },
    "Question2": {
      "Question": "A developer needs to store configuration variables for an application. The developer needs to set an expiration date and time for the configuration. The developer wants to receive notifications before the configuration expires. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a standard parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.",
      "Option2": "Create a standard parameter in AWS Systems Manager Parameter Store. Create an AWS Lambda function to expire the configuration and to send Amazon Simple Notification Service (Amazon SNS) notifications.",
      "Option3": "Create an advanced parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.",
      "Option4": "Create an advanced parameter in AWS Systems Manager Parameter Store. Create an Amazon EC2 instance with a cron job to expire the configuration and to send notifications.",
      "Correct Answer": 3
    },
    "Question3": {
      "Question": "A developer creates an AWS Lambda function that retrieves and groups data from several public API endpoints. The Lambda function has been updated and configured to connect to the private subnet of a VPC. An internet gateway is attached to the VPC. The VPC uses the default network ACL and security group configurations. <br>The developer finds that the Lambda function can no longer access the public API. The developer has ensured that the public API is accessible, but the Lambda function cannot connect to the API. <br>How should the developer fix the connection issue?",
      "Option1": "Ensure that the network ACL allows outbound traffic to the public internet.",
      "Option2": "Ensure that the security group allows outbound traffic to the public internet.",
      "Option3": "Ensure that outbound traffic from the private subnet is routed to a public NAT gateway.",
      "Option4": "Ensure that outbound traffic from the private subnet is routed to a new internet gateway.",
      "Correct Answer": 3
    },
    "Question4": {
      "Question": "A company is developing an ecommerce application that uses Amazon API Gateway APIs. The application uses AWS Lambda as a backend. The company needs to test the code in a dedicated, monitored test environment before the company releases the code to the production environment. <br>Which solution will meet these requirements?",
      "Option1": "Use a single stage in API Gateway. Create a Lambda function for each environment. Configure API clients to send a query parameter that indicates the environment and the specific Lambda function.",
      "Option2": "Use multiple stages in API Gateway. Create a single Lambda function for all environments. Add different code blocks for different environments in the Lambda function based on Lambda environment variables.",
      "Option3": "Use multiple stages in API Gateway. Create a Lambda function for each environment. Configure API Gateway stage variables to route traffic to the Lambda function in different environments.",
      "Option4": "Use a single stage in API Gateway. Configure API clients to send a query parameter that indicates the environment. Add different code blocks for different environments in the Lambda function to match the value of the query parameter.",
      "Correct Answer": 3
    },
    "Question5": {
      "Question": "A developer is working on a web application that uses Amazon DynamoDB as its data store. The application has two DynamoDB tables: one table that is named artists and one table that is named songs. The artists table has artistName as the partition key. The songs table has songName as the partition key and artistName as the sort key. <br>The table usage patterns include the retrieval of multiple songs and artists in a single database operation from the webpage. The developer needs a way to retrieve this information with minimal network traffic and optimal application performance. <br>Which solution will meet these requirements?",
      "Option1": "Perform a BatchGetItem operation that returns items from the two tables. Use the list of songName/artistName keys for the songs table and the list of artistName key for the artists table.",
      "Option2": "Create a local secondary index (LSI) on the songs table that uses artistName as the partition key. Perform a query operation for each artistName on the songs table that filters by the list of songName. Perform a query operation for each artistName on the artists table.",
      "Option3": "Perform a BatchGetitem operation on the songs table that uses the songName/artistName keys. Perform a BatchGetItem operation on the artists table that uses artistName as the key.",
      "Option4": "Perform a Scan operation on each table that filters by the list of songName/artistName for the songs table and the list of artistName in the artists table.",
      "Correct Answer": 1
    },
    "Question6": {
      "Question": "A developer is creating an AWS Lambda function. The Lambda function will consume messages from an Amazon Simple Queue Service (Amazon SQS) queue. The developer wants to integrate unit testing as part of the function's continuous integration and continuous delivery (CI/CD) process. <br>How can the developer unit test the function?",
      "Option1": "Create an AWS CloudFormation template that creates an SQS queue and deploys the Lambda function. Create a stack from the template during the CI/CD process. Invoke the deployed function. Verify the output.",
      "Option2": "Create an SQS event for tests. Use a test that consumes messages from the SQS queue during the function's CI/CD process.",
      "Option3": "Create an SQS queue for tests. Use this SQS queue in the application's unit test. Run the unit tests during the CI/CD process.",
      "Option4": "Use the aws lambda invoke command with a test event during the CIICD process.",
      "Correct Answer": 2
    },
    "Question7": {
      "Question": "A company has a front-end application that runs on four Amazon EC2 instances behind an Elastic Load Balancer (ELB) in a production environment that is provisioned by AWS Elastic Beanstalk. A developer needs to deploy and test new application code while updating the Elastic Beanstalk platform from the current version to a newer version of Node.js. The solution must result in zero downtime for the application. <br>Which solution meets these requirements?",
      "Option1": "Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.",
      "Option2": "Deploy the new application code in an all-at-once deployment to the existing EC2 instances. Test the code. Redeploy the previous code if verification fails.",
      "Option3": "Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks.",
      "Option4": "Use a rolling deployment for the new application code. Apply the code to a subset of EC2 instances until the tests pass. Redeploy the previous code if the tests fail.",
      "Correct Answer": 3
    },
    "Question8": {
      "Question": " A developer is creating an AWS Lambda function. The Lambda function needs an external library to connect to a third-party solution. The external library is a collection of files with a total size of 100 MB. The developer needs to make the external library available to the Lambda execution environment and reduce the Lambda package space. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a Lambda layer to store the external library. Configure the Lambda function to use the layer.",
      "Option2": "Create an Amazon S3 bucket. Upload the external library into the S3 bucket. Mount the S3 bucket folder in the Lambda function. Import the library by using the proper folder in the mount point.",
      "Option3": "Load the external library to the Lambda function's /tmp directory during deployment of the Lambda package. Import the library from the /tmp directory.",
      "Option4": "Create an Amazon Elastic File System (Amazon EFS) volume. Upload the external library to the EFS volume. Mount the EFS volume in the Lambda function. Import the library by using the proper folder in the mount point.",
      "Correct Answer": 1
    },
    "Question9": {
      "Question": "A developer is integrating Amazon ElastiCache in an application. The cache will store data from a database. The cached data must populate real-time dashboards. <br>Which caching strategy will meet these requirements?",
      "Option1": "A read-through cache",
      "Option2": "A write-behind cache",
      "Option3": "A lazy-loading cache",
      "Option4": "A write-through cache",
      "Correct Answer": 4
    },
    "Question10": {
      "Question": "A Developer is creating an AWS Serverless Application Model (AWS SAM) template. The AWS SAM template contains the definition of multiple AWS Lambda function, an Amazon S3 bucket, and an Amazon CloudFront distribution. One of the Lambda functions run on Lambda@Edge in the CloudFront distribution. The S3 bucket is configured as an origin for the CloudFront distribution. When the developer deploys the AWS SAM template in the eu-west-1 Region, the creation of the stack fails. <br>Which of the following could be the reason for this issue?",
      "Option1": "CloudFront distributions can be created only in the us-east-1 Region.",
      "Option2": "Lambda@Edge functions can be created only in the us-east-1 Region.",
      "Option3": "A single AWS SAM template cannot contain multiple Lambda functions.",
      "Option4": "The CloudFront distribution and the S3 bucket cannot be created in the same Region.",
      "Correct Answer": 2
    },
    "Question11": {
      "Question": "An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. <br>What AWS service should be used to accomplish this?",
      "Option1": "Amazon DynamoDB",
      "Option2": "Amazon EC2",
      "Option3": "AWS Lambda",
      "Option4": "Amazon RDS",
      "Correct Answer": 1
    },
    "Question12": {
      "Question": "A company must deploy all its Amazon RDS DB instances by using AWS CloudFormation templates as part of AWS CodePipeline continuous integration and continuous delivery (CI/CD) automation. The primary password for the DB instance must be automatically generated as part of the deployment process. <br>Which solution will meet these requirements with the LEAST development effort?",
      "Option1": "Create am AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get the value of the secure string. Use the value to create the DB instance.",
      "Option2": "Use the AWS CodeBuild action of  CodePipeline to generate a secure string by using the following AWS CLI command: aws secretsmanager get-random-password. Pass the generated secure string as a CloudFormation parameter with the NoEcho attribute set to true. Use the parameter reference to create the DB instance.",
      "Option3": "Create an AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get a value of the secure string. Create secrets in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored In the secret to create the DB instance.",
      "Option4": "Use the AWS::SecretsManager::Secret resource to generate a secure string. Store the secure string as a secret in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored in the secret to create the DB instance.",
      "Correct Answer": 4
    },
    "Question13": {
      "Question": "A developer is developing an application that uses signed requests (Signature Version 4) to call other AWS services. The developer has created a canonical request, has created the string to sign, and has calculated signing information. <br>Which methods could the developer use to complete a signed request? (Choose two.)",
      "Option1": "Add the signature to an HTTP header that is named Authorization.",
      "Option2": "Add the signature to a session cookie.",
      "Option3": "Add the signature to an HTTP header that is named Authentication.",
      "Option4": "Add the signature to a query string parameter that is named X-Amz-Signature.",
      "Option5": "Add the signature to an HTTP header that is named WWW-Authenticate.",
      "Correct Answer": 1
    },
    "Question14": {
      "Question": "A company's developer is building a static website to be deployed in Amazon S3 for a production environment. The website integrates with an Amazon Aurora PostgreSQL database by using an AWS Lambda function. The website that is deployed to production will use a Lambda alias that points to a specific version of the Lambda function. <br>The company must rotate the database credentials every 2 weeks. Lambda functions that the company deployed previously must be able to use the most recent credentials. <br>Which solution will meet these requirements?",
      "Option1": "Store the database credentials in AWS Secrets Manager. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Secrets Manager.",
      "Option2": "Include the database credentials as part of the Lambda function code. Update the credentials periodically and deploy the new Lambda function.",
      "Option3": "Use Lambda environment variables. Update the environment variables when new credentials are available.",
      "Option4": "Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Systems Manager Parameter Store.",
      "Correct Answer": 3
    },
    "Question15": {
      "Question": "A developer has written code for an application and wants to share it with other developers on the team to receive feedback. The shared application code needs to be stored long-term with multiple versions and batch change tracking. <br>Which AWS service should the developer use?",
      "Option1": "AWS CodeBuild",
      "Option2": "Amazon S3",
      "Option3": "AWS CodeCommit",
      "Option4": "AWS Cloud9",
      "Correct Answer": 3
    },
    "Question16": {
      "Question": "A developer is writing an application for a company. The application will be deployed on Amazon EC2 and will use an Amazon RDS for Microsoft SQL Server database. The company's security team requires that database credentials are rotated at least weekly. <br>How should the developer configure the database credentials for this application?",
      "Option1": "Create a database user. Store the user name and password in an AWS Systems Manager Parameter. Store secure string parameter. Enable rotation of the AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter.",
      "Option2": "Enable IAM authentication for the database. Create a database user for use with IAM authentication. Enable password rotation.",
      "Option3": "Create a database user. Store the user name and password in an AWS Secrets Manager secret that has daily rotation enabled.",
      "Option4": "Use the EC2 user data to create a database user. Provide the user name and password in environment variables to the application.",
      "Correct Answer": 3
    },
    "Question17": {
      "Question": "A developer maintains a critical business application that uses Amazon DynamoDB as the primary data store. The DynamoDB table contains millions of documents and receives 30-60 requests each minute. The developer needs to perform processing in near-real time on the documents when they are added or updated in the DynamoDB table. <br>How can the developer implement this feature with the LEAST amount of change to the existing application code?",
      "Option1": "Set up a cron job on an Amazon EC2 instance. Run a script every hour to query the table for changes and process the documents.",
      "Option2": "Enable a DynamoDB stream on the table. Invoke an AWS Lambda function to process the documents.",
      "Option3": "Update the application to send a PutEvents request to Amazon EventBridge. Create an EventBridge rule to invoke an AWS Lambda function to process the documents.",
      "Option4": "Update the application to synchronously process the documents directly after the DynamoDB write.",
      "Correct Answer": 2
    },
    "Question18": {
      "Question": "A company has hundreds of AWS Lambda functions that the company's QA team needs to test by using the Lambda function URLs. A developer needs to configure the authentication of the Lambda functions to allow access so that the QA IAM group can invoke the Lambda functions by using the public URLs. <br>Which solution will meet these requirements?",
      "Option1": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group.",
      "Option2": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group.",
      "Option3": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to loop on the Lambda functions to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group's Amazon Resource Name (ARN).",
      "Option4": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to loop on the Lambda functions to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group's Amazon Resource Name (ARN).",
      "Correct Answer": 1
    },
    "Question19": {
      "Question": "A developer needs to build an AWS CloudFormation template that self-populates the AWS Region variable that deploys the CloudFormation template. <br>What is the MOST operationally efficient way to determine the Region in which the template is being deployed?",
      "Option1": "Use the AWS::Region pseudo parameter.",
      "Option2": "Require the Region as a CloudFormation parameter.",
      "Option3": "Find the Region from the AWS::Stackld pseudo parameter by using the Fn::Split intrinsic function.",
      "Option4": "Dynamically import the Region by referencing the relevant parameter in AWS Systems Manager Parameter Store.",
      "Correct Answer": 1
    },
    "Question20": {
      "Question": " A developer is working on an ecommerce website. The developer wants to review server logs without logging in to each of the application servers individually. The website runs on multiple Amazon EC2 instances, is written in Python, and needs to be highly available. <br>How can the developer update the application to meet these requirements with MINIMUM changes?",
      "Option1": "Rewrite the application to be cloud native and to run on AWS Lambda, where the logs can be reviewed in Amazon CloudWatch.",
      "Option2": "Set up centralized logging by using Amazon OpenSearch Service, Logstash, and OpenSearch Dashboards.",
      "Option3": "Scale down the application to one larger EC2 instance where only one instance is recording logs.",
      "Option4": "Install the unified Amazon CloudWatch agent on the EC2 instances. Configure the agent to push the application logs to CloudWatch.",
      "Correct Answer": 4
    },
    "Question21": {
      "Question": "A Company has an image storage web application that runs on AWS. The company hosts the application on Amazon EC2 instances in an Auto Scaling group. The Auto Scaling group acts as the target group for an Application Load Balancer (ALB) and uses an Amazon S3 bucket to store the images for sale. The company wants to develop a feature to test system requests. The feature will direct requests to a separate target group that hosts a new beta version of the application. <br>Which solution will meet this requirement with the LEAST effort?",
      "Option1": "Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Update the test system code to use this cookie to test the beta version of the application.",
      "Option2": "Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Configure an alternate Amazon Route S3 record for the new ALB endpoint. Use the alternate Route S3 endpoint in the test system requests to test the beta version of the application.",
      "Option3": "Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Use Amazon CloudFront with Lambda@Edge to determine which specific request will go to the new ALB. Use the CloudFront endpoint to send the test system requests to test the beta version of the application.",
      "Option4": "Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Use Amazon CloudFront with Lambda@Edge to update the test system requests to add the required cookie when the requests go to the ALB.",
      "Correct Answer": 1
    },
    "Question22": {
      "Question": "A company is providing read access to objects in an Amazon S3 bucket for different customers. The company uses IAM permissions to restrict access to the S3 bucket. The customers can access only their own files. <br>Due to a regulation requirement, the company needs to enforce encryption in transit for interactions with Amazon S3. <br>Which solution will meet these requirements?",
      "Option1": "Add a bucket policy to the S3 bucket to deny S3 actions when the aws::SecureTransport condition is equal to false.",
      "Option2": "Add a bucket policy to the S3 bucket to deny S3 actions when the s3:x-amz-acl condition is equal to public-read.",
      "Option3": "Add an IAM policy to the IAM users to enforce the usage of the AWS SDK.",
      "Option4": "Add an IAM policy to the IAM users that allows S3 when the s3:x-amz-acl condition is equal to bucket-owner-read.",
      "Correct Answer": 1
    },
    "Question23": {
      "Question": "A developer wants to use AWS Elastic Beanstalk to test a new version of an application in a test environment. <br>Which deployment method offers the FASTEST deployment?",
      "Option1": "Immutable",
      "Option2": "Rolling",
      "Option3": "Rolling with additional batch",
      "Option4": "All at once",
      "Correct Answer": 4
    },
    "Question24": {
      "Question": "A developer is updating several AWS Lambda functions and notices that all the Lambda functions share the same custom libraries. The developer wants to centralize all the libraries, update the libraries in a convenient way, and keep the libraries versioned. <br>Which solution will meet these requirements with the LEAST development effort?",
      "Option1": "Create an AWS CodeArtifact repository that contains all the custom libraries.",
      "Option2": "Create a custom container image for the Lambda functions to save all the custom libraries.",
      "Option3": "Create a Lambda layer that contains all the custom libraries.",
      "Option4": "Create an Amazon Elastic File System (Amazon EFS) file system to store all the custom libraries.",
      "Correct Answer": 3
    },
    "Question25": {
      "Question": "A company has a web application that runs on Amazon EC2 instances with a custom Amazon Machine Image (AMI). The company uses AWS CloudFormation to provision the application. The application runs in the us-east-1 Region, and the company needs to deploy the application to the us-west-1 Region. <br>An attempt to create the AWS CloudFormation stack in us-west-1 fails. An error message states that the AMI ID does not exist. A developer must resolve this error with a solution that uses the least amount of operational overhead. <br>Which solution meets these requirements?",
      "Option1": "Change the AWS CloudFormation templates for us-east-1 and us-west-1 to use an AWS AMI. Relaunch the stack for both Regions.",
      "Option2": "Copy the custom AMI from us-east-1 to us-west-1. Update the AWS CloudFormation template for us-west-1 to refer to AMI ID for the copied AMI. Relaunch the stack.",
      "Option3": "Build the custom AMI in us-west-1. Create a new AWS CloudFormation template to launch the stack in us-west-1 with the new AMI ID.",
      "Option4": "Manually deploy the application outside AWS CloudFormation in us-west-1.",
      "Correct Answer": 2
    },
    "Question26": {
      "Question": "A company is updating an application to move the backend of the application from Amazon EC2 instances to a serverless model. The application uses an Amazon RDS for MySQL DB instance and runs in a single VPC on AWS. The application and the DB instance are deployed in a private subnet in the VPC. <br>The company needs to connect AWS Lambda functions to the DB instance. <br>Which solution will meet these requirements?",
      "Option1": "Create Lambda functions inside the VPC with the ASLambdaBasicExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group.",
      "Option2": "Create Lambda functions inside the VPC with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group-",
      "Option3": "Create Lambda functions with the AWSLambdaBasicExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunclion action for each Lambda function's Amazon Resource Name (ARN).",
      "Option4": "Create Lambda functions with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunction action for each Lambda function's Amazon Resource Name (ARN).",
      "Correct Answer": 2
    },
    "Question27": {
      "Question": "A company stores its data in data tables in a series of Amazon S3 buckets. The company received an alert that customer credit card information might have been exposed in a data table on one of the company's public applications. A developer needs to identify all potential exposures within the application environment <br>Which solution will meet these requirements?",
      "Option1": "Use Amazon Athena to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Personal finding type.",
      "Option2": "Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.",
      "Option3": "Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S30bject/Personal finding type.",
      "Option4": "Use Amazon Athena to run a job on the 53 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.",
      "Correct Answer": 2
    },
    "Question28": {
      "Question": "An ecommerce website uses an AWS Lambda function and an Amazon RDS for MySQL database for an order fulfillment service. The service needs to return order confirmation immediately. During a marketing campaign that caused an increase in the number of orders, the website's operations team noticed errors for 'too many connections' from Amazon RDS. However, the RDS DB cluster metrics are healthy. CPU and memory capacity are still available. <br>What should a developer do to resolve the errors?",
      "Option1": "Initialize the database connection outside the handler function. Increase the max_user_connections value on the parameter group of the DB cluster. Restart the DB cluster.",
      "Option2": "Initialize the database connection outside the handler function. Use RDS Proxy instead of connecting directly to the DB cluster.",
      "Option3": "Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function's concurrency to a value that equals the number of available database connections.",
      "Option4": "Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function's concurrency to a value that is less than the number of available database connections.",
      "Correct Answer": 2
    },
    "Question29": {
      "Question": "A social media application uses the AWS SDK for JavaScript on the frontend to get user credentials from AWS Security Token Service (AWS STS). The application stores its assets in an Amazon S3 bucket. The application serves its content by using an Amazon CloudFront distribution with the origin set to the S3 bucket. <br>The credentials for the role that the application assumes to make the SDK calls are stored in plaintext in a JSON file within the application code. The developer needs to implement a solution that will allow the application to get user credentials without having any credentials hardcoded in the application code. <br>Which solution will meet these requirements?",
      "Option1": "Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Add permissions to the function's execution role to allow the function to access AS STS. Move all SDK calls from the frontend into the function.",
      "Option2": "Add a CloudFront function to the distribution. Invoke the function on viewer request. Add permissions to the function's execution role to allow the function to access AWS STS. Move all SDK calls from the frontend into the function.",
      "Option3": "Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Move the credentials from the JSON file into the function. Move all SDK calls from the frontend into the function.",
      "Option4": "Add a CloudFront function to the distribution. Invoke the function on viewer request. Move the credentials Trom the JSON Tire into the function. Move all SDK calls from the frontend into the function.",
      "Correct Answer": 1
    },
    "Question30": {
      "Question": "A developer is creating an application. New users of the application must be able to create an account and register by using their own social media accounts. <br>Which AWS service or resource should the developer use to meet these requirements?",
      "Option1": "IAM role",
      "Option2": "Amazon Cognito identity pools",
      "Option3": "Amazon Cognito user pools",
      "Option4": "AWS Directory Service",
      "Correct Answer": 3
    },
    "Question31": {
      "Question": "A company uses AWS Lambda functions and an Amazon S3 trigger to process images into an S3 bucket A development team set up multiple environments in a single AWS account. <br>After a recent production deployment, the development team observed that the development S3 buckets invoked the production environment Lambda functions. These invocations caused unwanted execution of development S3 files by using production Lambda functions. The development team must prevent these invocations. The team must follow security best practices. <br>Which solution will meet these requirements?",
      "Option1": "Update the Lambda execution role for the production Lambda function to add a policy that allows the execution role to read from only the production environment S3 bucket.",
      "Option2": "Move the development and production environments into separate AWS accounts. Add a resource policy to each Lambda function to allow only S3 buckets that are within the same account to invoke the function.",
      "Option3": "Add a resource policy to the production Lambda function to allow only the production environment S3 bucket to invoke the function.",
      "Option4": "Move the development and production environments into separate AWS accounts. Update the Lambda execution role for each function to add a policy that allows the execution role to read from the S3 bucket that is within the same account.",
      "Correct Answer": 2
    },
    "Question32": {
      "Question": "A company has an AWS Lambda function that processes incoming requests from an Amazon API Gateway API. The API calls the Lambda function by using a Lambda alias. A developer updated the Lambda function code to handle more details related to the incoming requests. The developer wants to deploy the new Lambda function for more testing by other developers with no impact to customers that use the API <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a new version of the Lambda function. Create a new stage on API Gateway with integration to the new Lambda version. Use the new API Gateway stage to test the Lambda function.",
      "Option2": "Update the existing Lambda alias used by API Gateway to a weighted alias. Add the new Lambda version as an additional Lambda function with a weight of 10%. Use the existing API Gateway stage for testing.",
      "Option3": "Create a new version of the Lambda function. Create and deploy a second Lambda function to filter incoming requests from API Gateway. If the filtering Lambda function detects a test request, the filtering Lambda function will invoke the new Lambda version of the code. For other requests, the filtering Lambda function will invoke the old Lambda version. Update the API Gateway API to use the filtering Lambda function.",
      "Option4": "Create a new version of the Lambda function. Create a new API Gateway API for testing purposes. Update the integration of the new API with the new Lambda version. Use the new API for testing.",
      "Correct Answer": 1
    },
    "Question33": {
      "Question": "A developer is creating an AWS Lambda function in VPC mode. An Amazon S3 event will invoke the Lambda function when an object is uploaded into an S3 bucket. The Lambda function will process the object and produce some analytic results that will be recorded into a file. Each processed object will also generate a log entry that will be recorded into a file. <br>Other Lambda functions, AWS services, and on-premises resources must have access to the result files and log file. Each log entry must also be appended to the same shared log file. The developer needs a solution that can share files and append results into an existing file. <br>Which solution should the developer use to meet these requirements?",
      "Option1": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in Lambda, Store the result files and log file in the mount point. Append the log entries to the log file.",
      "Option2": "Create an Amazon Elastic Block Store (Amazon EBS) Multi-Attach enabled volume. Attach the EBS volume to all Lambda functions. Update the Lambda function code to download the log file, append the log entries, and upload the modified log file to Amazon EBS.",
      "Option3": "Create a reference to the /tmp local directory. Store the result files and log file by using the directory reference. Append the log entry to the log file.",
      "Option4": "Create a reference to the /opt storage directory. Store the result files and log file by using the directory reference. Append the log entry to the log file.",
      "Correct Answer": 1
    },
    "Question34": {
      "Question": " A developer has designed an application to store incoming data as JSON files in Amazon S3 objects. Custom business logic in an AWS Lambda function then transforms the objects, and the Lambda function loads the data into an Amazon DynamoDB table. Recently, the workload has experienced sudden and significant changes in traffic. The flow of data to the DynamoDB table is becoming throttled. <br>The developer needs to implement a solution to eliminate the throttling and load the data into the DynamoDB table more consistently. <br>Which solution will meet these requirements?",
      "Option1": "Refactor the Lambda function into two functions. Configure one function to transform the data and one function to load the data into the DynamoDB table. Create an Amazon Simple Queue Service (Amazon SQS) queue in between the functions to hold the items as messages and to invoke the second function.",
      "Option2": "Turn on auto scaling for the DynamoDB table. Use Amazon CloudWatch to monitor the table's read and write capacity metrics and to track consumed capacity.",
      "Option3": "Create an alias for the Lambda function. Configure provisioned concurrency for the application to use.",
      "Option4": "Refactor the Lambda function into two functions. Configure one function to store the data in the DynamoDB table. Configure the second function to process the data and update the items after the data is stored in DvnamoDB. Create a DvnamoDB stream to invoke the second function after the data is stored.",
      "Correct Answer": 1
    },
    "Question35": {
      "Question": "A developer is creating a service that uses an Amazon S3 bucket for image uploads. The service will use an AWS Lambda function to create a thumbnail of each image. Each time an image is uploaded, the service needs to send an email notification and create the thumbnail. The developer needs to configure the image processing and email notifications setup. <br>Which solution will meet these requirements?",
      "Option1": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an email notification subscription to the SNS topic.",
      "Option2": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the SQS queue to the SNS topic. Create an email notification subscription to the SQS queue.",
      "Option3": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure S3 event notifications with a destination of the SQS queue. Subscribe the Lambda function to the SQS queue. Create an email notification subscription to the SOS queue.",
      "Option4": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Send S3 event notifications to Amazon EventBridge. Create an EventBridge rule that runs the Lambda function when images are uploaded to the S3 bucket. Create an EventBridge rule that sends notifications to the SQS queue. Create an email notification subscription to the SOS queue.",
      "Correct Answer": 1
    },
    "Question36": {
      "Question": "A developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the developer's account. The developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. <br>Which logs can the developer use to verify whether the traffic is reaching subnet B?",
      "Option1": "VPN logs",
      "Option2": "BGP logs",
      "Option3": "VPC Flow Logs",
      "Option4": "AWS CloudTrail logs",
      "Correct Answer": 3
    },
    "Question37": {
      "Question": "A developer has written an application that runs on Amazon EC2 instances. The developer is adding functionality for the application to write objects to an Amazon S3 bucket. <br>Which policy must the developer modify to allow the instances to write these objects?",
      "Option1": "The IAM policy that is attached to the EC2 instance profile role",
      "Option2": "The session policy that is applied to the EC2 instance role session",
      "Option3": "The AWS Key Management Service (AWS KMS) key policy that is attached to the EC2 instance profile role",
      "Option4": "The Amazon VPC endpoint policy",
      "Correct Answer": 1
    },
    "Question38": {
      "Question": "A developer is building an application that uses Amazon DynamoDB. The developer wants to retrieve multiple specific items from the database with a single API call. <br>Which DynamoDB API call will meet these requirements with the MINIMUM impact on the database?",
      "Option1": "BatchGetItem",
      "Option2": "Getltem",
      "Option3": "Scan",
      "Option4": "Query",
      "Correct Answer": 1
    },
    "Question39": {
      "Question": "An e-commerce web application that shares session state on-premises is being migrated to AWS. The application must be fault tolerant, natively highly scalable, and any service interruption should not affect the user experience. <br>What is the best option to store the session state?",
      "Option1": "﻿﻿﻿Store the session state in Amazon ElastiCache.",
      "Option2": "﻿﻿﻿Store the session state in Amazon CloudFront.",
      "Option3": "Store the session state in Amazon S3.",
      "Option4": "Enable session stickiness using elastic load balancers.",
      "Correct Answer": 1
    },
    "Question40": {
      "Question": "A company needs to develop a proof of concept for a web service application. The application will show the weather forecast for one of the company's office locations. The application will provide a REST endpoint that clients can call. Where possible, the application should use caching features provided by AWS to limit the number of requests to the backend service. The application backend will receive a small amount of traffic only during testing. <br>Which approach should the developer take to provide the REST endpoint MOST cost-effectively?",
      "Option1": "Create a container image. Deploy the container image by using Amazon Elastic Kubernetes Service (Amazon EKS). Expose the functionality by using Amazon API Gateway.",
      "Option2": "Create an AWS Lambda function by using the AWS Serverless Application Model (AWS SAM). Expose the Lambda functionality by using Amazon API Gateway.",
      "Option3": "Create a container image. Deploy the container image by using Amazon Elastic Container Service (Amazon ECS). Expose the functionality by using Amazon API Gateway.",
      "Option4": "Create a microservices application. Deploy the application to AWS Elastic Beanstalk. Expose the AWS Lambda functionality by using an Application Load Balancer.",
      "Correct Answer": 3
    },
    "Question41": {
      "Question": "A company moved some of its secure files to a private Amazon S3 bucket that has no public access. The company wants to develop a serverless application that gives its employees the ability to log in and securely share the files with other users. <br>Which AWS feature should the company use to share and access the files securely?",
      "Option1": "Amazon Cognito user pool",
      "Option2": "﻿﻿﻿S3 presigned URLs",
      "Option3": "S3 bucket policy",
      "Option4": "Amazon Cognito identity pool",
      "Correct Answer": 1
    },
    "Question42": {
      "Question": "A company is using an Amazon API Gateway REST API endpoint as a webhook to publish events from an on-premises source control management (SCM) system to Amazon EventBridge. The company has configured an EventBridge rule to listen for the events and to control application deployment in a central AWS account. The company needs to receive the same events across multiple receiver AWS accounts. <br>How can a developer meet these requirements without changing the configuration of the SCM system?",
      "Option1": "Deploy the API Gateway REST API to all the required AWS accounts. Use the same custom domain name for all the gateway endpoints so that a single SCM webhook can be used for all events from all accounts.",
      "Option2": "﻿﻿﻿Deploy the API Gateway REST API to all the receiver AWS accounts. Create as many SCM webhooks as the number of AWS accounts.",
      "Option3": "Grant permission to the central AWS account for EventBridge to access the receiver AWS accounts. Add an EventBridge event bus on the receiver AWS accounts as the targets to the existing EventBridge rule.",
      "Option4": "Convert the API Gateway type from REST API to HTTP API.",
      "Correct Answer": 1
    },
    "Question43": {
      "Question": "A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. <br>What is the simplest way to do this?",
      "Option1": "﻿﻿﻿Write a script that deletes old records; schedule the script as a cron job on an Amazon EC2 instance.",
      "Option2": "Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.",
      "Option3": "Each day, create a new table to hold session data; delete the previous day's table.",
      "Option4": "﻿﻿﻿Add an attribute with the expiration time; name the attribute ItemExpiration.",
      "Correct Answer": 1
    },
    "Question44": {
      "Question": "A company's new mobile app uses Amazon API Gateway. As the development team completes a new release of its APIs, a developer must safely and transparently roll out the API change. <br>What is the SIMPLEST solution for the developer to use for rolling out the new API version to a limited number of users through API Gateway?",
      "Option1": "Create a new API in API Gateway. Direct a portion of the traffic to the new API using an Amazon Route S3 weighted routing policy.",
      "Option2": "Validate the new API version and promote it to production during the window of lowest expected utilization.",
      "Option3": "Implement an Amazon CloudWatch alarm to trigger a rollback if the observed HTTP 500 status code rate exceeds a predetermined threshold.",
      "Option4": "Use the canary release deployment option in API Gateway. Direct a percentage of the API traffic using the canarySettings setting.",
      "Correct Answer": 2
    },
    "Question45": {
      "Question": "A developer is implementing an AWS Cloud Development Kit (AWS CDK) serverless application. <br>The developer will provision several AWS Lambda functions and Amazon API Gateway APIs during AWS CloudFormation stack creation. The developer's workstation has the AWS Serverless Application Model (AWS SAM) and the AWS CDK installed locally. <br>How can the developer test a specific Lambda function locally?.",
      "Option1": "﻿﻿﻿Run the sam package and sam deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function.",
      "Option2": "﻿﻿﻿Run the cdk synth and cdk deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function.",
      "Option3": "Run the cdk synth and sam local invoke commands with the function construct identifier and the path to the synthesized CloudFormation template.",
      "Option4": "﻿﻿﻿Run the cdk synth and sam local start-lambda commands with the function construct identifier and the path to the synthesized CloudFormation template.",
      "Correct Answer": 2
    },
    "Question46": {
      "Question": "A developer is creating a Ruby application and needs to automate the deployment, scaling, and management of an environment without requiring knowledge of the underlying infrastructure. <br>Which service would best accomplish this task?",
      "Option1": "AWS CodeDeploy",
      "Option2": "AWS Cloud Formation",
      "Option3": "AWS OpsWorks",
      "Option4": "AWS Elastic Beanstalk",
      "Correct Answer": 3
    },
    "Question47": {
      "Question": "A developer has created an AWS Lambda function to provide notification through Amazon Simple Notification Service (Amazon SNS) whenever a file is uploaded to Amazon S3 that is larger than 50 MB. The developer has deployed and tested the Lambda function by using the CLI. However, when the event notification is added to the S3 bucket and a 3,000 MB file is uploaded, the Lambda function does not launch.",
      "Option1": "Which of the following is a possible reason for the Lambda function's inability to launch?",
      "Option2": "The S3 event notification does not activate for files that are larger than 1,000 MB.",
      "Option3": "The resource-based policy for the Lambda function does not have the required permissions to be invoked by Amazon S3.",
      "Option4": "Lambda functions cannot be invoked directly from an S3 event.",
      "Option5": "The S3 bucket needs to be made public.",
      "Correct Answer": 2
    },
    "Question48": {
      "Question": "A developer is building a highly secure healthcare application using serverless components. This application requires writing temporary data to / tmp storage on an AWS Lambda function. <br>How should the developer encrypt this data?",
      "Option1": "Enable Amazon EBS volume encryption with an AWS KMS key in the Lambda function configuration so that all storage attached to the Lambda function is encrypted.",
      "Option2": "Set up the Lambda function with a role and key policy to access an AWS KMS key. Use the key to generate a data key used to encrypt all data prior to writing to / tmp storage.",
      "Option3": "Use OpenSSL to generate a symmetric encryption key on Lambda startup. Use this key to encrypt the data prior to writing to /tmp.",
      "Option4": "Use an on-premises hardware security module (HS) to generate keys, where the Lambda function requests a data key from the HSM and uses that to encrypt data on all requests to the function.",
      "Correct Answer": 4
    },
    "Question49": {
      "Question": "A company hosts a batch processing application on AWS Elastic Beanstalk with instances that run the most recent version of Amazon Linux. The application sorts and processes large datasets. <br>In recent weeks, the application's performance has decreased significantly during a peak period for traffic. A developer suspects that the application issues are related to the memory usage. The developer checks the Elastic Beanstalk console and notices that memory usage is not being tracked.",
      "Option1": "How should the developer gather more information about the application performance issues?",
      "Option2": "Configure the Amazon CloudWatch agent to push logs to Amazon CloudWatch Logs by using port 443.",
      "Option3": "Configure the Elastic Beanstalk ebextensions directory to track the memory usage of the instances.",
      "Option4": "Configure the Amazon CloudWatch agent to track the memory usage of the instances.",
      "Option5": "Configure an Amazon CloudWatch dashboard to track the memory usage of the instances.",
      "Correct Answer": 3
    },
    "Question50": {
      "Question": "A company is planning to use AWS CodeDeploy to deploy an application to Amazon Elastic Container Service (Amazon ECS). During the deployment of a new version of the application, the company initially must expose only 10% of live traffic to the new version of the deployed application. <br>Then, after 15 minutes elapse, the company must route all the remaining live traffic to the new version of the deployed application. <br>Which CodeDeploy predefined configuration will meet these requirements?",
      "Option1": "CodeDeployDefault.ECSCanary10Percent15Minutes",
      "Option2": "CodeDeployDefault.LambdaCanary10Percent5Minutes",
      "Option3": "CodeDeployDefault.LambdaCanary10Percent|15Minutes",
      "Option4": "CodeDeployDefault.ECSLinear10PercentEvery1Minutes",
      "Correct Answer": 4
    }
  }
}
