{
  "Exam1": {
    "id": 1,
    "quesNum": 75,

    "Question1": {
      "Question": "A developer is deploying a new application to Amazon Elastic Container Service (Amazon ECS). The developer needs to securely store and retrieve different types of variables. These variables include authentication information for a remote API, the URL for the API, and credentials. The authentication information and API URL must be available to all current and future deployed versions of the application across development, testing, and production environments. <br>How should the developer retrieve the variables with the FEWEST application changes?",
      "Option1": "Update the application to retrieve the variables from AWS Systems Manager Parameter Store. Use unique paths in Parameter Store for each variable in each environment. Store the credentials in AWS Secrets Manager in each environment.",
      "Option2": "Update the application to retrieve the variables from AWS Key Management Service (AWS KMS). Store the API URL and credentials as unique keys for each environment.",
      "Option3": "Update the application to retrieve the variables from an encrypted file that is stored with the application. Store the API URL and credentials in unique files for each environment.",
      "Option4": "Update the application to retrieve the variables from each of the deployed environments. Define the authentication information and API URL in the ECS task definition as unique names during the deployment process.",
      "Correct Answer": 1
    },
    "Question2": {
      "Question": "A company is implementing an application on Amazon EC2 instances. The application needs to process incoming transactions. When the application detects a transaction that is not valid, the application must send a chat message to the company's support team. To send the message, the application needs to retrieve the access token to authenticate by using the chat API. <br> A developer needs to implement a solution to store the access token. The access token must be encrypted at rest and in transit. The access token must also be accessible from other AWS accounts. <br>Which solution will meet these requirements with the LEAST management overhead?",
      "Option1": "Use an AWS Systems Manager Parameter Store SecureString parameter that uses an AWS Key Management Service (AWS KMS) AWS managed key to store the access token. Add a resource-based policy to the parameter to allow access from other accounts. Update the IAM role of the EC2 instances with permissions to access Parameter Store. Retrieve the token from Parameter Store with the decrypt flag enabled. Use the decrypted access token to send the message to the chat.",
      "Option2": "Encrypt the access token by using an AWS Key Management Service (AWS KMS) customer managed key. Store the access token in an Amazon DynamoDB table. Update the IAM role of the EC2 instances with permissions to access DynamoDB and AWS KMS. Retrieve the token from DynamoDDecrypt the token by using AWS KMS on the EC2 instances. Use the decrypted access token to send the message to the chat.",
      "Option3": "Use AWS Secrets Manager with an AWS Key Management Service (AWS KMS) customer managed key to store the access token. Add a resource-based policy to the secret to allow access from other accounts. Update the IAM role of the EC2 instances with permissions to access Secrets Manager. Retrieve the token from Secrets Manager. Use the decrypted access token to send the message to the chat.",
      "Option4": "Encrypt the access token by using an AWS Key Management Service (AWS KMS) AWS managed key. Store the access token in an Amazon S3 bucket. Add a bucket policy to the $3 bucket to allow access from other accounts. Update the IAM role of the EC instances with permissions to access Amazon $3 and AWS KMS. Retrieve the token from the $3 bucket. Decrypt the token by using AWS KMS on the EC2 instances. Use the decrypted access token to send the message to the chat.",
      "Correct Answer": 3
    },
    "Question3": {
      "Question": "A company is running Amazon EC2 instances in multiple AWS accounts. A developer needs to implement an application that collects all the lifecycle events of the EC2 instances. The application needs to store the lifecycle events in a single Amazon Simple Queue Service (Amazon SQS) queue in the company's main AWS account for further processing. <br> Which solution will meet these requirements?",
      "Option1": "Configure Amazon EC2 to deliver the EC2 instance lifecycle events from all accounts to the Amazon EventBridge event bus of the main account. Add an EventBridge rule to the event bus of the main account that matches all EC2 instance lifecycle events. Add the SQS queue as a target of the rule.",
      "Option2": "Use the resource policies of the SQS queue in the main account to give each account permissions to write to that SQS queue. Add to the Amazon EventBridge event bus of each account an EventBridge rule that matches all EC2 instance lifecycle events. Add the SQS queue in the main account as a target of the rule.",
      "Option3": "Write an AWS Lambda function that scans through all EC2 instances in the company accounts to detect EC2 instance lifecycle changes. Configure the Lambda function to write a notification message to the SQS queue in the main account if the function detects an EC2 instance lifecycle change. Add an Amazon EventBridge scheduled rule that invokes the Lambda function every minute.",
      "Option4": "Configure the permissions on the main account event bus to receive events from all accounts. Create an Amazon EventBridge rule in each account to send all the EC2 instance lifecycle events to the main account event bus. Add an EventBridge rule to the main account event bus that matches all EC2 instance lifecycle events. Set the SQS queue as a target for the rule.",
      "Correct Answer": 4
    },
    "Question4": {
      "Question": "A company is building a scalable data management solution by using AWS services to improve the speed and agility of development. The solution will ingest large volumes of data from various sources and will process this data through multiple business rules and transformations. <br> The solution requires business rules to run in sequence and to handle reprocessing of data if errors occur when the business rules run. The company needs the solution to be scalable and to require the least possible maintenance. <br> Which AWS service should the company use to manage and automate the orchestration of the data flows to meet these requirements?",
      "Option1": "AWS Batch",
      "Option2": "AWS Step Functions",
      "Option3": "AWS Glue",
      "Option4": "AWS Lambda",
      "Correct Answer": 2
    },
    "Question5": {
      "Question": "A developer has created an AWS Lambda function that is written in Python. The Lambda function reads data from objects in Amazon S3 and writes data to an Amazon DynamoDB table. The function is successfully invoked from an $3 event notification when an object is created. However, the function fails when it attempts to write to the DynamoDB table. <br>What is the MOST likely cause of this issue?",
      "Option1": "The Lambda function's concurrency limit has been exceeded.",
      "Option2": "DynamoDB table requires a global secondary index (GSI) to support writes.",
      "Option3": "The Lambda function does not have IAM permissions to write to DynamoDB.",
      "Option4": "The DynamoDB table is not running in the same Availability Zone as the Lambda function.",
      "Correct Answer": 3
    },
    "Question6": {
      "Question": "A company has an application that provides blog hosting services to its customers. The application includes an Amazon DynamoDB table with a primary key. The primary key consists of the customers' UserName as a partition key and the NumberOfBlogs as a sort key. The application stores the TotalReactionsOnBlogs as an attribute on the same DynamoDB table. <br> A developer needs to implement an operation to retrieve the top 10 customers based on the greatest number of reactions on their blogs. This operation must not consume the DynamoDB table's existing read capacity. <br> What should the developer do to meet these requirements in the MOST operationally efficient manner?",
      "Option1": "For the existing DynamoDB table, create a new global secondary index (GSI) that has the UserName as a partition key and the TotalReactionsOnBlogs as a sort key.",
      "Option2": "For the existing DynamoDB table, create a new local secondary index (LSI) that has the UserName as a partition key and the TotalReactionsOnBlogs as a sort key.",
      "Option3": "Back up and restore the DynamoDB table to a new DynamoDB table. Create a new global secondary index (GSI) that has the UserName as a partition key and the TotalReactionsOnBlogs as a sort key. Delete the old DynamoDB table.",
      "Option4": "Back up and restore the DynamoDB table to a new DynamoDB table. Create a new local secondary index (LSI) that has the UserName as a partition key and the TotalReactionsOnBlogs as a sort key. Delete the old DynamoDB table.",
      "Correct Answer": 1
    },
    "Question7": {
      "Question": "A gaming company has deployed a web portal on AWS Elastic Beanstalk. The company sometimes needs to deploy new versions three or four times in a day. <br> The company needs to deploy new features for all users as quickly as possible. The solution must minimize performance impact and must maximize availability. <br> What solution will meet these requirements?",
      "Option1": "Use a rolling deployment policy to deploy to Amazon EC2 instances.",
      "Option2": "Use an immutable deployment policy to deploy to Amazon EC2 instances.",
      "Option3": "Use an all-at-once deployment policy to deploy to Amazon EC2 instances.",
      "Option4": "Use a canary deployment strategy to deploy changes to Amazon EC2 instances.",
      "Correct Answer": 2
    },
    "Question8": {
      "Question": "A developer is using Amazon API Gateway as an HTT proxy to a backend endpoint. There are three separate environments development, testing, and production. Each environment has a corresponding stage in the API. <br> The developer needs to direct traffic to different backend endpoints for each of these stages without creating a separate API for each stage. <br> Which solution will meet these requirements?",
      "Option1": "Add a model to the API. Add a schema to differentiate the different backend endpoints",
      "Option2": "Create stage variables. Configure the variables in the HTT integration request of the API.",
      "Option3": "Use API custom authorizers to create an authorizer for each of the different stages.",
      "Option4": "Update the integration response of the API to add different backend endpoint.",
      "Correct Answer": 2
    },
    "Question9": {
      "Question": "A developer is running an application on an Amazon EC2 instance. When the application tries to read an Amazon S3 bucket the application fails. The developer notices that the associated IAM role is missing the S3 read permission. The developer needs to give the application the ability to read the S3 bucket. <br> Which solution will meet this requirement with the LEAST application disruption?",
      "Option1": "Add the permission to the role. Terminate the existing EC2 instance. Launch a new EC2 instance",
      "Option2": "Add the permission to the role so that the change will take effect automatically",
      "Option3": "Add the permission to the role. Hibernate and restart the existing EC2 instance.",
      "Option4": "Add the permission to the $3 bucket. Restart the EC2 instance.",
      "Correct Answer": 2
    },
    "Question10": {
      "Question": "A developer wants to implement Amazon EC2 Auto Scaling for a web application The developer wants to ensure that sessions will not be lost during scale-in events. <br> How can the developer maintain the session state and share it across the EC2 instances?",
      "Option1": "Write the sessions to an Amazon Elastic Block Store (Amazon EBS) volume. Mount the EBS volume to each EC2 instance in the group.",
      "Option2": "Store the sessions in an Amazon ElastiCache for Memcached cluster. Configure the application to use the Memcached API.",
      "Option3": "Publish the sessions to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe each EC2 instance in the group to the topic.",
      "Option4": "Write the sessions to an Amazon Redshift cluster. Configure the application to use the Amazon Redshift API.",
      "Correct Answer": 2
    },
    "Question11": {
      "Question": "A company uses AWS Organizations to manage multiple accounts. Account A has an application that runs on an Amazon EC2 instance. The application uses the <br> AWS CLI to run automated deployments in Account.'|An administrator set up cross-account access by using an EC2 IAM service role in Account A and an IAM role in Account. 'l <br> The application uses the following command to assume the IAM role in Account 'Ibut is unable to deploy anything in Account. 'laws sts assume-role -role-arn 'am:aws:iam::<AccountB-ID>:role/AccountB-Role' role-session-name AccountB-Role-Session <br> Which step is needed next so that the application can successfully use the credentials that it obtains by using the role in Account B?",
      "Option1": "Configure the access key and secret access key of a valid IAM user from Account 'lin the environment variables.",
      "Option2": "Configure the access key, secret access key, and token from the assume-role command in the environment variables.",
      "Option3": "Create a CLI profile for the EC2 IAM service role in the AWS configuration file.",
      "Option4": "Delete any access keys and secret access keys in the environment variables.",
      "Correct Answer": 2
    },
    "Question12": {
      "Question": "A developer assumes a role with the AWS CLI to get a set of temporary security credentials. <br> Which of the following must be set in the environment variables or AWS configuration file to authenticate to AWS?",
      "Option1": "AccessKeyld SecretAccessKey, and AssumedRoleld",
      "Option2": "Userld, Session Token, and AssumedRoleld",
      "Option3": "AccessKeyld, SecretAccessKey, and Session Token",
      "Option4": "Userld, Session Token and Credentials",
      "Correct Answer": 3
    },
    "Question13": {
      "Question": "A company has designed a serverless application that uses Amazon Simple Queue Service (Amazon SQS) and an AWS Lambda function. The application receives data in an SQS queue on the last day of every month. The function successfully processes all the data in the queue within 1 day. <br> A detailed AWS bill shows a large number of SQS API requests throughout the month, even though the queue receives data only on the last day of the month. <br> What is the root cause of the extra API requests?",
      "Option1": "Lambda is using long polling to check for messages in the SQS queue.",
      "Option2": "The SQS queue is sending ping messages to Lambda.",
      "Option3": "The function is not automatically deleting the messages from the SQS queue.",
      "Option4": "Visibility timeout is not set to 0 to remove the extra API requests.",
      "Correct Answer": 1
    },
    "Question14": {
      "Question": "A company set up a continuous build process that uses AWS CodeBuild and AWS CodeCommit. <br> During the development phase, developers are frequently pushing code and causing significant build failures. The company wants a solution that will build code before the developers push the code to the main branch. <br> Which solution meets these requirements MOST cost-effectively?",
      "Option1": "Configure am Amazon EC2 instance with the CodeBuild agent to build the code.",
      "Option2": "Configure CodeBuild jobs on AWS for each branch build process.",
      "Option3": "Configure the CodeBuild agent to build the code in the local system.",
      "Option4": "Configure a Jenkins plugin for CodeBuild to run the code build process",
      "Correct Answer": 3
    },
    "Question15": {
      "Question": "A developer is writing a mobile application that allows users to view images from an S3 bucket. <br> The users must be able to log in with their Amazon login, as well as supported social media accounts. <br> How can the developer provide this authentication functionality?",
      "Option1": "Use Amazon Cognito with web identity federation.",
      "Option2": "Use Amazon Cognito with SAML-based identity federation.",
      "Option3": "Use IAM access keys and secret keys in the application code to allow Get* on the S3 bucket.",
      "Option4": "Use AWS STS AssumeRole in the application code and assume a role with Get* permissions on the S3 bucket.",
      "Correct Answer": 1
    },
    "Question16": {
      "Question": "A developer needs to modify an application architecture to meet new functional requirements. <br> Application data is stored in Amazon DynamoDB and processed for analysis in a nightly batch. The system analysts do not want to wait until the next day to view the processed data and have asked to have it available in near-real time. <br> Which application architecture pattern would enable the data to be processed as it is received?",
      "Option1": "Event driven",
      "Option2": "Client-server driven",
      "Option3": "Fan-out driven",
      "Option4": "Schedule driven",
      "Correct Answer": 1
    },
    "Question17": {
      "Question": "A media company is using Amazon API Gateway to manage microservices that are implemented as AWS Lambda functions. The company's development team is planning to roll out another version of its API. To avoid affecting existing users when the new API is deployed, the company wants to give all users a 3-month period to migrate from the old API version to the new API version. <br> Which implementation strategy should the company use to achieve this goal?",
      "Option1": "Update the Lambda functions. Configure the API to use Lambda proxy integration.",
      "Option2": "Update the Lambda functions. Provide the API client with the new Lambda endpoints.",
      "Option3": "Use API Gateway to deploy a new stage that uses updated Lambda functions and provides users with a new URL",
      "Option4": "Use API Gateway to redirect requests based on a request header to updated Lambda functions. Configure a 90-day expiration on the old API",
      "Correct Answer": 3
    },
    "Question18": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question19": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question20": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question21": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question22": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question23": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question24": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question25": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question26": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question27": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question28": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question29": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question29": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question30": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question31": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question32": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question33": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question34": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question35": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question36": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question37": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question38": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question39": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question40": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question41": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question42": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question43": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question44": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question45": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question46": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question47": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question48": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question49": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question50": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question51": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question52": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question53": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question54": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question55": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question56": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question57": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question58": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question59": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question60": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question61": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question62": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question63": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question64": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question65": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question66": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question67": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question68": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question69": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question70": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question71": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question72": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question73": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question74": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    },
    "Question75": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 2
    }
  },


  "Exam2": {
    "id": 1,
    "quesNum": 75,
    "Question1": {
      "Question": "A company uses Amazon API Gateway to expose a set of APIs to customers. The APIs have caching enabled in API Gateway. Customers need a way to invalidate the cache for each API when they test the API. What should a developer do to give customers the ability to invalidate the API cache?",
      "Option1": "Ask the customers to use AWS credentials to call the InvalidateCache API operation.",
      "Option2": "Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.",
      "Option3": "Ask the customers to use the AWS SDK API Gateway class to invoke the InvalidateCache API operation.",
      "Option4": "Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to add the INVALIDATE_CACHE query string parameter when they make an API call.",
      "Correct Answer": 2
    },
    "Question2": {
      "Question": "A developer is creating an AWS CloudFormation stack. The stack contains IAM resources with custom names. When the developer tries to deploy the stack, they receive an InsufficientCapabilities error. What should the developer do to resolve this issue?",
      "Option1": "Specify the CAPABILITY_AUTO_EXPAND capability in the CloudFormation stack.",
      "Option2": "Use an administrators role to deploy IAM resources with CloudFormation.",
      "Option3": "Specify the CAPABILITY_IAM capability in the CloudFormation stack.",
      "Option4": "Specify the CAPABILITY_NAMED_IAM capability in the CloudFormation stack.",
      "Correct Answer": 4
    },
    "Question3": {
      "Question": "A developer is preparing to begin development of a new version of an application. The previous version of the application is deployed in a production environment. The developer needs to deploy fixes and updates to the current version during the development of the new version of the application. The code for the new version of the application is stored in AWS CodeCommit. Which solution will meet these requirements?",
      "Option1": "From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.",
      "Option2": "Create a Git tag of the code that is currently deployed in production. Create a Git tag for the development of the new version. Push the two tags to the CodeCommit repository.",
      "Option3": "From the main branch, create a branch of the code that is currently deployed in production. Apply an IAM policy that ensures no other users can push or merge to the branch.",
      "Option4": "Create a new CodeCommit repository for development of the new version of the application. Create a Git tag for the development of the new version.",
      "Correct Answer": 1
    },
    "Question4": {
      "Question": " A developer is building a serverless application that connects to an Amazon Aurora PostgreSQL database. The serverless application consists of hundreds of AWS Lambda functions. During every Lambda function scale out, a new database connection is made that increases database resource consumption. The developer needs to decrease the number of connections made to the database. The solution must not impact the scalability of the Lambda functions. Which solution will meet these requirements?",
      "Option1": "Configure provisioned concurrency for each Lambda function by setting the ProvisionedConcurrentExecutions parameter to 10.",
      "Option2": "Enable cluster cache management for Aurora PostgreSQL. Change the connection string of each Lambda function to point to cluster cache management.",
      "Option3": "Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy.",
      "Option4": "Configure reserved concurrency for each Lambda function by setting the ReservedConcurrentExecutions parameter to 10.",
      "Correct Answer": 3
    },
    "Question5": {
      "Question": "A developer is setting up infrastructure by using AWS CloudFormation. If an error occurs when the resources described in the Cloud Formation template are provisioned, successfully provisioned resources must be preserved. The developer must provision and update the CloudFormation stack by using the AWS CLI. Which solution will meet these requirements?",
      "Option1": "Add an --enable-termination-protection command line option to the create-stack command and the update- stack command.",
      "Option2": "Add a --disable-rollback command line option to the create-stack command and the update-stack command.",
      "Option3": "Add a --parameters ParameterKey=Preserve Resources, ParameterValue=True command line option to the create-stack command and the update-stack command.",
      "Option4": "Add a --tags Key=Preserve Resources,Value=True command line option to the create-stack command and the update-stack command.",
      "Correct Answer": 2
    },
    "Question6": {
      "Question": "A developer is working on an application that processes operating data from loT devices. Each lot device uploads a data file once every hour to an Amazon S3 bucket. The developer wants to immediately process each data file when the data file is uploaded to Amazon S3. The developer will use an AWS Lambda function to process the data files from Amazon S3. The Lambda function is configured with the S3 bucket information where the files are uploaded. The developer wants to configure the Lambda function to immediately invoke after each data file is uploaded. Which solution will meet these requirements?",
      "Option1": "Add an asynchronous invocation to the Lambda function. Select the S3 bucket as the source.",
      "Option2": "Add an Amazon EventBridge event to the Lambda function. Select the S3 bucket as the source.",
      "Option3": "Add a trigger to the Lambda function. Select the S3 bucket as the source.",
      "Option4": "Add a layer to the Lambda function. Select the S3 bucket as the source.",
      "Correct Answer": 3
    },
    "Question7": {
      "Question": "A developer is building an application integrating an Amazon API Gateway with an AWS Lambda function. When calling the API. the developer receives the following error: Wed Nov 08 01:13:00 UTC 2017: Method completed with status: 502 What should the developer do to resolve the error?",
      "Option1": "Change the HTTP endpoint of the API to an HTTPS endpoint.",
      "Option2": "Change the format of the payload sent to the API Gateway.",
      "Option3": "Change the format of the Lambda function response to the API call.",
      "Option4": "Change the authorization header in the API call to access the Lambda function.",
      "Correct Answer": 3
    },
    "Question8": {
      "Question": "An IT department uses Amazon S3 to store sensitive images. After more than 1 year, the company moves the images into archival storage. The company rarely accesses the images, but the company wants a storage solution that maximizes resiliency. The IT department needs access to the images that have been moved to archival storage within 24 hours. Which solution will meet these requirements MOST cost-effectively?",
      "Option1": "Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.",
      "Option2": "Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.",
      "Option3": "Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.",
      "Option4": "Use S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.",
      "Correct Answer": 1
    },
    "Question9": {
      "Question": "A company has an application that stores data in Amazon RDS instances. The application periodically experiences surges of high traffic that cause performance problems. During periods of peak traffic, a developer notices a reduction in query speed in all database queries. The team's technical lead determines that a multi-threaded and scalable caching solution should be used to offload the heavy read traffic. The solution needs to improve performance. Which solution will meet these requirements with the LEAST complexity?",
      "Option1": "Use Amazon ElastiCache for Memcached to offload read requests from the main database.",
      "Option2": "Replicate the data to Amazon DynamoDSet up a DynamoDB Accelerator (DAX) cluster.",
      "Option3": "Configure the Amazon RDS instances to use Multi-AZ deployment with one standby instance. Offload read requests from the main database to the standby instance.",
      "Option4": "Use Amazon ElastiCache for Redis to offload read requests from the main database.",
      "Correct Answer": 1
    },
    "Question10": {
      "Question": "A company has a serverless application on AWS that uses a fleet of AWS Lambda functions that have aliases. The company regularly publishes new Lambda function by using an in-house deployment solution. The company wants to improve the release process and to use traffic shifting. A newly published function version should initially make available only to a fixed percentage of production users. Which solution will meet these requirements?",
      "Option1": "Configure routing on the alias of the new function by using a weighted alias.",
      "Option2": "Configure a canary deployment type for Lambda.",
      "Option3": "Configure routing on the new versions by using environment variables.",
      "Option4": "Configure a linear deployment type for Lambda.",
      "Correct Answer": 1
    },
    "Question11": {
      "Question": "A developer is creating a new REST API by using Amazon API Gateway and AWS Lambda. The development team tests the API and validates responses for the known use cases before deploying the API to the production environment. The developer wants to make the REST API available for testing by using API Gateway locally. Which AWS Serverless Application Model Command Line Interface (AWS SAM CLI) subcommand will meet these requirements?",
      "Option1": "Sam local invoke",
      "Option2": "Sam local generate-event",
      "Option3": "Sam local start-lambda",
      "Option4": "Sam local start-api",
      "Correct Answer": 4
    },
    "Question12": {
      "Question": "A developer has created an AWS Lambda function that makes queries to an Amazon Aurora MySQL DB instance. When the developer performs a test, the DB instance shows an error for too many connections. Which solution will meet these requirements with the LEAST operational effort?",
      "Option1": "Create a read replica for the DB instance. Query the replica DB instance instead of the primary DB instance.",
      "Option2": "Migrate the data to an Amazon DynamoDB database.",
      "Option3": "Configure the Amazon Aurora MySQL DB instance for Multi-AZ deployment.",
      "Option4": "Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.",
      "Correct Answer": 4
    },
    "Question13": {
      "Question": "A company needs to set up secure database credentials for all its AWS Cloud resources. The company's resources include Amazon RDS DB instances, Amazon DocumentDB clusters, and Amazon Aurora DB instances. The company's security policy mandates that database credentials be encrypted at rest and rotated at a regular interval. Which solution will meet these requirements MOST securely?",
      "Option1": "Set up IAM database authentication for token-based access. Generate user tokens to provide centralized access to RDS DB instances, Amazon DocumentDB clusters, and Aurora DB instances.",
      "Option2": "Create parameters for the database credentials in AWS Systems Manager Parameter Store. Set the Type parameter to SecureString. Set up automatic rotation on the parameters.",
      "Option3": "Store the database access credentials as an encrypted Amazon S3 object in an S3 bucket. Block all public access on the S3 bucket. Use S3 server-side encryption to set up automatic rotation on the encryption key.",
      "Option4": "Create an AWS Lambda function by using the Secrets Manager Rotation Template template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.",
      "Correct Answer": 4
    },
    "Question14": {
      "Question": "A company built a new application in the AWS Cloud. The company automated the bootstrapping of new resources with an Auto Scaling group by using AWS CloudFormation templates. The bootstrap scripts contain sensitive data. The company needs a solution that is integrated with CloudFormation to manage the sensitive data in the bootstrap scripts. Which solution will meet these requirements in the MOST secure way?",
      "Option1": "Put the sensitive data into a CloudFormation parameter. Encrypt the CloudFormation templates by using an AWS Key Management Service (AWS KMS) key.",
      "Option2": "Put the sensitive data into an Amazon S3 bucket. Update the CloudFormation templates to download the object from Amazon S3 during bootstrap.",
      "Option3": "Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.",
      "Option4": "Put the sensitive data into Amazon Elastic File System (Amazon EFS). Enforce EFS encryption after file system creation. Update the CloudFormation templates to retrieve data from Amazon EFS.",
      "Correct Answer": 3
    },
    "Question15": {
      "Question": "A company wants to automate part of its deployment process. A developer needs to automate the process of checking for and deleting unused resources that supported previously deployed stacks but that are no longer used. The company has a central application that uses the AWS Cloud Development Kit (AWS CDK) to manage all deployment stacks. The stacks are spread out across multiple accounts. The developer's solution must integrate as seamlessly as possible within the current deployment process. Which solution will meet these requirements with the LEAST amount of configuration?",
      "Option1": "In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CloudFormation template from a JSON file. Use the template to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option2": "In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option3": "In the central AWS CDK, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an API in AWS Amplify. Use the API to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option4": "In the AWS Lambda console, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to import the Lambda function into the stack and to invoke the Lambda function when the deployment stack runs.",
      "Correct Answer": 2
    },
    "Question16": {
      "Question": "A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?",
      "Option1": "Compress the application to a .zip file and upload it into AWS Lambda.",
      "Option2": "Test the new AWS Lambda function by first tracing it in AWS X-Ray.",
      "Option3": "Bundle the serverless application using a SAM package.",
      "Option4": "Create the application environment using the eb create my-env command.",
      "Correct Answer": 3
    },
    "Question17": {
      "Question": "A company is migrating its PostgreSQL database into the AWS Cloud. The company wants to use a database that will secure and regularly rotate database credentials. The company wants a solution that does not require additional programming overhead. Which solution will meet these requirements?",
      "Option1": "Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.",
      "Option2": "Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.",
      "Option3": "Use Amazon DynamoDB for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.",
      "Option4": "Use Amazon DynamoDB for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.",
      "Correct Answer": 2
    },
    "Question18": {
      "Question": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
      "Option1": "Configure AWS CloudTrail logging to investigate the invocation failures.",
      "Option2": "Configure Dead Letter Queues by sending events to Amazon SQS for investigation.",
      "Option3": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
      "Option4": "Configure AWS Config to process any direct unprocessed events.",
      "Correct Answer": 2
    },
    "Question19": {
      "Question": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
      "Option1": "Use Amazon CloudFront with signed URLs for Amazon S3.",
      "Option2": "Create a dedicated Amazon CloudFront Distribution for each customer.",
      "Option3": "Use Amazon Cloud Front with AWS Lambda@Edge.",
      "Option4": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
      "Correct Answer": 1
    },
    "Question20": {
      "Question": "A company has an ecommerce application. To track product reviews, the company's development team uses an Amazon DynamoDB table. <br>Every record includes the following: <br> • A Review ID, a 16-digit universally unique identifier (UUID) A Product ID and User ID, 16-digit UUIDS that reference other tables <br> • A Product Rating on a scale of 1-5 <br> • An optional comment from the user <br> The table partition key is the Review ID. The most performed query against the table is to find the 10 reviews with the highest rating for a given product. <br> Which index will provide the FASTEST response for this query?",
      "Option1": "A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key",
      "Option2": "A global secondary index (GSI) with Product ID as the partition key and Review ID as the sort key ",
      "Option3": "A local secondary index (LSI) with Product ID as the partition key and Product Rating as the sort key",
      "Option4": "A local secondary index (LSI) with Review ID as the partition key and Product ID as the sort key",
      "Correct Answer": 1
    },
    "Question21": {
      "Question": "A developer is storing sensitive data generated by an application in Amazon S3. The developer wants to encrypt the data at rest. 1 # A company policy requires an audit trail of when the AWS Key Management Service (AWS KMS) key was used and by whom. <br>Which encryption option will meet these requirements?",
      "Option1": " Server-side encryption with Amazon S3 managed keys (SSE-S3)",
      "Option2": "Server-side encryption with AWS KMS managed keys (SSE-KMS)",
      "Option3": "Server-side encryption with customer-provided keys (SSE-C)",
      "Option4": "Server-side encryption with self-managed keys",
      "Correct Answer": 2
    },
    "Question22": {
      "Question": " A development team maintains a web application by using a single AWS RDS, template. The template defines web servers and an Amazon RDS database. The team uses the CloudFormation template to deploy the CloudFormation stack to different environments. <br> During a recent application deployment, a developer caused the primary development database to be dropped and recreated. The result of this incident was a loss of data. The team needs to avoid accidental database deletion in the future. <br>Which solutions will meet these requirements? (Choose two.)",
      "Option1": "Add a CloudFormation Deletion Policy attribute with the Retain value to the database resource.",
      "Option2": "Update the CloudFormation stack policy to prevent updates to the database.",
      "Option3": "Modify the database to use a Multi-AZ deployment.",
      "Option4": "Create a CloudFormation stack set for the web application and database deployments.",
      "Option5": "Add a CloudFormation Deletion Policy attribute with the Retain value to the stack.",
      "Correct Answer": 1
    },
    "Question23": {
      "Question": "A developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. <br>How should the environment variables be passed to the container?",
      "Option1": "Define an array that includes the environment variables under the environment parameter within the service definition.",
      "Option2": "Define an array that includes the environment variables under the environment parameter within the task definition.",
      "Option3": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
      "Option4": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
      "Correct Answer": 2
    },
    "Question24": {
      "Question": "A developer has been asked to create an AWS Lambda function that is invoked any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being invoked. <br>Which option would enable DynamoDB table updates to invoke the Lambda function?",
      "Option1": "Change the Stream View Type parameter value to NEW_AND_OLD_IMAGES for the DynamoDB table.",
      "Option2": "Configure event source mapping for the Lambda function.",
      "Option3": "Map an Amazon Simple Notification Service (Amazon SNS) topic to the DynamoDB streams.",
      "Option4": "Increase the maximum runtime (timeout) setting of the Lambda function.",
      "Correct Answer": 2
    },
    "Question25": {
      "Question": "A developer is building a web application that uses Amazon API Gateway to expose an AWS Lambda function to process requests from clients. During testing, the Developer notices that the API Gateway times out even though the Lambda function finishes under the set time limit. <br>Which of the following API Gateway metrics in Amazon CloudWatch can help the Developer troubleshoot the issue? (Choose two.)",
      "Option1": "CacheHitCount",
      "Option2": "IntegrationLatency",
      "Option3": "CacheMissCount",
      "Option4": "Latency",
      "Option5": "Count",
      "Correct Answer": 2
    },
    "Question26": {
      "Question": "A developer is creating an Amazon DynamoDB table. The entire table must be encrypted at rest. Which solution will meet this requirement MOST cost-effectively?",
      "Option1": " Create the DynamoDB table by using default encryption settings.",
      "Option2": "Encrypt the data by using the DynamoDB Encryption Client.",
      "Option3": "During creation of the DynamoDB table, configure encryption at rest with an AWS Key Management Service (AWS KMS) AWS managed key.",
      "Option4": " During creation of the DynamoDB table, configure encryption at rest with an AWS Key Management Service (AWS KMS) customer managed key.",
      "Correct Answer": 1
    },
    "Question27": {
      "Question": "A company developed an API application on AWS by using Amazon CloudFront, Amazon API Gateway, and AWS Lambda. The API has a minimum of four requests every second. A developer notices that many API users run the same query by using the POST method. The developer wants to cache the POST request to optimize the API resources. <br>Which solution will meet these requirements?",
      "Option1": "Configure the Cloud Front cache. Update the application to return cached content based upon the default request headers.",
      "Option2": "Override the cache method in the selected stage of API Gateway. Select the POST method.",
      "Option3": " Save the latest request response in Lambda /tmp directory. Update the Lambda function to check the /tmp directory.",
      "Option4": "Save the latest request in AWS Systems Manager Parameter Store. Modify the Lambda function to take the latest request response from Parameter Store.",
      "Correct Answer": 2
    },
    "Question28": {
      "Question": "An application writes items to an Amazon DynamoDB table. As the application scales to thousands of instances, calls to the DynamoDB API generate occasional ThrottlingException errors. The application is coded in a language incompatible with the AWS SDK. How should the error be handled?",
      "Option1": "Add exponential backoff to the application logic",
      "Option2": "Use Amazon SQS as an API message bus",
      "Option3": "Pass API calls through Amazon API Gateway",
      "Option4": "Send the items to DynamoDB through Amazon Kinesis Data Firehose",
      "Correct Answer": 1
    },
    "Question29": {
      "Question": "A company has an application that runs as a series of AWS Lambda functions. Each Lambda function receives data from an Amazon Simple Notification Service (Amazon SNS) topic and writes the data to an Amazon Aurora DB instance. <br>To comply with an information security policy, the company must ensure that the Lambda functions all use a single securely encrypted database connection string to access Aurora. <br>Which solution will meet these requirements?",
      "Option1": "Use IAM database authentication for Aurora to enable secure database connections for all the Lambda functions.",
      "Option2": "Store the credentials and read the credentials from an encrypted Amazon RDS DB instance.",
      "Option3": "Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.",
      "Option4": "Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption.",
      "Correct Answer": 3
    },
    "Question30": {
      "Question": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
      "Option1": "Use Amazon CloudFront with signed URLs for Amazon S3",
      "Option2": "Create a dedicated Amazon Cloud Front Distribution for each customer",
      "Option3": "Use Amazon Cloud Front with AWS Lambda@Edge",
      "Option4": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket",
      "Correct Answer": 1
    },
    "Question31": {
      "Question": " company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. <br>What is the simplest way to do this?",
      "Option1": "Write a script that deletes old records; schedule the script as a cron job on an Amazon EC2 instance.",
      "Option2": "Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.",
      "Option3": "Each day, create a new table to hold session data; delete the previous day's table.",
      "Option4": "Add an attribute with the expiration time; name the attribute Item Expiration.",
      "Correct Answer": 2
    },
    "Question32": {
      "Question": "A developer is using AWS Elastic Beanstalk to create a deployment for a web application that supports ecommerce. According to a company requirement. Amazon EC2 instances that host one version of the application must be retired when the deployment of a new version is complete. Which deployment methods can the developer use to meet this requirement? (Choose two.)",
      "Option1": "All-al-once deployment",
      "Option2": " In-place deployment",
      "Option3": "Rolling deployment without an additional batch",
      "Option4": "Blue/green deployment",
      "Option5": "Immutable deployment",
      "Correct Answer": 4
    },
    "Question33": {
      "Question": "A developer is building a web and mobile application for two types of users: regular users and guest users. Regular users are required to log in, but guest users do not log in. Users should see only their data, regardless of whether they authenticate. Users need AWS credentials before they can access AWS resources. <br>What is the MOST secure solution that the developer can implement to allow access for guest users?",
      "Option1": "Use an Amazon Cognito credentials provider to issue temporary credentials that are linked to an unauthenticated role that has access to the required resources.",
      "Option2": "Set up an IAM user that has permissions to the required resources. Hardcode the IAM credentials in the web and mobile application.",
      "Option3": "Generate temporary keys that are stored in AWS Key Management Service (AWS KMS). Use the temporary keys to access the required resources.",
      "Option4": "Generate temporary credentials. Store the temporary credentials in AWS Secrets Manager. Use the temporary credentials to access the required resources.",
      "Correct Answer": 1
    },
    "Question34": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 1
    },
    "Question35": {
      "Question": "A developer is modifying an existing AWS Lambda function. While checking the code, the developer notices hardcoded parameter values for an Amazon RDS for SQL Server user name, password, database, host, and port. There are also hardcoded parameter values for an Amazon DynamoDB table, an Amazon S3 bucket, and an Amazon Simple Notification Service (Amazon SNS) topic. <br>The developer wants to securely store the parameter values outside the code in an encrypted format and wants to turn on rotation for the credentials. The developer also wants to be able to reuse the parameter values from other applications and to update the parameter values without modifying code. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. ",
      "Option2": "Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic.",
      "Option3": "Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. Create a Lambda function and set the logic for the credentials rotation task. Schedule the credentials rotation task in Amazon EventBridge.",
      "Option4": "Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Store the DynamoDB table, S3 bucket, and SNS topic in Amazon S3. Create a Lambda function and set the logic for the credentials rotation. Invoke the Lambda function on a schedule.",
      "Correct Answer": 2
    },
    "Question36": {
      "Question": "A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed. <br>What is the MOST cost-effective way to delete posts that are older than 48 hours?",
      "Option1": "For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteltem API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.",
      "Option2": "For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteltem API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.",
      "Option3": "For each item, add a new attribute of type Date that has a timestamp that is set to 48 hours after the blog post creation time. Create a global secondary index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the BatchWriteltem API operation. Schedule the function with an Amazon CloudWatch event every minute.",
      "Option4": "For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.",
      "Correct Answer": 4
    },
    "Question37": {
      "Question": "A developer has an application that is composed of many different AWS Lambda functions. The Lambda functions all use some of the same dependencies. To avoid security issues, the developer is constantly updating the dependencies of all of the Lambda functions. The result is duplicated effort for each function. <br>How can the developer keep the dependencies of the Lambda functions up to date with the LEAST additional complexity?",
      "Option1": "Define a maintenance window for the Lambda functions to ensure that the functions get updated copies of the dependencies.",
      "Option2": "Upgrade the Lambda functions to the most recent runtime version.",
      "Option3": "Define a Lambda layer that contains all of the shared dependencies.",
      "Option4": "Use an AWS CodeCommit repository to host the dependencies in a centralized location.",
      "Correct Answer": 3
    },
    "Question38": {
      "Question": "A developer at a company recently created a serverless application to process and show data from business reports. The application's user interface (UI) allows users to select and start processing the files. The UI displays a message when the result is available to view. The application uses AWS Step Functions with AWS Lambda functions to process the files. The developer used Amazon API Gateway and Lambda functions to create an API to support the UI. <br>The company's Ul team reports that the request to process a file is often returning timeout errors because of the size or complexity of the files. The UI team wants the API to provide an immediate response so that the UI can display a message while the files are being processed. The backend process that is invoked by the API needs to send an email message when the report processing is complete. <br>What should the developer do to configure the API to meet these requirements?",
      "Option1": "Change the API Gateway route to add an X-Amz-Invocation-Type header with a static value of 'Event' in the integration request. Deploy the API Gateway stage to apply the changes.",
      "Option2": "Change the configuration of the Lambda function that implements the request to process a file. Configure the maximum age of the event so that the Lambda function will run asynchronously.",
      "Option3": "Change the API Gateway timeout value to match the Lambda function timeout value. Deploy the API Gateway stage to apply the changes.",
      "Option4": "Change the API Gateway route to add an X-Amz-Target header with a static value of 'Async' in the integration request. Deploy the API Gateway stage to apply the changes.",
      "Correct Answer": 1
    },
    "Question39": {
      "Question": "A developer accesses AWS CodeCommit over SSH. The SSH keys configured to access AWS CodeCommit are tied to a user with the following permissions: <br>The developer needs to create/delete branches. <br>Which specific IAM permissions need to be added, based on the principle of least privilege?",
      "Option1": "'codecommit:CreateBranch' 'codecommit:DeleteBranch'",
      "Option2": "'codecommit:Put*'",
      "Option3": "'codecommit:Update*'",
      "Option4": "'codecommit:*'",
      "Correct Answer": 1
    },
    "Question40": {
      "Question": "A developer is working on an AWS Lambda function that accesses Amazon DynamoDB. The Lambda function must retrieve an item and update some of its attributes, or create the item if it does not exist. The Lambda function has access to the primary key. <br>Which IAM permissions should the developer request for the Lambda function to achieve this functionality?",
      "Option1": "dynamodb: DeleteItem <br>dynamodb: GetItem <br>dynamodb: PutItem <br>dynamodb: UpdateItem",
      "Option2": "dynamodb:GetItem <br>dynamodb: DescribeTable <br>dynamodb: GetRecords <br>dynamodb: PutItem",
      "Option3": "dynamodb: UpdateTable <br>dynamodb: UpdateItem",
      "Option4": "dynamodb: GotItem <br>dynamodb: PutItem",
      "Correct Answer": 4
    },
    "Question41": {
      "Question": "A Developer created configuration specifications for an AWS Elastic Beanstalk application in a file named healthcheckurl.yaml in the .ebextensions/directory of their application source bundle. The file contains the following: <br> option_settings: <br>-namespace: aws:elasticbeanstalk: application option_name: Application Healthcheck URL value: /health_check <br>After the application launches, the health check is not being run on the correct path, event though it is valid. <br>What can be done to correct this configuration file?",
      "Option1": "Convert the file to JSON format.",
      "Option2": "Rename the file to a .config extension.",
      "Option3": "Change the configuration section from options_settings to resources.",
      "Option4": "Change the namespace of the option settings to a custom namespace.",
      "Correct Answer": 2
    },
    "Question42": {
      "Question": "A developer is building a serverless application that is based on AWS Lambda. The developer initializes the AWS software development kit (SDK) outside of the Lambda handler function. What is the PRIMARY benefit of this action?",
      "Option1": "Improves legibility and stylistic convention",
      "Option2": "Takes advantage of runtime environment reuse ",
      "Option3": "Provides better error handling",
      "Option4": "Creates a new SDK instance for each invocation",
      "Correct Answer": 2
    },
    "Question43": {
      "Question": "A developer at a company needs to create a small application that makes the same API call once each day at a designated time. The company does not have infrastructure in the AWS Cloud yet, but the company wants to implement this functionality on AWS. <br>Which solution meets these requirements in the MOST operationally efficient manner?",
      "Option1": "Use a Kubernetes cron job that runs on Amazon Elastic Kubernetes Service (Amazon EKS).",
      "Option2": "Use an Amazon Linux crontab scheduled job that runs on Amazon EC2.",
      "Option3": "Use an AWS Lambda function that is invoked by an Amazon EventBridge scheduled event.",
      "Option4": "Use an AWS Batch job that is submitted to an AWS Batch job queue.",
      "Correct Answer": 3
    },
    "Question44": {
      "Question": "A developer has code that is stored in an Amazon S3 bucket. The code must be deployed as an AWS Lambda function across multiple accounts in the same AWS Region as the S3 bucket. An AWS CloudFormation template that runs for each account will deploy the Lambda function. <br>What is the MOST secure way to allow CloudFormation to access the Lambda code in the S3 bucket?",
      "Option1": "Grant the CloudFormation service role the S3 ListBucket and GetObject permissions. Add a bucket policy to Amazon S3 with the principal of 'AWS': [account numbers].",
      "Option2": "Grant the CloudFormation service role the S3 GetObject permission. Add a bucket policy to Amazon S3 with the principal of '*'.",
      "Option3": "Use a service-based link to grant the Lambda function the S3 ListBucket and GetObject permissions by explicitly adding the S3 bucket's account number in the resource.",
      "Option4": "Use a service-based link to grant the Lambda function the S3 GetObject permission. Add a resource of '*' to allow access to the S3 bucket",
      "Correct Answer": 1
    },
    "Question45": {
      "Question": "An application that runs on AWS Lambda requires access to specific highly confidential objects in an Amazon S3 bucket. In accordance with the principle of least privilege, a company grants access to the S3 bucket by using only temporary credentials. <br>How can a developer configure access to the S3 bucket in the MOST secure way?",
      "Option1": "Hardcode the credentials that are required to access the S3 objects in the application code. Use the credentials to access the required S3 objects.",
      "Option2": "Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID in AWS Secrets Manager. Configure the application to retrieve the Secrets Manager secret and use the credentials to access the $3 objects.",
      "Option3": "Create a Lambda function execution role. Attach a policy to the role that grants access to specific objects in the S3 bucket.",
      "Option4": "Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID as environment variables in Lambda. Use the environment variables to access the required S3 objects.",
      "Correct Answer": 3
    },
    "Question46": {
      "Question": "When using the AWS Encryption SDK, how does the developer keep track of the data encryption keys used to encrypt data?",
      "Option1": "The developer must manually keep track of the data encryption keys used for each data object.",
      "Option2": "The SDK encrypts the data encryption key and stores it (encrypted) as part of the returned ciphertext.",
      "Option3": "The SDK stores the data encryption keys automatically in Amazon S3.",
      "Option4": "The data encryption key is stored in the Userdata for the EC2 instance.",
      "Correct Answer": 2
    },
    "Question47": {
      "Question": "A developer is troubleshooting an application that uses Amazon DynamoDB in the us-west-2 Region. The application is deployed to an Amazon EC2 instance. The application requires read-only permissions to a table that is named Cars. The EC2 instance has an attached IAM role that contains the following IAM policy: <br>When the application tries to read from the Cars table, an Access Denied error occurs. <br>How can the developer resolve this error?",
      "Option1": " Modify the IAM policy resource to be 'arn:aws:dynamodb:us-west-2:account-id:table/*''.",
      "Option2": "Modify the IAM policy to include the dynamodb:* action.",
      "Option3": "Create a trust policy that specifies the EC2 service principal. Associate the role with the policy.",
      "Option4": "Create a trust relationship between the role and dynamodb.amazonaws.com.",
      "Correct Answer": 3
    },
    "Question48": {
      "Question": "A developer has observed an increase in bugs in the AWS Lambda functions that a development team has deployed in its Node.js application. To minimize these bugs, the developer wants to implement automated testing of Lambda functions in an environment that closely simulates the Lambda environment. <br>The developer needs to give other developers the ability to run the tests locally. The developer also needs to integrate the tests into the team's continuous integration and continuous delivery (CI/CD) pipeline before the AWS Cloud Development Kit (AWS CDK) deployment. <br>Which solution will meet these requirements?",
      "Option1": "Create sample events based on the Lambda documentation. Create automated test scripts that use the cdk local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts.",
      "Option2": "Install a unit testing framework that reproduces the Lambda execution environment. Create sample events based on the Lambda documentation. Invoke the handler function by using a unit testing framework. Check the response. Document how to run the unit testing framework for the other developers on the team. Update the CI/CD pipeline to run the unit testing framework.",
      "Option3": "Install the AWS Serverless Application Model (AWS SAM) CLI tool. Use the sam local generate-event command to generate sample events for the automated tests. Create automated test scripts that use the sam local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts.",
      "Option4": "Create sample events based on the Lambda documentation. Create a Docker container from the Node.js base image to invoke the Lambda functions. Check the response. Document how to run the Docker container for the other developers on the team. Update the CI/CD pipeline to run the Docker container.",
      "Correct Answer": 3
    },
    "Question49": {
      "Question": "A developer wants to deploy a new version of an AWS Elastic Beanstalk application. During deployment, the application must maintain full capacity and avoid service interruption. Additionally, the developer must minimize the cost of additional resources that support the deployment. <br>Which deployment method should the developer use to meet these requirements?",
      "Option1": "All at once",
      "Option2": "Rolling with additional batch",
      "Option3": "Blue/green",
      "Option4": "Immutable",
      "Correct Answer": 4
    },
    "Question50": {
      "Question": "A developer must analyze performance issues with production-distributed applications written as AWS Lambda functions. These distributed Lambda applications invoke other components that make up the applications. <br>How should the developer identify and troubleshoot the root cause of the performance issues in production?",
      "Option1": " Add logging statements to the Lambda functions, then use Amazon CloudWatch to view the logs.",
      "Option2": "Use AWS Cloud Trail and then examine the logs.",
      "Option3": "Use AWS X-Ray, then examine the segments and errors.",
      "Option4": "Run Amazon Inspector agents and then analyze performance.",
      "Correct Answer": 3
    },
    "Question51": {
      "Question": "The Operations team is asking for a graphical representation of one key performance metric for each application. These metrics should be available on one screen for easy monitoring. <br>Which steps should the Developer take to accomplish this using Amazon CloudWatch?",
      "Option1": "Create a custom namespace with a unique metric name for each application.",
      "Option2": "Create a custom dimension with a unique metric name for each application.",
      "Option3": "Create a custom event with a unique metric name for each application.",
      "Option4": "Create a custom alarm with a unique metric name for each application.",
      "Correct Answer": 1
    },
    "Question52": {
      "Question": "A developer is creating a serverless website with content that includes HTML files, images, videos, and JavaScript (client-side scripts). <br>Which combination of services should the Developer use to create the website?",
      "Option1": "Amazon S3 and Amazon CloudFront",
      "Option2": "Amazon EC2 and Amazon ElastiCache",
      "Option3": "Amazon ECS and Redis",
      "Option4": "AWS Lambda and Amazon API Gateway",
      "Correct Answer": 1
    },
    "Question53": {
      "Question": "An application runs on multiple EC2 instances behind an ELB. <br>Where is the session data best written so that it can be served reliably across multiple requests?",
      "Option1": "Write data to Amazon ElastiCache.",
      "Option2": "Write data to Amazon Elastic Block Store.",
      "Option3": "Write data to Amazon EC2 Instance Store.",
      "Option4": "Write data to the root filesystem.",
      "Correct Answer": 1
    },
    "Question54": {
      "Question": "A company uses Amazon DynamoDB for managing and tracking orders. The DynamoDB table is partitioned based on the order date. The company receives a huge increase in orders during a sales event, causing DynamoDB writes to throttle, and the consumed throughput is far below the provisioned throughput. <br>According to AWS best practices, how can this issue be resolved with MINIMAL costs?",
      "Option1": "Create a new DynamoDB table for every order date.",
      "Option2": "Increase the read and write capacity units of the DynamoDB table.",
      "Option3": "Add a random number suffix to the partition key values.",
      "Option4": "Add a global secondary index to the DynamoDB table.",
      "Correct Answer": 3
    },
    "Question55": {
      "Question": "A developer is writing a serverless application that requires an AWS Lambda function to be invoked every 10 minutes. <br>What is an automated and serverless way to invoke the function?",
      "Option1": "Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.",
      "Option2": "Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.",
      "Option3": "Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function.",
      "Option4": "Create an Amazon Simple Notification Service (Amazon SNS) topic that has a subscription to the Lambda function with a 600-second timer.",
      "Correct Answer": 3
    },
    "Question56": {
      "Question": "A developer maintains applications that store several secrets in AWS Secrets Manager. The applications use secrets that have changed over time. The developer needs to identify required secrets that are still in use. The developer does not want to cause any application downtime. <br>What should the developer do to meet these requirements?",
      "Option1": "Configure an AWS CloudTrail log file delivery to an Amazon S3 bucket. Create an Amazon CloudWatch alarm for the GetSecretValue Secrets Manager API operation requests.",
      "Option2": "Create a secretsmanager-secret-unused AWS Config managed rule. Create an Amazon EventBridge rule to initiate notifications when the AWS Config managed rule is met.",
      "Option3": "Deactivate the applications secrets and monitor the applications error logs temporarily.",
      "Option4": "Configure AWS X-Ray for the applications. Create a sampling rule to match the GetSecretValue Secrets Manager API operation requests.",
      "Correct Answer": 2
    },
    "Question57": {
      "Question": "A company uses a custom root certificate authority certificate chain (Root CA Cert) that is 10 KB in size to generate SSL certificates for its on-premises HTTPS endpoints. One of the company's cloud-based applications has hundreds of AWS Lambda functions that pull data from these endpoints. A developer updated the trust store of the Lambda execution environment to use the Root CA Cert when the Lambda execution environment is initialized. The developer bundled the Root CA Cert as a text file in the Lambda deployment bundle. <br>After 3 months of development, the Root CA Cert is no longer valid and must be updated. The developer needs a more efficient solution to update the Root CA Cert for all deployed Lambda functions. The solution must not include rebuilding or updating all Lambda functions that use the Root CA Cert. The solution must also work for all development, testing, and production environments. Each environment is managed in a separate AWS account. Which combination of steps should the developer take to meet these requirements MOST cost-effectively? (Choose two.)",
      "Option1": "Store the Root CA Cert as a secret in AWS Secrets Manager. Create a resource-based policy. Add IAM users to allow access to the secret.",
      "Option2": "Store the Root CA Cert as a SecureString parameter in AWS Systems Manager Parameter Store. Create a resource-based policy. Add IAM users to allow access to the policy.",
      "Option3": "Store the Root CA Cert in an Amazon S3 bucket. Create a resource-based policy to allow access to the bucket.",
      "Option4": "Refactor the Lambda code to load the Root CA Cert from the Root CA Cert's location. Modify the runtime trust store inside the Lambda function handler.",
      "Option5": "Refactor the Lambda code to load the Root CA Cert from the Root CA Cert's location. Modify the runtime trust store outside the Lambda function handler.",
      "Correct Answer": 1
    },
    "Question58": {
      "Question": "A company has multiple Amazon VPC endpoints in the same VPC. A developer needs to configure an Amazon S3 bucket policy so users can access an S3 bucket only by using these VPC endpoints. Which solution will meet these requirements?",
      "Option1": "Create multiple S3 bucket polices by using each VPC endpoint ID that have the aws:SourceVpce value in the StringNotEquals condition.",
      "Option2": "Create a single S3 bucket policy that has the aws:SourceVpc value and in the StringNotEquals condition to use VPC ID.",
      "Option3": "Create a single S3 bucket policy that has the aws:SourceVpce value and in the StringNotEquals condition to use vpce*",
      "Option4": "Create a single S3 bucket policy that has multiple aws:sourceVpce value in the StringNotEquals condition. Repeat for all the VPC endpoint IDs.",
      "Correct Answer": 4
    },
    "Question59": {
      "Question": "A team of developers is using an AWS CodePipeline pipeline as a continuous integration and continuous delivery (CI/CD) mechanism for a web application. A developer has written unit tests to programmatically test the functionality of the application code. The unit tests produce a test report that shows the results of each individual check. The developer now wants to run these tests automatically during the CI/CD process. <br>Which solution will meet this requirement with the LEAST operational effort?",
      "Option1": "Write a Git pre-commit hook that runs the tests before every commit. Ensure that each developer who is working on the project has the pre-commit hook installed locally. Review the test report and resolve any issues before pushing changes to AWS CodeCommit.",
      "Option2": "Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage after the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.",
      "Option3": "Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage before the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.",
      "Option4": "Add a new stage to the pipeline. Use Jenkins as the provider. Configure CodePipeline to use Jenkins to run the unit tests. Write a Jenkinsfile that fails the stage if any test does not pass. Use the test report plugin for Jenkins to integrate the report with the Jenkins dashboard. View the test results in Jenkins. Resolve any issues.",
      "Correct Answer": 3
    },
    "Question60": {
      "Question": "A developer is planning to migrate on-premises company data to Amazon S3. The data must be encrypted, and the encryption keys must support automatic annual rotation. The company must use AWS Key Management Service (AWS KMS) to encrypt the data. <br>Which type of keys should the developer use to meet these requirements?",
      "Option1": "Amazon S3 managed keys",
      "Option2": "Symmetric customer managed keys with key material that is generated by AWS",
      "Option3": "Asymmetric customer managed keys with key material that is generated by AWS",
      "Option4": "Symmetric customer managed keys with imported key material",
      "Correct Answer": 2
    },
    "Question61": {
      "Question": "An organization is using Amazon CloudFront to ensure that its users experience low-latency access to its web application. The organization has identified a need to encrypt all traffic between users and CloudFront, and all traffic between CloudFront and the web application. <br>How can these requirements be met? (Choose two.)",
      "Option1": "Use AWS KMS to encrypt traffic between CloudFront and the web application.",
      "Option2": "Set the Origin Protocol Policy to 'HTTPS Only'.",
      "Option3": "Set the Origin's HTTP Port to 443.",
      "Option4": "Set the Viewer Protocol Policy to 'HTTPS Only' or 'Redirect HTTP to HTTPS'.",
      "Option5": "Enable the Cloud Front option Restrict Viewer Access.",
      "Correct Answer": 2
    },
    "Question62": {
      "Question": "A developer is trying to get data from an Amazon DynamoDB table called demoman-table. The developer configured the AWS CLI to use a specific IAM user's credentials and ran the following command: <br>aws dynamodb get-item --table-name demoman-table --key '{'id': {'N':'1993'}}' <br>The command returned errors and no rows were returned. <br>What is the MOST likely cause of these issues?",
      "Option1": "The command is incorrect; it should be rewritten to use put-item with a string argument.",
      "Option2": "The developer needs to log a ticket with AWS Support to enable access to the demoman-table.",
      "Option3": "Amazon DynamoDB cannot be accessed from the AWS CLI and needs to be called via the REST API.",
      "Option4": "The IAM user needs an associated policy with read access to demoman-table.",
      "Correct Answer": 4
    },
    "Question63": {
      "Question": "A developer is building an application that gives users the ability to view bank accounts from multiple sources in a single dashboard. The developer has automated the process to retrieve API credentials for these sources. The process invokes an AWS Lambda function that is associated with an AWS CloudFormation custom resource. <br>The developer wants a solution that will store the API credentials with minimal operational overhead. Which solution will meet these requirements in the MOST secure way?",
      "Option1": "Add an AWS Secrets Manager GenerateSecretString resource to the CloudFormation template. Set the value to reference new credentials for the CloudFormation resource.",
      "Option2": "Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter type to SecureString.",
      "Option3": "Add an AWS Systems Manager Parameter Store resource to the CloudFormation template. Set the CloudFormation resource value to reference the new credentials. Set the resource NoEcho attribute to true.",
      "Option4": "Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter NoEcho attribute to true.",
      "Correct Answer": 4
    },
    "Question64": {
      "Question": "A developer is building an application that uses AWS API Gateway APIs, AWS Lambda functions, and AWS DynamoDB tables. The developer uses the AWS Serverless Application Model (AWS SAM) to build and run serverless applications on AWS. Each time the developer pushes changes for only to the Lambda functions, all the artifacts in the application are rebuilt. <br>The developer wants to implement AWS SAM Accelerate by running a command to only redeploy the Lambda functions that have changed. <br>Which command will meet these requirements?",
      "Option1": "sam deploy --force-upload",
      "Option2": "sam deploy --no-execute-changeset",
      "Option3": "sam package",
      "Option4": "sam sync --watch",
      "Correct Answer": 4
    },
    "Question65": {
      "Question": "A developer is creating an AWS Lambda function that searches for items from an Amazon DynamoDB table that contains customer contact information. The DynamoDB table items have the customer's email_address as the partition key and additional properties such as customer_type, name and job_title. <br>The Lambda function runs whenever a user types a new character into the customer_type text input. The developer wants the search to return partial matches of all the email_address property of a particular customer_type. The developer does not want to recreate the DynamoDB table. <br>What should the developer do to meet these requirements?",
      "Option1": "Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins with key condition expression with the email_address property.",
      "Option2": "Add a global secondary index (GSI) to the DynamoDB table with email_address as the partition key and customer_type as the sort key. Perform a query operation on the GSI by using the begins with key condition expression with the email_address property.",
      "Option3": "Add a local secondary index (LSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins with key condition expression with the email_address property.",
      "Option4": "Add a local secondary index (LSI) to the DynamoDB table with job_title as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins with key condition expression with the email_address property.",
      "Correct Answer": 1
    },
    "Question66": {
      "Question": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. <br>Which combination of steps will resolve the latency issue? (Choose two.)",
      "Option1": "Double the Auto Scaling group's maximum number of servers.",
      "Option2": "Host the application code on AWS Lambda.",
      "Option3": "Scale vertically by resizing the EC2 instances.",
      "Option4": "Create an Amazon CloudFront distribution to cache the static content.",
      "Option5": "Store the application's static content in Amazon S3.",
      "Correct Answer": 2
    },
    "Question67": {
        "Question": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. <br>Which combination of steps will resolve the latency issue? (Choose two.)",
        "Option1": "Double the Auto Scaling group's maximum number of servers.",
        "Option2": "Host the application code on AWS Lambda.",
        "Option3": "Scale vertically by resizing the EC2 instances.",
        "Option4": "Create an Amazon CloudFront distribution to cache the static content.",
        "Option5": "Store the application's static content in Amazon S3.",
        "Correct Answer": 4
    },
    "Question68": {
      "Question": "An online food company provides an Amazon API Gateway HTTP API to receive orders for partners. The API is integrated with an AWS Lambda function. The Lambda function stores the orders in an Amazon DynamoDB table. <br>The company expects to onboard additional partners. Some of the partners require additional Lambda functions to receive orders. The company has created an Amazon S3 bucket. The company needs to store all orders and updates in the S3 bucket for future analysis. <br>How can the developer ensure that all orders and updates are stored to Amazon S3 with the LEAST development effort?",
      "Option1": "Create a new Lambda function and a new API Gateway API endpoint. Configure the new Lambda function to write to the S3 bucket. Modify the original Lambda function to post updates to the new API endpoint.",
      "Option2": "Use Amazon Kinesis Data Streams to create a new data stream. Modify the Lambda function to publish orders to the data stream. Configure the data stream to write to the S3 bucket.",
      "Option3": "Enable DynamoDB Streams on the DynamoDB table. Create a new Lambda function. Associate the stream's Amazon Resource Name (ARN) with the Lambda function. Configure the Lambda function to write to the S3 bucket as records appear in the table's stream.",
      "Option4": "Modify the Lambda function to publish to a new Amazon Simple Notification Service (Amazon SNS) topic as the Lambda function receives orders. Subscribe a new Lambda function to the topic. Configure the new Lambda function to write to the S3 bucket as updates come through the topic.",
      "Correct Answer": 3
    },
    "Question69": {
      "Question": "A developer wants to add request validation to a production environment Amazon API Gateway API. The developer needs to test the changes before the API is deployed to the production environment. For the test, the developer will send test requests to the API through a testing tool. Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Export the existing API to an OpenAPI file. Create a new API. Import the OpenAPI file. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.",
      "Option2": "Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage.",
      "Option3": "Create a new API. Add the necessary resources and methods, including new request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production",
      "Option4": "Clone the existing API. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.",
      "Correct Answer": 2
    },
    "Question70": {
      "Question": "A company has an application that uses AWS CodePipeline to automate its continuous integration and continuous delivery (CI/CD) workflow. The application uses AWS CodeCommit for version control. A developer who was working on one of the tasks did not pull the most recent changes from the main branch. A week later, the developer noticed merge conflicts. <br>How can the developer resolve the merge conflicts in the developer's branch with the LEAST development effort?",
      "Option1": "Clone the repository. Create a new branch. Update the branch with the changes.",
      "Option2": "Create a new branch. Apply the changes from the previous branch.",
      "Option3": "Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts.",
      "Option4": "Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.",
      "Correct Answer": 4
    },
    "Question71": {
      "Question": "A developer is creating an application for a company. The application needs to read the file doc.txt that is placed in the root folder of an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET. The company's security team requires the principle of least privilege to be applied to the application's IAM policy. <br>Which IAM policy statement will meet these security requirements?",
      "Option1": "{<br>'Action': ['s3:GetObject'], <br>'Effect': 'Allow',<br>'Resource': 'arn:aws: 53:::DOC-EXAMPLE-BUCKET/doc.txt'<br>}",
      "Option2": "{<br>'Action': ['s3'], <br>'Effect': 'Allow',<br>'Resource': '*'<br>}",
      "Option3": "{<br>'Action':['s3:'], <br>'Effect': 'Allow', <br>'Resource': 'arn:aws: :::DOC-EXAMPLE-BUCKET/doc.txt' <br>}",
      "Option4": "{<br>'Action':['s3:'], <br> 'Effect': 'Allow', <br> 'Resource': 'arn:aws: s3:::DOC-EXAMPLE-BUCKET/*' <br>}",
      "Correct Answer": 1
    },
    "Question72": {
      "Question": "Users are reporting errors in an application. The application consists of several microservices that are deployed on Amazon Elastic Container Service (Amazon ECS) with AWS Fargate. <br>Which combination of steps should a developer take to fix the errors? (Choose two.)",
      "Option1": "Deploy AWS X-Ray as a sidecar container to the microservices. Update the task role policy to allow access to the X-Ray API.",
      "Option2": "Deploy AWS X-Ray as a daemonset to the Fargate cluster. Update the service role policy to allow access to the X-Ray API.",
      "Option3": "Instrument the application by using the AWS X-Ray SDK. Update the application to use the PutXrayTrace API call to communicate with the X-Ray API.",
      "Option4": "Instrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X- Ray daemon.",
      "Option5": "Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action.",
      "Correct Answer": 4
    },
    "Question73": {
      "Question": "A company is developing a serverless multi-tier application on AWS. The company will build the serverless logic tier by using Amazon API Gateway and AWS Lambda. <br>While the company builds the logic tier, a developer who works on the frontend of the application must develop integration tests. The tests must cover both positive and negative scenarios, depending on success and error HTTP status codes. <br>Which solution will meet these requirements with the LEAST effort?",
      "Option1": "Set up a mock integration for API methods in API Gateway. In the integration request from Method Execution, add simple logic to return either a success or error based on HTTP status code. In the integration response, add messages that correspond to the HTTP status codes.",
      "Option2": "Create two mock integration resources for API methods in API Gateway. In the integration request, return a success HTTP status code for one resource and an error HTTP status code for the other resource. In the integration response, add messages that correspond to the HTTP status codes.",
      "Option3": "Create Lambda functions to perform tests. Add simple logic to return either success or error, based on the HTTP status codes. Build an API Gateway Lambda integration. Select appropriate Lambda functions that correspond to the HTTP status codes.",
      "Option4": "Create a Lambda function to perform tests. Add simple logic to return either success or error-based HTTP status codes. Create a mock integration in API Gateway. Select the Lambda function that corresponds to the HTTP status codes.",
      "Correct Answer": 1
    },
    "Question74": {
      "Question": "A developer is setting up a deployment pipeline. The pipeline includes an AWS CodeBuild build stage that requires access to a database to run integration tests. The developer is using a buildspec.yml file to configure the database connection. Company policy requires automatic rotation of all database credentials. <br>Which solution will handle the database credentials MOST securely?",
      "Option1": "Retrieve the credentials from variables that are hardcoded in the buildspec.yml file. Configure an AWS Lambda function to rotate the credentials.",
      "Option2": "Retrieve the credentials from an environment variable that is linked to a SecureString parameter in AWS Systems Manager Parameter Store. Configure Parameter Store for automatic rotation.",
      "Option3": "Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.",
      "Option4": "Retrieve the credentials from an environment variable that contains the connection string in plaintext. Configure an Amazon EventBridge event to rotate the credentials.",
      "Correct Answer": 3
    },
    "Question75": {
      "Question": "A company created four AWS Lambda functions that connect to a relational database server that runs on an Amazon RDS instance. A security team requires the company to automatically change the database password every 30 days. <br>Which solution will meet these requirements MOST securely?",
      "Option1": "Store the database credentials in the environment variables of the Lambda function. Deploy the Lambda function with the new credentials every 30 days.",
      "Option2": "Store the database credentials in AWS Secrets Manager. Configure a 30-day rotation schedule for the credentials.",
      "Option3": "Store the database credentials in AWS Systems Manager Parameter Store secure strings. Configure a 30-day schedule for the secure strings.",
      "Option4": "Store the database credentials in an Amazon S3 bucket that uses server-side encryption with customer- provided encryption keys (SSE-C). Configure a 30-day key rotation schedule for the customer key.",
      "Correct Answer": 1
    }
  },
  "Exam3": {
    "id": 1,
    "quesNum": 75,
    "Question1": {
      "Question": "A company is developing a serverless application that consists of various AWS Lambda functions behind Amazon API Gateway APIs. A developer needs to automate the deployment of Lambda function code. The developer will deploy updated Lambda functions with AWS CodeDeploy. The deployment must minimize the exposure of potential errors to end users. When the application is in production, the application cannot experience downtime outside the specified maintenance window. <br>Which deployment configuration will meet these requirements with the LEAST deployment time?",
      "Option1": "Use the AWS CodeDeploy in-place deployment configuration for the Lambda functions. Shift all traffic immediately after deployment.",
      "Option2": "Use the AWS CodeDeploy linear deployment configuration to shift 10% of the traffic every minute.",
      "Option3": "Use the AWS CodeDeploy all-at-once deployment configuration to shift all traffic to the updated versions immediately.",
      "Option4": "Use the AWS CodeDeploy predefined canary deployment configuration to shift 10% of the traffic immediately and shift the remaining traffic after 5 minutes.",
      "Correct Answer": 4
    },
    "Question2": {
      "Question": "A developer needs to store configuration variables for an application. The developer needs to set an expiration date and time for the configuration. The developer wants to receive notifications before the configuration expires. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a standard parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.",
      "Option2": "Create a standard parameter in AWS Systems Manager Parameter Store. Create an AWS Lambda function to expire the configuration and to send Amazon Simple Notification Service (Amazon SNS) notifications.",
      "Option3": "Create an advanced parameter in AWS Systems Manager Parameter Store. Set Expiration and ExpirationNotification policy types.",
      "Option4": "Create an advanced parameter in AWS Systems Manager Parameter Store. Create an Amazon EC2 instance with a cron job to expire the configuration and to send notifications.",
      "Correct Answer": 3
    },
    "Question3": {
      "Question": "A developer creates an AWS Lambda function that retrieves and groups data from several public API endpoints. The Lambda function has been updated and configured to connect to the private subnet of a VPC. An internet gateway is attached to the VPC. The VPC uses the default network ACL and security group configurations. <br>The developer finds that the Lambda function can no longer access the public API. The developer has ensured that the public API is accessible, but the Lambda function cannot connect to the API. <br>How should the developer fix the connection issue?",
      "Option1": "Ensure that the network ACL allows outbound traffic to the public internet.",
      "Option2": "Ensure that the security group allows outbound traffic to the public internet.",
      "Option3": "Ensure that outbound traffic from the private subnet is routed to a public NAT gateway.",
      "Option4": "Ensure that outbound traffic from the private subnet is routed to a new internet gateway.",
      "Correct Answer": 3
    },
    "Question4": {
      "Question": "A company is developing an ecommerce application that uses Amazon API Gateway APIs. The application uses AWS Lambda as a backend. The company needs to test the code in a dedicated, monitored test environment before the company releases the code to the production environment. <br>Which solution will meet these requirements?",
      "Option1": "Use a single stage in API Gateway. Create a Lambda function for each environment. Configure API clients to send a query parameter that indicates the environment and the specific Lambda function.",
      "Option2": "Use multiple stages in API Gateway. Create a single Lambda function for all environments. Add different code blocks for different environments in the Lambda function based on Lambda environment variables.",
      "Option3": "Use multiple stages in API Gateway. Create a Lambda function for each environment. Configure API Gateway stage variables to route traffic to the Lambda function in different environments.",
      "Option4": "Use a single stage in API Gateway. Configure API clients to send a query parameter that indicates the environment. Add different code blocks for different environments in the Lambda function to match the value of the query parameter.",
      "Correct Answer": 3
    },
    "Question5": {
      "Question": "A developer is working on a web application that uses Amazon DynamoDB as its data store. The application has two DynamoDB tables: one table that is named artists and one table that is named songs. The artists table has artistName as the partition key. The songs table has songName as the partition key and artistName as the sort key. <br>The table usage patterns include the retrieval of multiple songs and artists in a single database operation from the webpage. The developer needs a way to retrieve this information with minimal network traffic and optimal application performance. <br>Which solution will meet these requirements?",
      "Option1": "Perform a BatchGetItem operation that returns items from the two tables. Use the list of songName/artistName keys for the songs table and the list of artistName key for the artists table.",
      "Option2": "Create a local secondary index (LSI) on the songs table that uses artistName as the partition key. Perform a query operation for each artistName on the songs table that filters by the list of songName. Perform a query operation for each artistName on the artists table.",
      "Option3": "Perform a BatchGetitem operation on the songs table that uses the songName/artistName keys. Perform a BatchGetItem operation on the artists table that uses artistName as the key.",
      "Option4": "Perform a Scan operation on each table that filters by the list of songName/artistName for the songs table and the list of artistName in the artists table.",
      "Correct Answer": 1
    },
    "Question6": {
      "Question": "A developer is creating an AWS Lambda function. The Lambda function will consume messages from an Amazon Simple Queue Service (Amazon SQS) queue. The developer wants to integrate unit testing as part of the function's continuous integration and continuous delivery (CI/CD) process. <br>How can the developer unit test the function?",
      "Option1": "Create an AWS CloudFormation template that creates an SQS queue and deploys the Lambda function. Create a stack from the template during the CI/CD process. Invoke the deployed function. Verify the output.",
      "Option2": "Create an SQS event for tests. Use a test that consumes messages from the SQS queue during the function's CI/CD process.",
      "Option3": "Create an SQS queue for tests. Use this SQS queue in the application's unit test. Run the unit tests during the CI/CD process.",
      "Option4": "Use the aws lambda invoke command with a test event during the CIICD process.",
      "Correct Answer": 2
    },
    "Question7": {
      "Question": "A company has a front-end application that runs on four Amazon EC2 instances behind an Elastic Load Balancer (ELB) in a production environment that is provisioned by AWS Elastic Beanstalk. A developer needs to deploy and test new application code while updating the Elastic Beanstalk platform from the current version to a newer version of Node.js. The solution must result in zero downtime for the application. <br>Which solution meets these requirements?",
      "Option1": "Clone the production environment to a different platform version. Deploy the new application code, and test it. Swap the environment URLs upon verification.",
      "Option2": "Deploy the new application code in an all-at-once deployment to the existing EC2 instances. Test the code. Redeploy the previous code if verification fails.",
      "Option3": "Perform an immutable update to deploy the new application code to new EC2 instances. Serve traffic to the new instances after they pass health checks.",
      "Option4": "Use a rolling deployment for the new application code. Apply the code to a subset of EC2 instances until the tests pass. Redeploy the previous code if the tests fail.",
      "Correct Answer": 3
    },
    "Question8": {
      "Question": " A developer is creating an AWS Lambda function. The Lambda function needs an external library to connect to a third-party solution. The external library is a collection of files with a total size of 100 MB. The developer needs to make the external library available to the Lambda execution environment and reduce the Lambda package space. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a Lambda layer to store the external library. Configure the Lambda function to use the layer.",
      "Option2": "Create an Amazon S3 bucket. Upload the external library into the S3 bucket. Mount the S3 bucket folder in the Lambda function. Import the library by using the proper folder in the mount point.",
      "Option3": "Load the external library to the Lambda function's /tmp directory during deployment of the Lambda package. Import the library from the /tmp directory.",
      "Option4": "Create an Amazon Elastic File System (Amazon EFS) volume. Upload the external library to the EFS volume. Mount the EFS volume in the Lambda function. Import the library by using the proper folder in the mount point.",
      "Correct Answer": 1
    },
    "Question9": {
      "Question": "A developer is integrating Amazon ElastiCache in an application. The cache will store data from a database. The cached data must populate real-time dashboards. <br>Which caching strategy will meet these requirements?",
      "Option1": "A read-through cache",
      "Option2": "A write-behind cache",
      "Option3": "A lazy-loading cache",
      "Option4": "A write-through cache",
      "Correct Answer": 4
    },
    "Question10": {
      "Question": "A Developer is creating an AWS Serverless Application Model (AWS SAM) template. The AWS SAM template contains the definition of multiple AWS Lambda function, an Amazon S3 bucket, and an Amazon CloudFront distribution. One of the Lambda functions run on Lambda@Edge in the CloudFront distribution. The S3 bucket is configured as an origin for the CloudFront distribution. When the developer deploys the AWS SAM template in the eu-west-1 Region, the creation of the stack fails. <br>Which of the following could be the reason for this issue?",
      "Option1": "CloudFront distributions can be created only in the us-east-1 Region.",
      "Option2": "Lambda@Edge functions can be created only in the us-east-1 Region.",
      "Option3": "A single AWS SAM template cannot contain multiple Lambda functions.",
      "Option4": "The CloudFront distribution and the S3 bucket cannot be created in the same Region.",
      "Correct Answer": 2
    },
    "Question11": {
      "Question": "An organization is storing large files in Amazon S3, and is writing a web application to display meta-data about the files to end-users. Based on the metadata a user selects an object to download. The organization needs a mechanism to index the files and provide single-digit millisecond latency retrieval for the metadata. <br>What AWS service should be used to accomplish this?",
      "Option1": "Amazon DynamoDB",
      "Option2": "Amazon EC2",
      "Option3": "AWS Lambda",
      "Option4": "Amazon RDS",
      "Correct Answer": 1
    },
    "Question12": {
      "Question": "A company must deploy all its Amazon RDS DB instances by using AWS CloudFormation templates as part of AWS CodePipeline continuous integration and continuous delivery (CI/CD) automation. The primary password for the DB instance must be automatically generated as part of the deployment process. <br>Which solution will meet these requirements with the LEAST development effort?",
      "Option1": "Create am AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get the value of the secure string. Use the value to create the DB instance.",
      "Option2": "Use the AWS CodeBuild action of  CodePipeline to generate a secure string by using the following AWS CLI command: aws secretsmanager get-random-password. Pass the generated secure string as a CloudFormation parameter with the NoEcho attribute set to true. Use the parameter reference to create the DB instance.",
      "Option3": "Create an AWS Lambda-backed CloudFormation custom resource. Write Lambda code that generates a secure string. Return the value of the secure string as a data field of the custom resource response object. Use the CloudFormation Fn::GetAtt intrinsic function to get a value of the secure string. Create secrets in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored In the secret to create the DB instance.",
      "Option4": "Use the AWS::SecretsManager::Secret resource to generate a secure string. Store the secure string as a secret in AWS Secrets Manager. Use the secretsmanager dynamic reference to use the value stored in the secret to create the DB instance.",
      "Correct Answer": 4
    },
    "Question13": {
      "Question": "A developer is developing an application that uses signed requests (Signature Version 4) to call other AWS services. The developer has created a canonical request, has created the string to sign, and has calculated signing information. <br>Which methods could the developer use to complete a signed request? (Choose two.)",
      "Option1": "Add the signature to an HTTP header that is named Authorization.",
      "Option2": "Add the signature to a session cookie.",
      "Option3": "Add the signature to an HTTP header that is named Authentication.",
      "Option4": "Add the signature to a query string parameter that is named X-Amz-Signature.",
      "Option5": "Add the signature to an HTTP header that is named WWW-Authenticate.",
      "Correct Answer": 1
    },
    "Question14": {
      "Question": "A company's developer is building a static website to be deployed in Amazon S3 for a production environment. The website integrates with an Amazon Aurora PostgreSQL database by using an AWS Lambda function. The website that is deployed to production will use a Lambda alias that points to a specific version of the Lambda function. <br>The company must rotate the database credentials every 2 weeks. Lambda functions that the company deployed previously must be able to use the most recent credentials. <br>Which solution will meet these requirements?",
      "Option1": "Store the database credentials in AWS Secrets Manager. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Secrets Manager.",
      "Option2": "Include the database credentials as part of the Lambda function code. Update the credentials periodically and deploy the new Lambda function.",
      "Option3": "Use Lambda environment variables. Update the environment variables when new credentials are available.",
      "Option4": "Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation. Write code in the Lambda function to retrieve the credentials from Systems Manager Parameter Store.",
      "Correct Answer": 3
    },
    "Question15": {
      "Question": "A developer has written code for an application and wants to share it with other developers on the team to receive feedback. The shared application code needs to be stored long-term with multiple versions and batch change tracking. <br>Which AWS service should the developer use?",
      "Option1": "AWS CodeBuild",
      "Option2": "Amazon S3",
      "Option3": "AWS CodeCommit",
      "Option4": "AWS Cloud9",
      "Correct Answer": 3
    },
    "Question16": {
      "Question": "A developer is writing an application for a company. The application will be deployed on Amazon EC2 and will use an Amazon RDS for Microsoft SQL Server database. The company's security team requires that database credentials are rotated at least weekly. <br>How should the developer configure the database credentials for this application?",
      "Option1": "Create a database user. Store the user name and password in an AWS Systems Manager Parameter. Store secure string parameter. Enable rotation of the AWS Key Management Service (AWS KMS) key that is used to encrypt the parameter.",
      "Option2": "Enable IAM authentication for the database. Create a database user for use with IAM authentication. Enable password rotation.",
      "Option3": "Create a database user. Store the user name and password in an AWS Secrets Manager secret that has daily rotation enabled.",
      "Option4": "Use the EC2 user data to create a database user. Provide the user name and password in environment variables to the application.",
      "Correct Answer": 3
    },
    "Question17": {
      "Question": "A developer maintains a critical business application that uses Amazon DynamoDB as the primary data store. The DynamoDB table contains millions of documents and receives 30-60 requests each minute. The developer needs to perform processing in near-real time on the documents when they are added or updated in the DynamoDB table. <br>How can the developer implement this feature with the LEAST amount of change to the existing application code?",
      "Option1": "Set up a cron job on an Amazon EC2 instance. Run a script every hour to query the table for changes and process the documents.",
      "Option2": "Enable a DynamoDB stream on the table. Invoke an AWS Lambda function to process the documents.",
      "Option3": "Update the application to send a PutEvents request to Amazon EventBridge. Create an EventBridge rule to invoke an AWS Lambda function to process the documents.",
      "Option4": "Update the application to synchronously process the documents directly after the DynamoDB write.",
      "Correct Answer": 2
    },
    "Question18": {
      "Question": "A company has hundreds of AWS Lambda functions that the company's QA team needs to test by using the Lambda function URLs. A developer needs to configure the authentication of the Lambda functions to allow access so that the QA IAM group can invoke the Lambda functions by using the public URLs. <br>Which solution will meet these requirements?",
      "Option1": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group.",
      "Option2": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action to all the Lambda function Amazon Resource Names (ARNs). Attach the policy to the QA IAM group.",
      "Option3": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the AWS_IAM auth type. Run another script to loop on the Lambda functions to create an IAM identity-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group's Amazon Resource Name (ARN).",
      "Option4": "Create a CLI script that loops on the Lambda functions to add a Lambda function URL with the NONE auth type. Run another script to loop on the Lambda functions to create an IAM resource-based policy that allows the lambda:InvokeFunctionUrl action from the QA IAM group's Amazon Resource Name (ARN).",
      "Correct Answer": 1
    },
    "Question19": {
      "Question": "A developer needs to build an AWS CloudFormation template that self-populates the AWS Region variable that deploys the CloudFormation template. <br>What is the MOST operationally efficient way to determine the Region in which the template is being deployed?",
      "Option1": "Use the AWS::Region pseudo parameter.",
      "Option2": "Require the Region as a CloudFormation parameter.",
      "Option3": "Find the Region from the AWS::Stackld pseudo parameter by using the Fn::Split intrinsic function.",
      "Option4": "Dynamically import the Region by referencing the relevant parameter in AWS Systems Manager Parameter Store.",
      "Correct Answer": 1
    },
    "Question20": {
      "Question": " A developer is working on an ecommerce website. The developer wants to review server logs without logging in to each of the application servers individually. The website runs on multiple Amazon EC2 instances, is written in Python, and needs to be highly available. <br>How can the developer update the application to meet these requirements with MINIMUM changes?",
      "Option1": "Rewrite the application to be cloud native and to run on AWS Lambda, where the logs can be reviewed in Amazon CloudWatch.",
      "Option2": "Set up centralized logging by using Amazon OpenSearch Service, Logstash, and OpenSearch Dashboards.",
      "Option3": "Scale down the application to one larger EC2 instance where only one instance is recording logs.",
      "Option4": "Install the unified Amazon CloudWatch agent on the EC2 instances. Configure the agent to push the application logs to CloudWatch.",
      "Correct Answer": 4
    },
    "Question21": {
      "Question": "A Company has an image storage web application that runs on AWS. The company hosts the application on Amazon EC2 instances in an Auto Scaling group. The Auto Scaling group acts as the target group for an Application Load Balancer (ALB) and uses an Amazon S3 bucket to store the images for sale. The company wants to develop a feature to test system requests. The feature will direct requests to a separate target group that hosts a new beta version of the application. <br>Which solution will meet this requirement with the LEAST effort?",
      "Option1": "Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Update the test system code to use this cookie to test the beta version of the application.",
      "Option2": "Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Configure an alternate Amazon Route S3 record for the new ALB endpoint. Use the alternate Route S3 endpoint in the test system requests to test the beta version of the application.",
      "Option3": "Create a new ALB, Auto Scaling group, and target group for the beta version of the application. Use Amazon CloudFront with Lambda@Edge to determine which specific request will go to the new ALB. Use the CloudFront endpoint to send the test system requests to test the beta version of the application.",
      "Option4": "Create a new Auto Scaling group and target group for the beta version of the application. Update the ALB routing rule with a condition that looks for a cookie named version that has a value of beta. Use Amazon CloudFront with Lambda@Edge to update the test system requests to add the required cookie when the requests go to the ALB.",
      "Correct Answer": 1
    },
    "Question22": {
      "Question": "A company is providing read access to objects in an Amazon S3 bucket for different customers. The company uses IAM permissions to restrict access to the S3 bucket. The customers can access only their own files. <br>Due to a regulation requirement, the company needs to enforce encryption in transit for interactions with Amazon S3. <br>Which solution will meet these requirements?",
      "Option1": "Add a bucket policy to the S3 bucket to deny S3 actions when the aws::SecureTransport condition is equal to false.",
      "Option2": "Add a bucket policy to the S3 bucket to deny S3 actions when the s3:x-amz-acl condition is equal to public-read.",
      "Option3": "Add an IAM policy to the IAM users to enforce the usage of the AWS SDK.",
      "Option4": "Add an IAM policy to the IAM users that allows S3 when the s3:x-amz-acl condition is equal to bucket-owner-read.",
      "Correct Answer": 1
    },
    "Question23": {
      "Question": "A developer wants to use AWS Elastic Beanstalk to test a new version of an application in a test environment. <br>Which deployment method offers the FASTEST deployment?",
      "Option1": "Immutable",
      "Option2": "Rolling",
      "Option3": "Rolling with additional batch",
      "Option4": "All at once",
      "Correct Answer": 4
    },
    "Question24": {
      "Question": "A developer is updating several AWS Lambda functions and notices that all the Lambda functions share the same custom libraries. The developer wants to centralize all the libraries, update the libraries in a convenient way, and keep the libraries versioned. <br>Which solution will meet these requirements with the LEAST development effort?",
      "Option1": "Create an AWS CodeArtifact repository that contains all the custom libraries.",
      "Option2": "Create a custom container image for the Lambda functions to save all the custom libraries.",
      "Option3": "Create a Lambda layer that contains all the custom libraries.",
      "Option4": "Create an Amazon Elastic File System (Amazon EFS) file system to store all the custom libraries.",
      "Correct Answer": 3
    },
    "Question25": {
      "Question": "A company has a web application that runs on Amazon EC2 instances with a custom Amazon Machine Image (AMI). The company uses AWS CloudFormation to provision the application. The application runs in the us-east-1 Region, and the company needs to deploy the application to the us-west-1 Region. <br>An attempt to create the AWS CloudFormation stack in us-west-1 fails. An error message states that the AMI ID does not exist. A developer must resolve this error with a solution that uses the least amount of operational overhead. <br>Which solution meets these requirements?",
      "Option1": "Change the AWS CloudFormation templates for us-east-1 and us-west-1 to use an AWS AMI. Relaunch the stack for both Regions.",
      "Option2": "Copy the custom AMI from us-east-1 to us-west-1. Update the AWS CloudFormation template for us-west-1 to refer to AMI ID for the copied AMI. Relaunch the stack.",
      "Option3": "Build the custom AMI in us-west-1. Create a new AWS CloudFormation template to launch the stack in us-west-1 with the new AMI ID.",
      "Option4": "Manually deploy the application outside AWS CloudFormation in us-west-1.",
      "Correct Answer": 2
    },
    "Question26": {
      "Question": "A company is updating an application to move the backend of the application from Amazon EC2 instances to a serverless model. The application uses an Amazon RDS for MySQL DB instance and runs in a single VPC on AWS. The application and the DB instance are deployed in a private subnet in the VPC. <br>The company needs to connect AWS Lambda functions to the DB instance. <br>Which solution will meet these requirements?",
      "Option1": "Create Lambda functions inside the VPC with the ASLambdaBasicExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group.",
      "Option2": "Create Lambda functions inside the VPC with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Modify the RDS security group to allow inbound access from the Lambda security group-",
      "Option3": "Create Lambda functions with the AWSLambdaBasicExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunclion action for each Lambda function's Amazon Resource Name (ARN).",
      "Option4": "Create Lambda functions with the AWSLambdaVPCAccessExecutionRole policy attached to the Lambda execution role. Create an interface VPC endpoint for the Lambda functions. Configure the interface endpoint policy to allow the lambda:InvokeFunction action for each Lambda function's Amazon Resource Name (ARN).",
      "Correct Answer": 2
    },
    "Question27": {
      "Question": "A company stores its data in data tables in a series of Amazon S3 buckets. The company received an alert that customer credit card information might have been exposed in a data table on one of the company's public applications. A developer needs to identify all potential exposures within the application environment <br>Which solution will meet these requirements?",
      "Option1": "Use Amazon Athena to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Personal finding type.",
      "Option2": "Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.",
      "Option3": "Use Amazon Macie to run a job on the S3 buckets that contain the affected data. Filter the findings by using the SensitiveData:S30bject/Personal finding type.",
      "Option4": "Use Amazon Athena to run a job on the 53 buckets that contain the affected data. Filter the findings by using the SensitiveData:S3Object/Financial finding type.",
      "Correct Answer": 2
    },
    "Question28": {
      "Question": "An ecommerce website uses an AWS Lambda function and an Amazon RDS for MySQL database for an order fulfillment service. The service needs to return order confirmation immediately. During a marketing campaign that caused an increase in the number of orders, the website's operations team noticed errors for 'too many connections' from Amazon RDS. However, the RDS DB cluster metrics are healthy. CPU and memory capacity are still available. <br>What should a developer do to resolve the errors?",
      "Option1": "Initialize the database connection outside the handler function. Increase the max_user_connections value on the parameter group of the DB cluster. Restart the DB cluster.",
      "Option2": "Initialize the database connection outside the handler function. Use RDS Proxy instead of connecting directly to the DB cluster.",
      "Option3": "Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function's concurrency to a value that equals the number of available database connections.",
      "Option4": "Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to queue the orders. Ingest the orders into the database. Set the Lambda function's concurrency to a value that is less than the number of available database connections.",
      "Correct Answer": 2
    },
    "Question29": {
      "Question": "A social media application uses the AWS SDK for JavaScript on the frontend to get user credentials from AWS Security Token Service (AWS STS). The application stores its assets in an Amazon S3 bucket. The application serves its content by using an Amazon CloudFront distribution with the origin set to the S3 bucket. <br>The credentials for the role that the application assumes to make the SDK calls are stored in plaintext in a JSON file within the application code. The developer needs to implement a solution that will allow the application to get user credentials without having any credentials hardcoded in the application code. <br>Which solution will meet these requirements?",
      "Option1": "Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Add permissions to the function's execution role to allow the function to access AS STS. Move all SDK calls from the frontend into the function.",
      "Option2": "Add a CloudFront function to the distribution. Invoke the function on viewer request. Add permissions to the function's execution role to allow the function to access AWS STS. Move all SDK calls from the frontend into the function.",
      "Option3": "Add a Lambda@Edge function to the distribution. Invoke the function on viewer request. Move the credentials from the JSON file into the function. Move all SDK calls from the frontend into the function.",
      "Option4": "Add a CloudFront function to the distribution. Invoke the function on viewer request. Move the credentials Trom the JSON Tire into the function. Move all SDK calls from the frontend into the function.",
      "Correct Answer": 1
    },
    "Question30": {
      "Question": "A developer is creating an application. New users of the application must be able to create an account and register by using their own social media accounts. <br>Which AWS service or resource should the developer use to meet these requirements?",
      "Option1": "IAM role",
      "Option2": "Amazon Cognito identity pools",
      "Option3": "Amazon Cognito user pools",
      "Option4": "AWS Directory Service",
      "Correct Answer": 3
    },
    "Question31": {
      "Question": "A company uses AWS Lambda functions and an Amazon S3 trigger to process images into an S3 bucket A development team set up multiple environments in a single AWS account. <br>After a recent production deployment, the development team observed that the development S3 buckets invoked the production environment Lambda functions. These invocations caused unwanted execution of development S3 files by using production Lambda functions. The development team must prevent these invocations. The team must follow security best practices. <br>Which solution will meet these requirements?",
      "Option1": "Update the Lambda execution role for the production Lambda function to add a policy that allows the execution role to read from only the production environment S3 bucket.",
      "Option2": "Move the development and production environments into separate AWS accounts. Add a resource policy to each Lambda function to allow only S3 buckets that are within the same account to invoke the function.",
      "Option3": "Add a resource policy to the production Lambda function to allow only the production environment S3 bucket to invoke the function.",
      "Option4": "Move the development and production environments into separate AWS accounts. Update the Lambda execution role for each function to add a policy that allows the execution role to read from the S3 bucket that is within the same account.",
      "Correct Answer": 2
    },
    "Question32": {
      "Question": "A company has an AWS Lambda function that processes incoming requests from an Amazon API Gateway API. The API calls the Lambda function by using a Lambda alias. A developer updated the Lambda function code to handle more details related to the incoming requests. The developer wants to deploy the new Lambda function for more testing by other developers with no impact to customers that use the API <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create a new version of the Lambda function. Create a new stage on API Gateway with integration to the new Lambda version. Use the new API Gateway stage to test the Lambda function.",
      "Option2": "Update the existing Lambda alias used by API Gateway to a weighted alias. Add the new Lambda version as an additional Lambda function with a weight of 10%. Use the existing API Gateway stage for testing.",
      "Option3": "Create a new version of the Lambda function. Create and deploy a second Lambda function to filter incoming requests from API Gateway. If the filtering Lambda function detects a test request, the filtering Lambda function will invoke the new Lambda version of the code. For other requests, the filtering Lambda function will invoke the old Lambda version. Update the API Gateway API to use the filtering Lambda function.",
      "Option4": "Create a new version of the Lambda function. Create a new API Gateway API for testing purposes. Update the integration of the new API with the new Lambda version. Use the new API for testing.",
      "Correct Answer": 1
    },
    "Question33": {
      "Question": "A developer is creating an AWS Lambda function in VPC mode. An Amazon S3 event will invoke the Lambda function when an object is uploaded into an S3 bucket. The Lambda function will process the object and produce some analytic results that will be recorded into a file. Each processed object will also generate a log entry that will be recorded into a file. <br>Other Lambda functions, AWS services, and on-premises resources must have access to the result files and log file. Each log entry must also be appended to the same shared log file. The developer needs a solution that can share files and append results into an existing file. <br>Which solution should the developer use to meet these requirements?",
      "Option1": "Create an Amazon Elastic File System (Amazon EFS) file system. Mount the EFS file system in Lambda, Store the result files and log file in the mount point. Append the log entries to the log file.",
      "Option2": "Create an Amazon Elastic Block Store (Amazon EBS) Multi-Attach enabled volume. Attach the EBS volume to all Lambda functions. Update the Lambda function code to download the log file, append the log entries, and upload the modified log file to Amazon EBS.",
      "Option3": "Create a reference to the /tmp local directory. Store the result files and log file by using the directory reference. Append the log entry to the log file.",
      "Option4": "Create a reference to the /opt storage directory. Store the result files and log file by using the directory reference. Append the log entry to the log file.",
      "Correct Answer": 1
    },
    "Question34": {
      "Question": " A developer has designed an application to store incoming data as JSON files in Amazon S3 objects. Custom business logic in an AWS Lambda function then transforms the objects, and the Lambda function loads the data into an Amazon DynamoDB table. Recently, the workload has experienced sudden and significant changes in traffic. The flow of data to the DynamoDB table is becoming throttled. <br>The developer needs to implement a solution to eliminate the throttling and load the data into the DynamoDB table more consistently. <br>Which solution will meet these requirements?",
      "Option1": "Refactor the Lambda function into two functions. Configure one function to transform the data and one function to load the data into the DynamoDB table. Create an Amazon Simple Queue Service (Amazon SQS) queue in between the functions to hold the items as messages and to invoke the second function.",
      "Option2": "Turn on auto scaling for the DynamoDB table. Use Amazon CloudWatch to monitor the table's read and write capacity metrics and to track consumed capacity.",
      "Option3": "Create an alias for the Lambda function. Configure provisioned concurrency for the application to use.",
      "Option4": "Refactor the Lambda function into two functions. Configure one function to store the data in the DynamoDB table. Configure the second function to process the data and update the items after the data is stored in DvnamoDB. Create a DvnamoDB stream to invoke the second function after the data is stored.",
      "Correct Answer": 1
    },
    "Question35": {
      "Question": "A developer is creating a service that uses an Amazon S3 bucket for image uploads. The service will use an AWS Lambda function to create a thumbnail of each image. Each time an image is uploaded, the service needs to send an email notification and create the thumbnail. The developer needs to configure the image processing and email notifications setup. <br>Which solution will meet these requirements?",
      "Option1": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an email notification subscription to the SNS topic.",
      "Option2": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure S3 event notifications with a destination of the SNS topic. Subscribe the Lambda function to the SNS topic. Create an Amazon Simple Queue Service (Amazon SQS) queue. Subscribe the SQS queue to the SNS topic. Create an email notification subscription to the SQS queue.",
      "Option3": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Configure S3 event notifications with a destination of the SQS queue. Subscribe the Lambda function to the SQS queue. Create an email notification subscription to the SOS queue.",
      "Option4": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Send S3 event notifications to Amazon EventBridge. Create an EventBridge rule that runs the Lambda function when images are uploaded to the S3 bucket. Create an EventBridge rule that sends notifications to the SQS queue. Create an email notification subscription to the SOS queue.",
      "Correct Answer": 1
    },
    "Question36": {
      "Question": "A developer is leveraging a Border Gateway Protocol (BGP)-based AWS VPN connection to connect from on-premises to Amazon EC2 instances in the developer's account. The developer is able to access an EC2 instance in subnet A, but is unable to access an EC2 instance in subnet B in the same VPC. <br>Which logs can the developer use to verify whether the traffic is reaching subnet B?",
      "Option1": "VPN logs",
      "Option2": "BGP logs",
      "Option3": "VPC Flow Logs",
      "Option4": "AWS CloudTrail logs",
      "Correct Answer": 3
    },
    "Question37": {
      "Question": "A developer has written an application that runs on Amazon EC2 instances. The developer is adding functionality for the application to write objects to an Amazon S3 bucket. <br>Which policy must the developer modify to allow the instances to write these objects?",
      "Option1": "The IAM policy that is attached to the EC2 instance profile role",
      "Option2": "The session policy that is applied to the EC2 instance role session",
      "Option3": "The AWS Key Management Service (AWS KMS) key policy that is attached to the EC2 instance profile role",
      "Option4": "The Amazon VPC endpoint policy",
      "Correct Answer": 1
    },
    "Question38": {
      "Question": "A developer is building an application that uses Amazon DynamoDB. The developer wants to retrieve multiple specific items from the database with a single API call. <br>Which DynamoDB API call will meet these requirements with the MINIMUM impact on the database?",
      "Option1": "BatchGetItem",
      "Option2": "Getltem",
      "Option3": "Scan",
      "Option4": "Query",
      "Correct Answer": 1
    },
    "Question39": {
      "Question": "An e-commerce web application that shares session state on-premises is being migrated to AWS. The application must be fault tolerant, natively highly scalable, and any service interruption should not affect the user experience. <br>What is the best option to store the session state?",
      "Option1": "Store the session state in Amazon ElastiCache.",
      "Option2": "Store the session state in Amazon CloudFront.",
      "Option3": "Store the session state in Amazon S3.",
      "Option4": "Enable session stickiness using elastic load balancers.",
      "Correct Answer": 1
    },
    "Question40": {
      "Question": "A company needs to develop a proof of concept for a web service application. The application will show the weather forecast for one of the company's office locations. The application will provide a REST endpoint that clients can call. Where possible, the application should use caching features provided by AWS to limit the number of requests to the backend service. The application backend will receive a small amount of traffic only during testing. <br>Which approach should the developer take to provide the REST endpoint MOST cost-effectively?",
      "Option1": "Create a container image. Deploy the container image by using Amazon Elastic Kubernetes Service (Amazon EKS). Expose the functionality by using Amazon API Gateway.",
      "Option2": "Create an AWS Lambda function by using the AWS Serverless Application Model (AWS SAM). Expose the Lambda functionality by using Amazon API Gateway.",
      "Option3": "Create a container image. Deploy the container image by using Amazon Elastic Container Service (Amazon ECS). Expose the functionality by using Amazon API Gateway.",
      "Option4": "Create a microservices application. Deploy the application to AWS Elastic Beanstalk. Expose the AWS Lambda functionality by using an Application Load Balancer.",
      "Correct Answer": 3
    },
    "Question41": {
      "Question": "A company moved some of its secure files to a private Amazon S3 bucket that has no public access. The company wants to develop a serverless application that gives its employees the ability to log in and securely share the files with other users. <br>Which AWS feature should the company use to share and access the files securely?",
      "Option1": "Amazon Cognito user pool",
      "Option2": "S3 presigned URLs",
      "Option3": "S3 bucket policy",
      "Option4": "Amazon Cognito identity pool",
      "Correct Answer": 1
    },
    "Question42": {
      "Question": "A company is using an Amazon API Gateway REST API endpoint as a webhook to publish events from an on-premises source control management (SCM) system to Amazon EventBridge. The company has configured an EventBridge rule to listen for the events and to control application deployment in a central AWS account. The company needs to receive the same events across multiple receiver AWS accounts. <br>How can a developer meet these requirements without changing the configuration of the SCM system?",
      "Option1": "Deploy the API Gateway REST API to all the required AWS accounts. Use the same custom domain name for all the gateway endpoints so that a single SCM webhook can be used for all events from all accounts.",
      "Option2": "Deploy the API Gateway REST API to all the receiver AWS accounts. Create as many SCM webhooks as the number of AWS accounts.",
      "Option3": "Grant permission to the central AWS account for EventBridge to access the receiver AWS accounts. Add an EventBridge event bus on the receiver AWS accounts as the targets to the existing EventBridge rule.",
      "Option4": "Convert the API Gateway type from REST API to HTTP API.",
      "Correct Answer": 1
    },
    "Question43": {
      "Question": "A company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. <br>What is the simplest way to do this?",
      "Option1": "Write a script that deletes old records; schedule the script as a cron job on an Amazon EC2 instance.",
      "Option2": "Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.",
      "Option3": "Each day, create a new table to hold session data; delete the previous day's table.",
      "Option4": "Add an attribute with the expiration time; name the attribute ItemExpiration.",
      "Correct Answer": 1
    },
    "Question44": {
      "Question": "A company's new mobile app uses Amazon API Gateway. As the development team completes a new release of its APIs, a developer must safely and transparently roll out the API change. <br>What is the SIMPLEST solution for the developer to use for rolling out the new API version to a limited number of users through API Gateway?",
      "Option1": "Create a new API in API Gateway. Direct a portion of the traffic to the new API using an Amazon Route S3 weighted routing policy.",
      "Option2": "Validate the new API version and promote it to production during the window of lowest expected utilization.",
      "Option3": "Implement an Amazon CloudWatch alarm to trigger a rollback if the observed HTTP 500 status code rate exceeds a predetermined threshold.",
      "Option4": "Use the canary release deployment option in API Gateway. Direct a percentage of the API traffic using the canarySettings setting.",
      "Correct Answer": 2
    },
    "Question45": {
      "Question": "A developer is implementing an AWS Cloud Development Kit (AWS CDK) serverless application. <br>The developer will provision several AWS Lambda functions and Amazon API Gateway APIs during AWS CloudFormation stack creation. The developer's workstation has the AWS Serverless Application Model (AWS SAM) and the AWS CDK installed locally. <br>How can the developer test a specific Lambda function locally?.",
      "Option1": "Run the sam package and sam deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function.",
      "Option2": "Run the cdk synth and cdk deploy commands. Create a Lambda test event from the AWS Management Console. Test the Lambda function.",
      "Option3": "Run the cdk synth and sam local invoke commands with the function construct identifier and the path to the synthesized CloudFormation template.",
      "Option4": "Run the cdk synth and sam local start-lambda commands with the function construct identifier and the path to the synthesized CloudFormation template.",
      "Correct Answer": 2
    },
    "Question46": {
      "Question": "A developer is creating a Ruby application and needs to automate the deployment, scaling, and management of an environment without requiring knowledge of the underlying infrastructure. <br>Which service would best accomplish this task?",
      "Option1": "AWS CodeDeploy",
      "Option2": "AWS Cloud Formation",
      "Option3": "AWS OpsWorks",
      "Option4": "AWS Elastic Beanstalk",
      "Correct Answer": 3
    },
    "Question47": {
      "Question": "A developer has created an AWS Lambda function to provide notification through Amazon Simple Notification Service (Amazon SNS) whenever a file is uploaded to Amazon S3 that is larger than 50 MB. The developer has deployed and tested the Lambda function by using the CLI. However, when the event notification is added to the S3 bucket and a 3,000 MB file is uploaded, the Lambda function does not launch.",
      "Option1": "Which of the following is a possible reason for the Lambda function's inability to launch?",
      "Option2": "The S3 event notification does not activate for files that are larger than 1,000 MB.",
      "Option3": "The resource-based policy for the Lambda function does not have the required permissions to be invoked by Amazon S3.",
      "Option4": "Lambda functions cannot be invoked directly from an S3 event.",
      "Option5": "The S3 bucket needs to be made public.",
      "Correct Answer": 2
    },
    "Question48": {
      "Question": "A developer is building a highly secure healthcare application using serverless components. This application requires writing temporary data to / tmp storage on an AWS Lambda function. <br>How should the developer encrypt this data?",
      "Option1": "Enable Amazon EBS volume encryption with an AWS KMS key in the Lambda function configuration so that all storage attached to the Lambda function is encrypted.",
      "Option2": "Set up the Lambda function with a role and key policy to access an AWS KMS key. Use the key to generate a data key used to encrypt all data prior to writing to / tmp storage.",
      "Option3": "Use OpenSSL to generate a symmetric encryption key on Lambda startup. Use this key to encrypt the data prior to writing to /tmp.",
      "Option4": "Use an on-premises hardware security module (HS) to generate keys, where the Lambda function requests a data key from the HSM and uses that to encrypt data on all requests to the function.",
      "Correct Answer": 4
    },
    "Question49": {
      "Question": "A company hosts a batch processing application on AWS Elastic Beanstalk with instances that run the most recent version of Amazon Linux. The application sorts and processes large datasets. <br>In recent weeks, the application's performance has decreased significantly during a peak period for traffic. A developer suspects that the application issues are related to the memory usage. The developer checks the Elastic Beanstalk console and notices that memory usage is not being tracked.",
      "Option1": "How should the developer gather more information about the application performance issues?",
      "Option2": "Configure the Amazon CloudWatch agent to push logs to Amazon CloudWatch Logs by using port 443.",
      "Option3": "Configure the Elastic Beanstalk ebextensions directory to track the memory usage of the instances.",
      "Option4": "Configure the Amazon CloudWatch agent to track the memory usage of the instances.",
      "Option5": "Configure an Amazon CloudWatch dashboard to track the memory usage of the instances.",
      "Correct Answer": 3
    },
    "Question50": {
      "Question": "A company is planning to use AWS CodeDeploy to deploy an application to Amazon Elastic Container Service (Amazon ECS). During the deployment of a new version of the application, the company initially must expose only 10% of live traffic to the new version of the deployed application. <br>Then, after 15 minutes elapse, the company must route all the remaining live traffic to the new version of the deployed application. <br>Which CodeDeploy predefined configuration will meet these requirements?",
      "Option1": "CodeDeployDefault.ECSCanary10Percent15Minutes",
      "Option2": "CodeDeployDefault.LambdaCanary10Percent5Minutes",
      "Option3": "CodeDeployDefault.LambdaCanary10Percent|15Minutes",
      "Option4": "CodeDeployDefault.ECSLinear10PercentEvery1Minutes",
      "Correct Answer": 4
    },
    "Question51": {
      "Question": "A developer wants to debug an application by searching and filtering log data. The application logs are stored in Amazon CloudWatch Logs. The developer creates a new metric filter to count exceptions in the application logs. However, no results are returned from the logs. <br>What is the reason that no filtered results are being returned?",
      "Option1": "A setup of the Amazon CloudWatch interface VPC endpoint is required for filtering the CloudWatch Logs in the VPC.",
      "Option2": "CloudWatch Logs only publishes metric data for events that happen after the filter is created.",
      "Option3": "The log group for CloudWatch Logs should be first streamed to Amazon OpenSearch Service before metric filtering returns the results.",
      "Option4": "Metric data points for logs groups can be filtered only after they are exported to an Amazon S3 bucket.",
      "Correct Answer": 2
    },
    "Question52": {
      "Question": "Company A has an S3 bucket containing premier content that they intend to make available to only paid subscribers of their website. The S3 bucket currently has default permissions of all objects being private to prevent inadvertent exposure of the premier content to non-paying website visitors. <br>How can Company A provide only paid subscribers the ability to download a premier content file in the S3 bucket?",
      "Option1": "Apply a bucket policy that grants anonymous users to download the content from the S3 bucket",
      "Option2": "Generate a pre-signed object URL for the premier content file when a paid subscriber requests a download",
      "Option3": "Add a bucket policy that requires Multi-Factor Authentication for requests to access the $3 bucket objects",
      "Option4": "Enable server side encryption on the S3 bucket for data protection against the non-paying website visitors",
      "Correct Answer": 2
    },
    "Question53": {
      "Question": "An application under development is required to store hundreds of video files. The data must be encrypted within the application prior to storage, with a unique key for each video file. <br>How should the developer code the application?",
      "Option1": "Use the KMS Encrypt API to encrypt the data. Store the encrypted data key and data.",
      "Option2": "Use a cryptography library to generate an encryption key for the application. Use the encryption key to encrypt the data. Store the encrypted data.",
      "Option3": "Use the KMS GenerateDataKey API to get a data key. Encrypt the data with the data key. Store the encrypted data key and data.",
      "Option4": "Upload the data to an S3 bucket using server side-encryption with an AWS KMS key.",
      "Correct Answer": 3
    },
    "Question54": {
      "Question": "A developer deployed an application to an Amazon EC2 instance. The application needs to know the public IPv4 address of the instance. <br>How can the application find this information?",
      "Option1": "Query the instance metadata from http://169.254.169.254/latest/meta-data/.",
      "Option2": "Query the instance user data from http://169.254.169.254/latest/user-data/.",
      "Option3": "Query the Amazon Machine Image (AMI) information from http://169.254.169.254/latest/meta-data/ami/.",
      "Option4": "Check the hosts file of the operating system.",
      "Correct Answer": 1
    },
    "Question55": {
      "Question": "A developer is writing unit tests for a new application that will be deployed on AWS. The developer wants to validate all pull requests with unit tests and merge the code with the main branch only when all tests pass. <br>The developer stores the code in AWS CodeCommit and sets up AWS CodeBuild to run the unit tests. <br>The developer creates an AWS Lambda function to start the CodeBuild task. The developer needs to identify the CodeCommit events in an Amazon EventBridge event that can invoke the Lambda function when a pull request is created or updated. <br>Which CodeCommit event will meet these requirements?",
      "Option1": "{ <br> 'source': ['aws.codecommit'], <br> 'detail': { <br> 'event': ['pullRequestMergeStatusUpdated'] <br> } <br>}",
      "Option2": "{ <br> 'source': ['aws.codecommit'], <br> 'detail': { <br> 'event': ['pullRequestApprovalRuleCreated'] <br> } <br>}",
      "Option3": "{ <br> 'source': ['aws.codecommit'], <br> 'detail': { <br> 'event': ['pullRequestSourceBranchUpdated', 'pullRequestCreated'] <br> } <br>}",
      "Option4": "{ <br> 'source': ['aws.codecommit'], <br> 'detail': { <br> 'event': ['pullRequestUpdated', 'pullRequestSourceBranchCreated'] <br> } <br>}",
      "Correct Answer": 3
    },
    "Question56": {
      "Question": "A developer created an AWS Lambda function that accesses resources in a VPC. The Lambda function polls an Amazon Simple Queue Service (Amazon SQS) queue for new messages through a VPC endpoint. Then the function calculates a rolling average of the numeric values that are contained in the messages. After initial tests of the Lambda function, the developer found that the value of the rolling average that the function returned was not accurate. <br>How can the developer ensure that the function calculates an accurate rolling average?",
      "Option1": "Set the function's reserved concurrency to 1. Calculate the rolling average in the function. Store the calculated rolling average in Amazon ElastiCache.",
      "Option2": "Modify the function to store the values in Amazon ElastiCache. When the function initializes, use the previous values from the cache to calculate the rolling average.",
      "Option3": "Set the function's provisioned concurrency to 1. Calculate the rolling average in the function. Store the calculated rolling average in Amazon ElastiCache.",
      "Option4": "Modify the function to store the values in the function's layers. When the function initializes, use the previously stored values to calculate the rolling average.",
      "Correct Answer": 2
    },
    "Question57": {
      "Question": "A company runs an application on AWS. The company deployed the application on Amazon EC2 instances. The application stores data on Amazon Aurora. <br>The application recently logged multiple application-specific custom DECRYP_ERROR errors to Amazon CloudWatch logs. The company did not detect the issue until the automated tests that run every 30 minutes failed. A developer must implement a solution that will monitor for the custom errors and alert a development team in real time when these errors occur in the production environment. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Configure the application to create a custom metric and to push the metric to CloudWatch. Create an AWS CloudTrail alarm. Configure the CloudTrail alarm to use an Amazon Simple Notification Service (Amazon SNS) topic to send notifications.",
      "Option2": "Create an AWS Lambda function to run every 5 minutes to scan the CloudWatch logs for the keyword DECRYP_ERROR. Configure the Lambda function to use Amazon Simple Notification Service (Amazon SNS) to send a notification.",
      "Option3": "Use Amazon CloudWatch Logs to create a metric filter that has a filter pattern for DECRYP_ERROR. Create a CloudWatch alarm on this metric for a threshold >=1. Configure the alarm to send Amazon Simple Notification Service (Amazon SNS) notifications.",
      "Option4": "Install the CloudWatch unified agent on the EC2 instance. Configure the application to generate a metric for the keyword DECRYP_ERROR errors. Configure the agent to send Amazon Simple Notification Service (Amazon SNS) notifications.",
      "Correct Answer": 3   
    },
    "Question58": {
      "Question": "A developer creates a VPC named VPC-A that has public and private subnets. The developer also creates an Amazon RDS database inside the private subnet of VPC-A. To perform some queries, the developer creates an AWS Lambda function in the default VPC. The Lambda function has code to access the RDS database. When the Lambda function runs, an error message indicates that the function cannot connect to the RDS database. <br>How can the developer solve this problem?",
      "Option1": "Modify the RDS security group. Add a rule to allow traffic from all the ports from the VPC CIDR block.",
      "Option2": "Redeploy the Lambda function in the same subnet as the RDS instance. Ensure that the RDS security group allows traffic from the Lambda function.",
      "Option3": "Create a security group for the Lambda function. Add a new rule in the RDS security group to allow traffic from the new Lambda security group.",
      "Option4": "Create an IAM role. Attach a policy that allows access to the RDS database. Attach the role to the Lambda function.",
      "Correct Answer": 3
    },
    "Question59": {
      "Question": "A developer is working on an existing application that uses Amazon DynamoDB as its data store. The DynamoDB table has the following attributes: partNumber (partition key), vendor (sort key), description, productFamily, and productType. When the developer analyzes the usage patterns, the developer notices that there are application modules that frequently look for a list of products based on the productFamily and product Type attributes. <br>The developer wants to make changes to the application to improve performance of the query operations. <br>Which solution will meet these requirements?",
      "Option1": "Create a global secondary index (GSI) with productFamily as the partition key and productType as the sort key.",
      "Option2": "Create a local secondary index (LSI) with productFamily as the partition key and product Type as the sort key.",
      "Option3": "Recreate the table. Add partNumber as the partition key and vendor as the sort key. During table creation, add a local secondary index (LSI) with productFamily as the partition key and productType as the sort key.",
      "Option4": "Update the queries to use Scan operations with productFamily as the partition key and productType as the sort key.",
      "Correct Answer": 1
    },
    "Question60": {
      "Question": "An engineer created an A/B test of a new feature on an Amazon CloudWatch Evidently project. The engineer configured two variations of the feature (Variation A and Variation B) for the test. The engineer wants to work exclusively with Variation A. The engineer needs to make updates so that Variation A is the only variation that appears when the engineer hits the application's endpoint. <br>Which solution will meet this requirement?",
      "Option1": "Add an override to the feature. Set the identifier of the override to the engineer's user ID. Set the variation to Variation A.",
      "Option2": "Add an override to the feature. Set the identifier of the override to Variation A. Set the variation to 100%.",
      "Option3": "Add an experiment to the project. Set the identifier of the experiment to Variation B. Set the variation to 0%.",
      "Option4": "Add an experiment to the project. Set the identifier of the experiment to the AWS account's account ID.Set the variation to Variation A.",
      "Correct Answer": 1
    },
    "Question61": {
      "Question": " A developer is creating a mobile application that will not require users to log in. <br>What is the MOST efficient method to grant users access to AWS resources?",
      "Option1": "Use an identity provider to securely authenticate with the application.",
      "Option2": "Create an AWS Lambda function to create an IAM user when a user accesses the application.",
      "Option3": "Create credentials using AWS KMS and apply these credentials to users when using the application.",
      "Option4": "Use Amazon Cognito to associate unauthenticated users with an IAM role that has limited access to resources.",
      "Correct Answer": 4
    },
    "Question62": {
      "Question": " A company is building a serverless application that uses AWS Lambda functions. The company needs to create a set of test events to test Lambda functions in a development environment. The test events will be created once and then will be used by all the developers in an IAM developer group. The test events must be editable by any of the IAM users in the IAM developer group. <br>Which solution will meet these requirements?",
      "Option1": "Create and store the test events in Amazon S3 as JSON objects. Allow S3 bucket access to all IAM users.",
      "Option2": "Create the test events. Configure the event sharing settings to make the test events shareable.",
      "Option3": "Create and store the test events in Amazon DynamoDB. Allow access to DynamoDB by using IAM roles.",
      "Option4": "Create the test events. Configure the event sharing settings to make the test events private.",
      "Correct Answer": 2
    },
    "Question63": {
      "Question": "A company has installed smart meters in all its customer locations. The smart meters measure power usage at 1-minute intervals and send the usage readings to a remote endpoint for collection. <br>The company needs to create an endpoint that will receive the smart meter readings and store the readings in a database. The company wants to store the location ID and timestamp information. <br>The company wants to give its customers low-latency access to their current usage and historical usage on demand. The company expects demand to increase significantly. The solution must not impact performance or include downtime while scaling. <br>Which solution will meet these requirements MOST cost-effectively?",
      "Option1": "Store the smart meter readings in an Amazon RDS database. Create an index on the location ID and timestamp columns. Use the columns to filter on the customers' data.",
      "Option2": "Store the smart meter readings in an Amazon DynamoDB table. Create a composite key by using the location ID and timestamp columns. Use the columns to filter on the customers' data.",
      "Option3": "Store the smart meter readings in Amazon ElastiCache for Redis. Create a SortedSet key by using the location ID and timestamp columns. Use the columns to filter on the customers' data.",
      "Option4": "Store the smart meter readings in Amazon S3. Partition the data by using the location ID and timestamp columns. Use Amazon Athena to filter on the customers' data.",
      "Correct Answer": 2
    },
    "Question64": {
      "Question": "A company has a critical application on AWS. The application exposes an HTTP API by using Amazon API Gateway. The API is integrated with an AWS Lambda function. The application stores data in an Amazon RDS for MySQL DB instance with 2 virtual CPUs (vCPUs) and 64 GB of RAM. <br>Customers have reported that some of the API calls return HTTP 500 Internal Server Error responses. <br>Amazon CloudWatch Logs shows errors for 'too many connections.' The errors occur during peak usage times that are unpredictable. <br>The company needs to make the application resilient. The database cannot be down outside of scheduled maintenance hours. <br>Which solution will meet these requirements?",
      "Option1": "Decrease the number of vPUs for the DB instance. Increase the max_connections setting.",
      "Option2": "Use Amazon RDS Proxy to create a proxy that connects to the DB instance. Update the Lambda function to connect to the proxy.",
      "Option3": "Add a CloudWatch alarm that changes the DB instance class when the number of connections increases to more than 1,000.",
      "Option4": "Add an Amazon EventBridge rule that increases the max_connections setting of the DB instance when CPU utilization is above 75%.",
      "Correct Answer": 2
    },
    "Question65": {
      "Question": "A developer is building a new application on AWS. The application uses an AWS Lambda function that retrieves information from an Amazon DynamoDB table. The developer hard coded the DynamoDB table name into the Lambda function code. The table name might change over time. The developer does not want to modify the Lambda code if the table name changes. <br>Which solution will meet these requirements MOST efficiently?",
      "Option1": "Create a Lambda environment variable to store the table name. Use the standard method for the programming language to retrieve the variable.",
      "Option2": "Store the table name in a file. Store the file in the /tmp folder. Use the SDK for the programming language to retrieve the table name.",
      "Option3": "Create a file to store the table name. Zip the file and upload the file to the Lambda layer. Use the SDK for the programming language to retrieve the table name.",
      "Option4": "Create a global variable that is outside the handler in the Lambda function to store the table name.",
      "Correct Answer": 1
    },
    "Question66": {
      "Question": "A developer is migrating some features from a legacy monolithic application to use AWS Lambda functions instead. The application currently stores data in an Amazon Aurora DB cluster that runs in private subnets in a VPC. The AWS account has one VPC deployed. The Lambda functions and the DB cluster are deployed in the same AWS Region in the same AWS account. <br>The developer needs to ensure that the Lambda functions can securely access the DB cluster without crossing the public internet. <br>Which solution will meet these requirements?",
      "Option1": "Configure the DB cluster's public access setting to Yes.",
      "Option2": "Configure an Amazon RDS database proxy for he Lambda functions.",
      "Option3": "Configure a NAT gateway and a security group for the Lambda functions.",
      "Option4": "Configure the VPC, subnets, and a security group for the Lambda functions.",
      "Correct Answer": 4
    },
    "Question67": {
      "Question": "A developer is incorporating AWS X-Ray into an application that handles personal identifiable information (PIl). The application is hosted on Amazon EC2 instances. The application trace messages include encrypted PIl and go to Amazon CloudWatch. The developer needs to ensure that no PIl goes outside of the EC2 instances. <br>Which solution will meet these requirements?",
      "Option1": "Manually instrument the X-Ray SDK in the application code.",
      "Option2": "Use the X-Ray auto-instrumentation agent.",
      "Option3": "Use Amazon Macie to detect and hide PIl. Call the X-Ray API from AWS Lambda.",
      "Option4": "Use AWS Distro for Open Telemetry.",
      "Correct Answer": 1
    },
    "Question68": {
      "Question": " A company has deployed an application on AWS Elastic Beanstalk. The company has configured the Auto Scaling group that is associated with the Elastic Beanstalk environment to have five Amazon EC2 instances. If the capacity is fewer than four EC2 instances during the deployment, application performance degrades. The company is using the all-at-once deployment policy. <br>What is the MOST cost-effective way to solve the deployment issue?",
      "Option1": "Change the Auto Scaling group to six desired instances.",
      "Option2": "Change the deployment policy to traffic splitting. Specify an evaluation time of 1 hour.",
      "Option3": "Change the deployment policy to rolling with additional batch. Specify a batch size of 1.",
      "Option4": "Change the deployment policy to rolling. Specify a batch size of 2.",
      "Correct Answer": 3
    },
    "Question69": {
      "Question": "A company is building a web application on AWS. When a customer sends a request, the application will generate reports and then make the reports available to the customer within one hour. <br>Reports should be accessible to the customer for 8 hours. Some reports are larger than 1 MB. Each report is unique to the customer. The application should delete all reports that are older than 2 days. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "A. Generate the reports and then store the reports as Amazon DynamoDB items that have a specified TTL. Generate a URL that retrieves the reports from DynamoDB. Provide the URL to customers through the web application.",
      "Option2": "Generate the reports and then store the reports in an Amazon S3 bucket that uses server-side encryption. Attach the reports to an Amazon Simple Notification Service (Amazon SNS) message. Subscribe the customer to email notifications from Amazon SNS.",
      "Option3": "C. Generate the reports and then store the reports in an Amazon $3 bucket that uses server-side encryption. Generate a presigned URL that contains an expiration date Provide the URL to customers through the web application. Add S3 Lifecycle configuration rules to the S3 bucket to delete old reports.",
      "Option4": "Generate the reports and then store the reports in an Amazon RDS database with a date stamp. Generate an URL that retrieves the reports from the RDS database. Provide the URL to customers through the web application. Schedule an hourly AWS Lambda function to delete database records that have expired date stamps.",
      "Correct Answer": 3
    },
    "Question70": {
      "Question": "An ecommerce company is using an AWS Lambda function behind Amazon API Gateway as its application tier. To process orders during checkout, the application calls a POST API from the frontend. <br>The POST API invokes the Lambda function asynchronously. In rare situations, the application has not processed orders. The Lambda application logs show no errors or failures. <br>What should a developer do to solve this problem?",
      "Option1": "Inspect the frontend logs for API failures. Call the POST API manually by using the requests from the log file.",
      "Option2": "Create and inspect the Lambda dead-letter queue. Troubleshoot the failed functions. Reprocess the events.",
      "Option3": "Inspect the Lambda logs in Amazon CloudWatch for possible errors. Fix the errors.",
      "Option4": "Make sure that caching is disabled for the POST API in API Gateway.",
      "Correct Answer": 2
    },
    "Question71": {
      "Question": "A developer is using AWS Amplify Hosting to build and deploy an application. The developer is receiving an increased number of bug reports from users. The developer wants to add end-to-end testing to the application to eliminate as many bugs as possible before the bugs reach production. <br>Which solution should the developer implement to meet these requirements?",
      "Option1": "Run the amplify add test command in the Amplify CLI.",
      "Option2": "Create unit tests in the application. Deploy the unit tests by using the amplify push command in the Amplify CLI.",
      "Option3": "Add a test phase to the amplify.ymi build settings for the application.",
      "Option4": "Add a test phase to the aws-exports.js file for the application.",
      "Correct Answer": 3
    },
    "Question72": {
      "Question": "A developer is testing a new tie storage application that uses an Amazon CloudFront distribution to serve content from an Amazon S3 bucket. The distribution accesses the S3 bucket by using an origin access identity (OAl). The S3 bucket's permissions explicitly deny access to all other users. <br>The application prompts users to authenticate on a login page and then uses signed cookies to allow users to access their personal storage directories. The developer has configured the distribution to use its default cache behavior with restricted viewer access and has set the origin to point to the S3 bucket. However, when the developer tries to navigate to the login page, the developer receives a 403 Forbidden error. <br>The developer needs to implement a solution to allow unauthenticated access to the login page. The solution also must keep all private content secure. <br>Which solution will meet these requirements?",
      "Option1": "Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to the path of the login page, and make viewer access unrestricted. Keep the default cache behavior's settings unchanged.",
      "Option2": "Add a second cache behavior to the distribution with the same origin as the default cache behavior. Set the path pattern for the second cache behavior to *, and make viewer access restricted. Change the default cache behavior's path pattern to the path of the login page, and make viewer access unrestricted.",
      "Option3": "Add a second origin as a failover origin to the default cache behavior. Point the failover origin to the S3 bucket. Set the path pattern for the primary origin to *, and make viewer access restricted. Set the path pattern for the failover origin to the path of the login page, and make viewer access unrestricted.",
      "Option4": "Add a bucket policy to the S3 bucket to allow read access. Set the resource on the policy to the Amazon Resource Name (ARN) of the login page object in the S3 bucket. Add a CloudFront function to the default cache behavior to redirect unauthorized requests to the login page's S3 URL.",
      "Correct Answer": 1
    },
    "Question73": {
      "Question": "A company needs to harden its container images before the images are in a running state. The company's application uses Amazon Elastic Container Registry (Amazon ECR) as an image registry. Amazon Elastic Kubernetes Service (Amazon EKS) for compute, and an AWS CodePipeline pipeline that orchestrates a continuous integration and continuous delivery (Cl/CD worktlow. <br>Dynamic application security testing occurs in the final stage of the pipeline after a new image is deployed to a development namespace in the EKS cluster. A developer needs to place an analysis stage before this deployment to analyze the container image earlier in the CI/CD pipeline. <br>Which solution will meet these requirements with the MOST operational efficiency?",
      "Option1": "Build the container image and run the docker scan command locally. Mitigate any findings before pushing changes to the source code repository. Write a pre-commit hook that enforces the use of this workflow before commit.",
      "Option2": "Create a new CodePipeline stage that occurs after the container image is built. Configure ECR basic image scanning to scan on image push. Use an AWS Lambda function as the action provider. Configure the Lambda function to check the scan results and to fail the pipeline if there are findings.",
      "Option3": "Create a new CodePipeline stage that occurs after source code has been retrieved from its repository. Run a security scanner on the latest revision of the source code. Fail the pipeline if there are findings.",
      "Option4": "Add an action to the deployment stage of the pipeline so that the action occurs before the deployment to the EKS cluster. Configure ECR basic image scanning to scan on image push. Use an AWS Lambda function as the action provider. Configure the Lambda function to check the scan results and to fail the pipeline if there are findings.",
      "Correct Answer": 2
    },
    "Question74": {
      "Question": " An application uses Lambda functions to extract metadata from files uploaded to an S3 bucket; the metadata is stored in Amazon DynamoDB. The application starts behaving unexpectedly, and the developer wants to examine the logs of the Lambda function code for errors. <br>Based on this system configuration, where would the developer find the logs?",
      "Option1": "Amazon S3",
      "Option2": "AWS CloudTrail",
      "Option3": "Amazon CloudWatch",
      "Option4": "Amazon DynamoDB",
      "Correct Answer": 3
    },
    "Question75": {
      "Question": "A developer needs to migrate an online retail application to AWS to handle an anticipated increase in traffic. The application currently runs on two servers: one server for the web application and another server for the database. The web server renders webpages and manages session state in memory. The database server hosts a MySQL database that contains order details. When traffic to the application is heavy, the memory usage for the web server approaches 100% and the application slows down considerably. <br>The developer has found that most of the memory increase and performance decrease is related to the load of managing additional user sessions. For the web server migration, the developer will use Amazon EC2 instances with an Auto Scaling group behind an Application Load Balancer. <br>Which additional set of changes should the developer make to the application to improve the application's performance?",
      "Option1": "Use an EC2 instance to host the MySQL database. Store the session data and the application data in the MySQL database.",
      "Option2": "Use Amazon ElastiCache for Memcached to store and manage the session data. Use an Amazon RDS for MySQL DB instance to store the application data.",
      "Option3": "Use Amazon ElastiCache for Memcached to store and manage the session data and the application data.",
      "Option4": "Use the EC2 instance store to manage the session data. Use an Amazon RDS for MySQL DB instance to store the application data.",
      "Correct Answer": 2
    }
  }
}
