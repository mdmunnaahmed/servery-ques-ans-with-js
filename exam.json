{
  "Exam1": {
    "id": 1,
    "quesNum": 100,
    "Question1": {
      "Question": "A company uses Amazon API Gateway to expose a set of APIs to customers. The APIs have caching enabled in API Gateway. Customers need a way to invalidate the cache for each API when they test the API. What should a developer do to give customers the ability to invalidate the API cache?",
      "Option1": "Ask the customers to use AWS credentials to call the InvalidateCache API operation.",
      "Option2": "Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to send a request that contains the Cache-Control:max-age=0 HTTP header when they make an API call.",
      "Option3": "Ask the customers to use the AWS SDK API Gateway class to invoke the InvalidateCache API operation.",
      "Option4": "Attach an InvalidateCache policy to the IAM execution role that the customers use to invoke the API. Ask the customers to add the INVALIDATE_CACHE query string parameter when they make an API call.",
      "Correct Answer": 2
    },
    "Question2": {
      "Question": "A developer is creating an AWS CloudFormation stack. The stack contains IAM resources with custom names. When the developer tries to deploy the stack, they receive an InsufficientCapabilities error. What should the developer do to resolve this issue?",
      "Option1": "Specify the CAPABILITY_AUTO_EXPAND capability in the CloudFormation stack.",
      "Option2": "Use an administrators role to deploy IAM resources with CloudFormation.",
      "Option3": "Specify the CAPABILITY_IAM capability in the CloudFormation stack.",
      "Option4": "Specify the CAPABILITY_NAMED_IAM capability in the CloudFormation stack.",
      "Correct Answer": 4
    },
    "Question3": {
      "Question": "A developer is preparing to begin development of a new version of an application. The previous version of the application is deployed in a production environment. The developer needs to deploy fixes and updates to the current version during the development of the new version of the application. The code for the new version of the application is stored in AWS CodeCommit. Which solution will meet these requirements?",
      "Option1": "From the main branch, create a feature branch for production bug fixes. Create a second feature branch from the main branch for development of the new version.",
      "Option2": "Create a Git tag of the code that is currently deployed in production. Create a Git tag for the development of the new version. Push the two tags to the CodeCommit repository.",
      "Option3": "From the main branch, create a branch of the code that is currently deployed in production. Apply an IAM policy that ensures no other users can push or merge to the branch.",
      "Option4": "Create a new CodeCommit repository for development of the new version of the application. Create a Git tag for the development of the new version.",
      "Correct Answer": 1
    },
    "Question4": {
      "Question": " A developer is building a serverless application that connects to an Amazon Aurora PostgreSQL database. The serverless application consists of hundreds of AWS Lambda functions. During every Lambda function scale out, a new database connection is made that increases database resource consumption. The developer needs to decrease the number of connections made to the database. The solution must not impact the scalability of the Lambda functions. Which solution will meet these requirements?",
      "Option1": "Configure provisioned concurrency for each Lambda function by setting the ProvisionedConcurrentExecutions parameter to 10.",
      "Option2": "Enable cluster cache management for Aurora PostgreSQL. Change the connection string of each Lambda function to point to cluster cache management.",
      "Option3": "Use Amazon RDS Proxy to create a connection pool to manage the database connections. Change the connection string of each Lambda function to reference the proxy.",
      "Option4": "Configure reserved concurrency for each Lambda function by setting the ReservedConcurrentExecutions parameter to 10.",
      "Correct Answer": 3
    },
    "Question5": {
      "Question": "A developer is setting up infrastructure by using AWS CloudFormation. If an error occurs when the resources described in the Cloud Formation template are provisioned, successfully provisioned resources must be preserved. The developer must provision and update the CloudFormation stack by using the AWS CLI. Which solution will meet these requirements?",
      "Option1": "Add an --enable-termination-protection command line option to the create-stack command and the update- stack command.",
      "Option2": "Add a --disable-rollback command line option to the create-stack command and the update-stack command.",
      "Option3": "Add a --parameters ParameterKey=Preserve Resources, ParameterValue=True command line option to the create-stack command and the update-stack command.",
      "Option4": "Add a --tags Key=Preserve Resources,Value=True command line option to the create-stack command and the update-stack command.",
      "Correct Answer": 2
    },
    "Question6": {
      "Question": "A developer is working on an application that processes operating data from loT devices. Each lot device uploads a data file once every hour to an Amazon S3 bucket. The developer wants to immediately process each data file when the data file is uploaded to Amazon S3. The developer will use an AWS Lambda function to process the data files from Amazon S3. The Lambda function is configured with the S3 bucket information where the files are uploaded. The developer wants to configure the Lambda function to immediately invoke after each data file is uploaded. Which solution will meet these requirements?",
      "Option1": "Add an asynchronous invocation to the Lambda function. Select the S3 bucket as the source.",
      "Option2": "Add an Amazon EventBridge event to the Lambda function. Select the S3 bucket as the source.",
      "Option3": "Add a trigger to the Lambda function. Select the S3 bucket as the source.",
      "Option4": "Add a layer to the Lambda function. Select the S3 bucket as the source.",
      "Correct Answer": 3
    },
    "Question7": {
      "Question": "A developer is building an application integrating an Amazon API Gateway with an AWS Lambda function. When calling the API. the developer receives the following error: Wed Nov 08 01:13:00 UTC 2017: Method completed with status: 502 What should the developer do to resolve the error?",
      "Option1": "Change the HTTP endpoint of the API to an HTTPS endpoint.",
      "Option2": "Change the format of the payload sent to the API Gateway.",
      "Option3": "Change the format of the Lambda function response to the API call.",
      "Option4": "Change the authorization header in the API call to access the Lambda function.",
      "Correct Answer": 3
    },
    "Question8": {
      "Question": "An IT department uses Amazon S3 to store sensitive images. After more than 1 year, the company moves the images into archival storage. The company rarely accesses the images, but the company wants a storage solution that maximizes resiliency. The IT department needs access to the images that have been moved to archival storage within 24 hours. Which solution will meet these requirements MOST cost-effectively?",
      "Option1": "Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.",
      "Option2": "Use S3 Standard-Infrequent Access (S3 Standard-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.",
      "Option3": "Use S3 Intelligent-Tiering to store the images. Use S3 Glacier Deep Archive with standard retrieval to store and retrieve archived images.",
      "Option4": "Use S3 One Zone-Infrequent Access (S3 One Zone-IA) to store the images. Use S3 Glacier Deep Archive with bulk retrieval to store and retrieve archived images.",
      "Correct Answer": 1
    },
    "Question9": {
      "Question": "A company has an application that stores data in Amazon RDS instances. The application periodically experiences surges of high traffic that cause performance problems. During periods of peak traffic, a developer notices a reduction in query speed in all database queries. The team's technical lead determines that a multi-threaded and scalable caching solution should be used to offload the heavy read traffic. The solution needs to improve performance. Which solution will meet these requirements with the LEAST complexity?",
      "Option1": "Use Amazon ElastiCache for Memcached to offload read requests from the main database.",
      "Option2": "Replicate the data to Amazon DynamoDSet up a DynamoDB Accelerator (DAX) cluster.",
      "Option3": "Configure the Amazon RDS instances to use Multi-AZ deployment with one standby instance. Offload read requests from the main database to the standby instance.",
      "Option4": "Use Amazon ElastiCache for Redis to offload read requests from the main database.",
      "Correct Answer": 1
    },
    "Question10": {
      "Question": "A company has a serverless application on AWS that uses a fleet of AWS Lambda functions that have aliases. The company regularly publishes new Lambda function by using an in-house deployment solution. The company wants to improve the release process and to use traffic shifting. A newly published function version should initially make available only to a fixed percentage of production users. Which solution will meet these requirements?",
      "Option1": "Configure routing on the alias of the new function by using a weighted alias.",
      "Option2": "Configure a canary deployment type for Lambda.",
      "Option3": "Configure routing on the new versions by using environment variables.",
      "Option4": "Configure a linear deployment type for Lambda.",
      "Correct Answer": 1
    },
    "Question11": {
      "Question": "A developer is creating a new REST API by using Amazon API Gateway and AWS Lambda. The development team tests the API and validates responses for the known use cases before deploying the API to the production environment. The developer wants to make the REST API available for testing by using API Gateway locally. Which AWS Serverless Application Model Command Line Interface (AWS SAM CLI) subcommand will meet these requirements?",
      "Option1": "Sam local invoke",
      "Option2": "Sam local generate-event",
      "Option3": "Sam local start-lambda",
      "Option4": "Sam local start-api",
      "Correct Answer": 4
    },
    "Question12": {
      "Question": "A developer has created an AWS Lambda function that makes queries to an Amazon Aurora MySQL DB instance. When the developer performs a test, the DB instance shows an error for too many connections. Which solution will meet these requirements with the LEAST operational effort?",
      "Option1": "Create a read replica for the DB instance. Query the replica DB instance instead of the primary DB instance.",
      "Option2": "Migrate the data to an Amazon DynamoDB database.",
      "Option3": "Configure the Amazon Aurora MySQL DB instance for Multi-AZ deployment.",
      "Option4": "Create a proxy in Amazon RDS Proxy. Query the proxy instead of the DB instance.",
      "Correct Answer": 4
    },
    "Question13": {
      "Question": "A company needs to set up secure database credentials for all its AWS Cloud resources. The company's resources include Amazon RDS DB instances, Amazon DocumentDB clusters, and Amazon Aurora DB instances. The company's security policy mandates that database credentials be encrypted at rest and rotated at a regular interval. Which solution will meet these requirements MOST securely?",
      "Option1": "Set up IAM database authentication for token-based access. Generate user tokens to provide centralized access to RDS DB instances, Amazon DocumentDB clusters, and Aurora DB instances.",
      "Option2": "Create parameters for the database credentials in AWS Systems Manager Parameter Store. Set the Type parameter to SecureString. Set up automatic rotation on the parameters.",
      "Option3": "Store the database access credentials as an encrypted Amazon S3 object in an S3 bucket. Block all public access on the S3 bucket. Use S3 server-side encryption to set up automatic rotation on the encryption key.",
      "Option4": "Create an AWS Lambda function by using the Secrets Manager Rotation Template template in the AWS Secrets Manager console. Create secrets for the database credentials in Secrets Manager. Set up secrets rotation on a schedule.",
      "Correct Answer": 4
    },
    "Question14": {
      "Question": "A company built a new application in the AWS Cloud. The company automated the bootstrapping of new resources with an Auto Scaling group by using AWS CloudFormation templates. The bootstrap scripts contain sensitive data. The company needs a solution that is integrated with CloudFormation to manage the sensitive data in the bootstrap scripts. Which solution will meet these requirements in the MOST secure way?",
      "Option1": "Put the sensitive data into a CloudFormation parameter. Encrypt the CloudFormation templates by using an AWS Key Management Service (AWS KMS) key.",
      "Option2": "Put the sensitive data into an Amazon S3 bucket. Update the CloudFormation templates to download the object from Amazon S3 during bootstrap.",
      "Option3": "Put the sensitive data into AWS Systems Manager Parameter Store as a secure string parameter. Update the CloudFormation templates to use dynamic references to specify template values.",
      "Option4": "Put the sensitive data into Amazon Elastic File System (Amazon EFS). Enforce EFS encryption after file system creation. Update the CloudFormation templates to retrieve data from Amazon EFS.",
      "Correct Answer": 3
    },
    "Question15": {
      "Question": "A company wants to automate part of its deployment process. A developer needs to automate the process of checking for and deleting unused resources that supported previously deployed stacks but that are no longer used. The company has a central application that uses the AWS Cloud Development Kit (AWS CDK) to manage all deployment stacks. The stacks are spread out across multiple accounts. The developer's solution must integrate as seamlessly as possible within the current deployment process. Which solution will meet these requirements with the LEAST amount of configuration?",
      "Option1": "In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CloudFormation template from a JSON file. Use the template to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option2": "In the central AWS CDK application, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option3": "In the central AWS CDK, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an API in AWS Amplify. Use the API to attach the function code to an AWS Lambda function and to invoke the Lambda function when the deployment stack runs.",
      "Option4": "In the AWS Lambda console, write a handler function in the code that uses AWS SDK calls to check for and delete unused resources. Create an AWS CDK custom resource. Use the custom resource to import the Lambda function into the stack and to invoke the Lambda function when the deployment stack runs.",
      "Correct Answer": 2
    },
    "Question16": {
      "Question": "A company has developed a new serverless application using AWS Lambda functions that will be deployed using the AWS Serverless Application Model (AWS SAM) CLI. Which step should the developer complete prior to deploying the application?",
      "Option1": "Compress the application to a .zip file and upload it into AWS Lambda.",
      "Option2": "Test the new AWS Lambda function by first tracing it in AWS X-Ray.",
      "Option3": "Bundle the serverless application using a SAM package.",
      "Option4": "Create the application environment using the eb create my-env command.",
      "Correct Answer": 3
    },
    "Question17": {
      "Question": "A company is migrating its PostgreSQL database into the AWS Cloud. The company wants to use a database that will secure and regularly rotate database credentials. The company wants a solution that does not require additional programming overhead. Which solution will meet these requirements?",
      "Option1": "Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.",
      "Option2": "Use Amazon Aurora PostgreSQL for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.",
      "Option3": "Use Amazon DynamoDB for the database. Store the database credentials in AWS Systems Manager Parameter Store. Turn on rotation.",
      "Option4": "Use Amazon DynamoDB for the database. Store the database credentials in AWS Secrets Manager. Turn on rotation.",
      "Correct Answer": 2
    },
    "Question18": {
      "Question": "A developer is testing an application that invokes an AWS Lambda function asynchronously. During the testing phase, the Lambda function fails to process after two retries. How can the developer troubleshoot the failure?",
      "Option1": "Configure AWS CloudTrail logging to investigate the invocation failures.",
      "Option2": "Configure Dead Letter Queues by sending events to Amazon SQS for investigation.",
      "Option3": "Configure Amazon Simple Workflow Service to process any direct unprocessed events.",
      "Option4": "Configure AWS Config to process any direct unprocessed events.",
      "Correct Answer": 2
    },
    "Question19": {
      "Question": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
      "Option1": "Use Amazon CloudFront with signed URLs for Amazon S3.",
      "Option2": "Create a dedicated Amazon CloudFront Distribution for each customer.",
      "Option3": "Use Amazon Cloud Front with AWS Lambda@Edge.",
      "Option4": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket.",
      "Correct Answer": 1
    },
    "Question20": {
      "Question": "A company has an ecommerce application. To track product reviews, the company's development team uses an Amazon DynamoDB table. <br>Every record includes the following: <br> • A Review ID, a 16-digit universally unique identifier (UUID) A Product ID and User ID, 16-digit UUIDS that reference other tables <br> • A Product Rating on a scale of 1-5 <br> • An optional comment from the user <br> The table partition key is the Review ID. The most performed query against the table is to find the 10 reviews with the highest rating for a given product. <br> Which index will provide the FASTEST response for this query?",
      "Option1": "A global secondary index (GSI) with Product ID as the partition key and Product Rating as the sort key",
      "Option2": "A global secondary index (GSI) with Product ID as the partition key and Review ID as the sort key ",
      "Option3": "A local secondary index (LSI) with Product ID as the partition key and Product Rating as the sort key",
      "Option4": "A local secondary index (LSI) with Review ID as the partition key and Product ID as the sort key",
      "Correct Answer": 1
    },
    "Question21": {
      "Question": "A developer is storing sensitive data generated by an application in Amazon S3. The developer wants to encrypt the data at rest. 1 # A company policy requires an audit trail of when the AWS Key Management Service (AWS KMS) key was used and by whom. <br>Which encryption option will meet these requirements?",
      "Option1": " Server-side encryption with Amazon S3 managed keys (SSE-S3)",
      "Option2": "Server-side encryption with AWS KMS managed keys (SSE-KMS)",
      "Option3": "Server-side encryption with customer-provided keys (SSE-C)",
      "Option4": "Server-side encryption with self-managed keys",
      "Correct Answer": 2
    },
    "Question22": {
      "Question": " A development team maintains a web application by using a single AWS RDS, template. The template defines web servers and an Amazon RDS database. The team uses the CloudFormation template to deploy the CloudFormation stack to different environments. <br> During a recent application deployment, a developer caused the primary development database to be dropped and recreated. The result of this incident was a loss of data. The team needs to avoid accidental database deletion in the future. <br>Which solutions will meet these requirements? (Choose two.)",
      "Option1": "Add a CloudFormation Deletion Policy attribute with the Retain value to the database resource.",
      "Option2": "Update the CloudFormation stack policy to prevent updates to the database.",
      "Option3": "Modify the database to use a Multi-AZ deployment.",
      "Option4": "Create a CloudFormation stack set for the web application and database deployments.",
      "Option5": "Add a CloudFormation Deletion Policy attribute with the Retain value to the stack.",
      "Correct Answer": 1
    },
    "Question23": {
      "Question": "A developer needs to deploy an application running on AWS Fargate using Amazon ECS. The application has environment variables that must be passed to a container for the application to initialize. <br>How should the environment variables be passed to the container?",
      "Option1": "Define an array that includes the environment variables under the environment parameter within the service definition.",
      "Option2": "Define an array that includes the environment variables under the environment parameter within the task definition.",
      "Option3": "Define an array that includes the environment variables under the entryPoint parameter within the task definition.",
      "Option4": "Define an array that includes the environment variables under the entryPoint parameter within the service definition.",
      "Correct Answer": 2
    },
    "Question24": {
      "Question": "A developer has been asked to create an AWS Lambda function that is invoked any time updates are made to items in an Amazon DynamoDB table. The function has been created, and appropriate permissions have been added to the Lambda execution role. Amazon DynamoDB streams have been enabled for the table, but the function is still not being invoked. <br>Which option would enable DynamoDB table updates to invoke the Lambda function?",
      "Option1": "Change the Stream View Type parameter value to NEW_AND_OLD_IMAGES for the DynamoDB table.",
      "Option2": "Configure event source mapping for the Lambda function.",
      "Option3": "Map an Amazon Simple Notification Service (Amazon SNS) topic to the DynamoDB streams.",
      "Option4": "Increase the maximum runtime (timeout) setting of the Lambda function.",
      "Correct Answer": 2
    },
    "Question25": {
      "Question": "A developer is building a web application that uses Amazon API Gateway to expose an AWS Lambda function to process requests from clients. During testing, the Developer notices that the API Gateway times out even though the Lambda function finishes under the set time limit. <br>Which of the following API Gateway metrics in Amazon CloudWatch can help the Developer troubleshoot the issue? (Choose two.)",
      "Option1": "CacheHitCount",
      "Option2": "IntegrationLatency",
      "Option3": "CacheMissCount",
      "Option4": "Latency",
      "Option5": "Count",
      "Correct Answer": 2
    },
    "Question26": {
      "Question": "A developer is creating an Amazon DynamoDB table. The entire table must be encrypted at rest. Which solution will meet this requirement MOST cost-effectively?",
      "Option1": " Create the DynamoDB table by using default encryption settings.",
      "Option2": "Encrypt the data by using the DynamoDB Encryption Client.",
      "Option3": "During creation of the DynamoDB table, configure encryption at rest with an AWS Key Management Service (AWS KMS) AWS managed key.",
      "Option4": " During creation of the DynamoDB table, configure encryption at rest with an AWS Key Management Service (AWS KMS) customer managed key.",
      "Correct Answer": 1
    },
    "Question27": {
      "Question": "A company developed an API application on AWS by using Amazon CloudFront, Amazon API Gateway, and AWS Lambda. The API has a minimum of four requests every second. A developer notices that many API users run the same query by using the POST method. The developer wants to cache the POST request to optimize the API resources. <br>Which solution will meet these requirements?",
      "Option1": "Configure the Cloud Front cache. Update the application to return cached content based upon the default request headers.",
      "Option2": "Override the cache method in the selected stage of API Gateway. Select the POST method.",
      "Option3": " Save the latest request response in Lambda /tmp directory. Update the Lambda function to check the /tmp directory.",
      "Option4": "Save the latest request in AWS Systems Manager Parameter Store. Modify the Lambda function to take the latest request response from Parameter Store.",
      "Correct Answer": 2
    },
    "Question28": {
      "Question": "An application writes items to an Amazon DynamoDB table. As the application scales to thousands of instances, calls to the DynamoDB API generate occasional ThrottlingException errors. The application is coded in a language incompatible with the AWS SDK. How should the error be handled?",
      "Option1": "Add exponential backoff to the application logic",
      "Option2": "Use Amazon SQS as an API message bus",
      "Option3": "Pass API calls through Amazon API Gateway",
      "Option4": "Send the items to DynamoDB through Amazon Kinesis Data Firehose",
      "Correct Answer": 1
    },
    "Question29": {
      "Question": "A company has an application that runs as a series of AWS Lambda functions. Each Lambda function receives data from an Amazon Simple Notification Service (Amazon SNS) topic and writes the data to an Amazon Aurora DB instance. <br>To comply with an information security policy, the company must ensure that the Lambda functions all use a single securely encrypted database connection string to access Aurora. <br>Which solution will meet these requirements?",
      "Option1": "Use IAM database authentication for Aurora to enable secure database connections for all the Lambda functions.",
      "Option2": "Store the credentials and read the credentials from an encrypted Amazon RDS DB instance.",
      "Option3": "Store the credentials in AWS Systems Manager Parameter Store as a secure string parameter.",
      "Option4": "Use Lambda environment variables with a shared AWS Key Management Service (AWS KMS) key for encryption.",
      "Correct Answer": 3
    },
    "Question30": {
      "Question": "A company needs to distribute firmware updates to its customers around the world. Which service will allow easy and secure control of the access to the downloads at the lowest cost?",
      "Option1": "Use Amazon CloudFront with signed URLs for Amazon S3",
      "Option2": "Create a dedicated Amazon Cloud Front Distribution for each customer",
      "Option3": "Use Amazon Cloud Front with AWS Lambda@Edge",
      "Option4": "Use Amazon API Gateway and AWS Lambda to control access to an S3 bucket",
      "Correct Answer": 1
    },
    "Question31": {
      "Question": " company caches session information for a web application in an Amazon DynamoDB table. The company wants an automated way to delete old items from the table. <br>What is the simplest way to do this?",
      "Option1": "Write a script that deletes old records; schedule the script as a cron job on an Amazon EC2 instance.",
      "Option2": "Add an attribute with the expiration time; enable the Time To Live feature based on that attribute.",
      "Option3": "Each day, create a new table to hold session data; delete the previous day's table.",
      "Option4": "Add an attribute with the expiration time; name the attribute Item Expiration.",
      "Correct Answer": 2
    },
    "Question32": {
      "Question": "A developer is using AWS Elastic Beanstalk to create a deployment for a web application that supports ecommerce. According to a company requirement. Amazon EC2 instances that host one version of the application must be retired when the deployment of a new version is complete. Which deployment methods can the developer use to meet this requirement? (Choose two.)",
      "Option1": "All-al-once deployment",
      "Option2": " In-place deployment",
      "Option3": "Rolling deployment without an additional batch",
      "Option4": "Blue/green deployment",
      "Option5": "Immutable deployment",
      "Correct Answer": 4
    },
    "Question33": {
      "Question": "A developer is building a web and mobile application for two types of users: regular users and guest users. Regular users are required to log in, but guest users do not log in. Users should see only their data, regardless of whether they authenticate. Users need AWS credentials before they can access AWS resources. <br>What is the MOST secure solution that the developer can implement to allow access for guest users?",
      "Option1": "Use an Amazon Cognito credentials provider to issue temporary credentials that are linked to an unauthenticated role that has access to the required resources.",
      "Option2": "Set up an IAM user that has permissions to the required resources. Hardcode the IAM credentials in the web and mobile application.",
      "Option3": "Generate temporary keys that are stored in AWS Key Management Service (AWS KMS). Use the temporary keys to access the required resources.",
      "Option4": "Generate temporary credentials. Store the temporary credentials in AWS Secrets Manager. Use the temporary credentials to access the required resources.",
      "Correct Answer": 1
    },
    "Question34": {
      "Question": "",
      "Option1": "",
      "Option2": "",
      "Option3": "",
      "Option4": "",
      "Correct Answer": 1
    },
    "Question35": {
      "Question": "A developer is modifying an existing AWS Lambda function. While checking the code, the developer notices hardcoded parameter values for an Amazon RDS for SQL Server user name, password, database, host, and port. There are also hardcoded parameter values for an Amazon DynamoDB table, an Amazon S3 bucket, and an Amazon Simple Notification Service (Amazon SNS) topic. <br>The developer wants to securely store the parameter values outside the code in an encrypted format and wants to turn on rotation for the credentials. The developer also wants to be able to reuse the parameter values from other applications and to update the parameter values without modifying code. <br>Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. ",
      "Option2": "Create an RDS database secret in AWS Secrets Manager. Set the user name, password, database, host, and port. Turn on secret rotation. Create SecureString parameters in AWS Systems Manager Parameter Store for the DynamoDB table, S3 bucket, and SNS topic.",
      "Option3": "Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Create encrypted Lambda environment variables for the DynamoDB table, S3 bucket, and SNS topic. Create a Lambda function and set the logic for the credentials rotation task. Schedule the credentials rotation task in Amazon EventBridge.",
      "Option4": "Create RDS database parameters in AWS Systems Manager Parameter Store for the user name, password, database, host, and port. Store the DynamoDB table, S3 bucket, and SNS topic in Amazon S3. Create a Lambda function and set the logic for the credentials rotation. Invoke the Lambda function on a schedule.",
      "Correct Answer": 2
    },
    "Question36": {
      "Question": "A mobile app stores blog posts in an Amazon DynamoDB table. Millions of posts are added every day, and each post represents a single item in the table. The mobile app requires only recent posts. Any post that is older than 48 hours can be removed. <br>What is the MOST cost-effective way to delete posts that are older than 48 hours?",
      "Option1": "For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteltem API operation. Schedule a cron job on an Amazon EC2 instance once an hour to start the script.",
      "Option2": "For each item, add a new attribute of type String that has a timestamp that is set to the blog post creation time. Create a script to find old posts with a table scan and remove posts that are older than 48 hours by using the BatchWriteltem API operation. Place the script in a container image. Schedule an Amazon Elastic Container Service (Amazon ECS) task on AWS Fargate that invokes the container every 5 minutes.",
      "Option3": "For each item, add a new attribute of type Date that has a timestamp that is set to 48 hours after the blog post creation time. Create a global secondary index (GSI) that uses the new attribute as a sort key. Create an AWS Lambda function that references the GSI and removes expired items by using the BatchWriteltem API operation. Schedule the function with an Amazon CloudWatch event every minute.",
      "Option4": "For each item, add a new attribute of type Number that has a timestamp that is set to 48 hours after the blog post creation time. Configure the DynamoDB table with a TTL that references the new attribute.",
      "Correct Answer": 4
    },
    "Question37": {
      "Question": "A developer has an application that is composed of many different AWS Lambda functions. The Lambda functions all use some of the same dependencies. To avoid security issues, the developer is constantly updating the dependencies of all of the Lambda functions. The result is duplicated effort for each function. <br>How can the developer keep the dependencies of the Lambda functions up to date with the LEAST additional complexity?",
      "Option1": "Define a maintenance window for the Lambda functions to ensure that the functions get updated copies of the dependencies.",
      "Option2": "Upgrade the Lambda functions to the most recent runtime version.",
      "Option3": "Define a Lambda layer that contains all of the shared dependencies.",
      "Option4": "Use an AWS CodeCommit repository to host the dependencies in a centralized location.",
      "Correct Answer": 3
    },
    "Question38": {
      "Question": "A developer at a company recently created a serverless application to process and show data from business reports. The application's user interface (UI) allows users to select and start processing the files. The UI displays a message when the result is available to view. The application uses AWS Step Functions with AWS Lambda functions to process the files. The developer used Amazon API Gateway and Lambda functions to create an API to support the UI. <br>The company's Ul team reports that the request to process a file is often returning timeout errors because of the size or complexity of the files. The UI team wants the API to provide an immediate response so that the UI can display a message while the files are being processed. The backend process that is invoked by the API needs to send an email message when the report processing is complete. <br>What should the developer do to configure the API to meet these requirements?",
      "Option1": "Change the API Gateway route to add an X-Amz-Invocation-Type header with a static value of 'Event' in the integration request. Deploy the API Gateway stage to apply the changes.",
      "Option2": "Change the configuration of the Lambda function that implements the request to process a file. Configure the maximum age of the event so that the Lambda function will run asynchronously.",
      "Option3": "Change the API Gateway timeout value to match the Lambda function timeout value. Deploy the API Gateway stage to apply the changes.",
      "Option4": "Change the API Gateway route to add an X-Amz-Target header with a static value of 'Async' in the integration request. Deploy the API Gateway stage to apply the changes.",
      "Correct Answer": 1
    },
    "Question39": {
      "Question": "A developer accesses AWS CodeCommit over SSH. The SSH keys configured to access AWS CodeCommit are tied to a user with the following permissions: <br>The developer needs to create/delete branches. <br>Which specific IAM permissions need to be added, based on the principle of least privilege?",
      "Option1": "'codecommit:CreateBranch' 'codecommit:DeleteBranch'",
      "Option2": "'codecommit:Put*'",
      "Option3": "'codecommit:Update*'",
      "Option4": "'codecommit:*'",
      "Correct Answer": 1
    },
    "Question40": {
      "Question": "A developer is working on an AWS Lambda function that accesses Amazon DynamoDB. The Lambda function must retrieve an item and update some of its attributes, or create the item if it does not exist. The Lambda function has access to the primary key. <br>Which IAM permissions should the developer request for the Lambda function to achieve this functionality?",
      "Option1": "dynamodb: DeleteItem <br>dynamodb: GetItem <br>dynamodb: PutItem <br>dynamodb: UpdateItem",
      "Option2": "dynamodb:GetItem <br>dynamodb: DescribeTable <br>dynamodb: GetRecords <br>dynamodb: PutItem",
      "Option3": "dynamodb: UpdateTable <br>dynamodb: UpdateItem",
      "Option4": "dynamodb: GotItem <br>dynamodb: PutItem",
      "Correct Answer": 4
    },
    "Question41": {
      "Question": "A Developer created configuration specifications for an AWS Elastic Beanstalk application in a file named healthcheckurl.yaml in the .ebextensions/directory of their application source bundle. The file contains the following: <br> option_settings: <br>-namespace: aws:elasticbeanstalk: application option_name: Application Healthcheck URL value: /health_check <br>After the application launches, the health check is not being run on the correct path, event though it is valid. <br>What can be done to correct this configuration file?",
      "Option1": "Convert the file to JSON format.",
      "Option2": "Rename the file to a .config extension.",
      "Option3": "Change the configuration section from options_settings to resources.",
      "Option4": "Change the namespace of the option settings to a custom namespace.",
      "Correct Answer": 2
    },
    "Question42": {
      "Question": "A developer is building a serverless application that is based on AWS Lambda. The developer initializes the AWS software development kit (SDK) outside of the Lambda handler function. What is the PRIMARY benefit of this action?",
      "Option1": "Improves legibility and stylistic convention",
      "Option2": "Takes advantage of runtime environment reuse ",
      "Option3": "Provides better error handling",
      "Option4": "Creates a new SDK instance for each invocation",
      "Correct Answer": 2
    },
    "Question43": {
      "Question": "A developer at a company needs to create a small application that makes the same API call once each day at a designated time. The company does not have infrastructure in the AWS Cloud yet, but the company wants to implement this functionality on AWS. <br>Which solution meets these requirements in the MOST operationally efficient manner?",
      "Option1": "Use a Kubernetes cron job that runs on Amazon Elastic Kubernetes Service (Amazon EKS).",
      "Option2": "Use an Amazon Linux crontab scheduled job that runs on Amazon EC2.",
      "Option3": "Use an AWS Lambda function that is invoked by an Amazon EventBridge scheduled event.",
      "Option4": "Use an AWS Batch job that is submitted to an AWS Batch job queue.",
      "Correct Answer": 3
    },
    "Question44": {
      "Question": "A developer has code that is stored in an Amazon S3 bucket. The code must be deployed as an AWS Lambda function across multiple accounts in the same AWS Region as the S3 bucket. An AWS CloudFormation template that runs for each account will deploy the Lambda function. <br>What is the MOST secure way to allow CloudFormation to access the Lambda code in the S3 bucket?",
      "Option1": "Grant the CloudFormation service role the S3 ListBucket and GetObject permissions. Add a bucket policy to Amazon S3 with the principal of 'AWS': [account numbers].",
      "Option2": "Grant the CloudFormation service role the S3 GetObject permission. Add a bucket policy to Amazon S3 with the principal of '*'.",
      "Option3": "Use a service-based link to grant the Lambda function the S3 ListBucket and GetObject permissions by explicitly adding the S3 bucket's account number in the resource.",
      "Option4": "Use a service-based link to grant the Lambda function the S3 GetObject permission. Add a resource of '*' to allow access to the S3 bucket",
      "Correct Answer": 1
    },
    "Question45": {
      "Question": "An application that runs on AWS Lambda requires access to specific highly confidential objects in an Amazon S3 bucket. In accordance with the principle of least privilege, a company grants access to the S3 bucket by using only temporary credentials. <br>How can a developer configure access to the S3 bucket in the MOST secure way?",
      "Option1": "Hardcode the credentials that are required to access the S3 objects in the application code. Use the credentials to access the required S3 objects.",
      "Option2": "Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID in AWS Secrets Manager. Configure the application to retrieve the Secrets Manager secret and use the credentials to access the $3 objects.",
      "Option3": "Create a Lambda function execution role. Attach a policy to the role that grants access to specific objects in the S3 bucket.",
      "Option4": "Create a secret access key and access key ID with permission to access the S3 bucket. Store the key and key ID as environment variables in Lambda. Use the environment variables to access the required S3 objects.",
      "Correct Answer": 3
    },
    "Question46": {
      "Question": "When using the AWS Encryption SDK, how does the developer keep track of the data encryption keys used to encrypt data?",
      "Option1": "The developer must manually keep track of the data encryption keys used for each data object.",
      "Option2": "The SDK encrypts the data encryption key and stores it (encrypted) as part of the returned ciphertext.",
      "Option3": "The SDK stores the data encryption keys automatically in Amazon S3.",
      "Option4": "The data encryption key is stored in the Userdata for the EC2 instance.",
      "Correct Answer": 2
    },
    "Question47": {
      "Question": "A developer is troubleshooting an application that uses Amazon DynamoDB in the us-west-2 Region. The application is deployed to an Amazon EC2 instance. The application requires read-only permissions to a table that is named Cars. The EC2 instance has an attached IAM role that contains the following IAM policy: <br>When the application tries to read from the Cars table, an Access Denied error occurs. <br>How can the developer resolve this error?",
      "Option1": " Modify the IAM policy resource to be 'arn:aws:dynamodb:us-west-2:account-id:table/*''.",
      "Option2": "Modify the IAM policy to include the dynamodb:* action.",
      "Option3": "Create a trust policy that specifies the EC2 service principal. Associate the role with the policy.",
      "Option4": "Create a trust relationship between the role and dynamodb.amazonaws.com.",
      "Correct Answer": 3
    },
    "Question48": {
      "Question": "A developer has observed an increase in bugs in the AWS Lambda functions that a development team has deployed in its Node.js application. To minimize these bugs, the developer wants to implement automated testing of Lambda functions in an environment that closely simulates the Lambda environment. <br>The developer needs to give other developers the ability to run the tests locally. The developer also needs to integrate the tests into the team's continuous integration and continuous delivery (CI/CD) pipeline before the AWS Cloud Development Kit (AWS CDK) deployment. <br>Which solution will meet these requirements?",
      "Option1": "Create sample events based on the Lambda documentation. Create automated test scripts that use the cdk local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts.",
      "Option2": "Install a unit testing framework that reproduces the Lambda execution environment. Create sample events based on the Lambda documentation. Invoke the handler function by using a unit testing framework. Check the response. Document how to run the unit testing framework for the other developers on the team. Update the CI/CD pipeline to run the unit testing framework.",
      "Option3": "Install the AWS Serverless Application Model (AWS SAM) CLI tool. Use the sam local generate-event command to generate sample events for the automated tests. Create automated test scripts that use the sam local invoke command to invoke the Lambda functions. Check the response. Document the test scripts for the other developers on the team. Update the CI/CD pipeline to run the test scripts.",
      "Option4": "Create sample events based on the Lambda documentation. Create a Docker container from the Node.js base image to invoke the Lambda functions. Check the response. Document how to run the Docker container for the other developers on the team. Update the CI/CD pipeline to run the Docker container.",
      "Correct Answer": 3
    },
    "Question49": {
      "Question": "A developer wants to deploy a new version of an AWS Elastic Beanstalk application. During deployment, the application must maintain full capacity and avoid service interruption. Additionally, the developer must minimize the cost of additional resources that support the deployment. <br>Which deployment method should the developer use to meet these requirements?",
      "Option1": "All at once",
      "Option2": "Rolling with additional batch",
      "Option3": "Blue/green",
      "Option4": "Immutable",
      "Correct Answer": 4
    },
    "Question50": {
      "Question": "A developer must analyze performance issues with production-distributed applications written as AWS Lambda functions. These distributed Lambda applications invoke other components that make up the applications. <br>How should the developer identify and troubleshoot the root cause of the performance issues in production?",
      "Option1": " Add logging statements to the Lambda functions, then use Amazon CloudWatch to view the logs.",
      "Option2": "Use AWS Cloud Trail and then examine the logs.",
      "Option3": "Use AWS X-Ray, then examine the segments and errors.",
      "Option4": "Run Amazon Inspector agents and then analyze performance.",
      "Correct Answer": 3
    },
    "Question51": {
      "Question": "The Operations team is asking for a graphical representation of one key performance metric for each application. These metrics should be available on one screen for easy monitoring. <br>Which steps should the Developer take to accomplish this using Amazon CloudWatch?",
      "Option1": "Create a custom namespace with a unique metric name for each application.",
      "Option2": "Create a custom dimension with a unique metric name for each application.",
      "Option3": "Create a custom event with a unique metric name for each application.",
      "Option4": "Create a custom alarm with a unique metric name for each application.",
      "Correct Answer": 1
    },
    "Question52": {
      "Question": "A developer is creating a serverless website with content that includes HTML files, images, videos, and JavaScript (client-side scripts). <br>Which combination of services should the Developer use to create the website?",
      "Option1": "Amazon S3 and Amazon CloudFront",
      "Option2": "Amazon EC2 and Amazon ElastiCache",
      "Option3": "Amazon ECS and Redis",
      "Option4": "AWS Lambda and Amazon API Gateway",
      "Correct Answer": 1
    },
    "Question53": {
      "Question": "An application runs on multiple EC2 instances behind an ELB. <br>Where is the session data best written so that it can be served reliably across multiple requests?",
      "Option1": "Write data to Amazon ElastiCache.",
      "Option2": "Write data to Amazon Elastic Block Store.",
      "Option3": "Write data to Amazon EC2 Instance Store.",
      "Option4": "Write data to the root filesystem.",
      "Correct Answer": 1
    },
    "Question54": {
      "Question": "A company uses Amazon DynamoDB for managing and tracking orders. The DynamoDB table is partitioned based on the order date. The company receives a huge increase in orders during a sales event, causing DynamoDB writes to throttle, and the consumed throughput is far below the provisioned throughput. <br>According to AWS best practices, how can this issue be resolved with MINIMAL costs?",
      "Option1": "Create a new DynamoDB table for every order date.",
      "Option2": "Increase the read and write capacity units of the DynamoDB table.",
      "Option3": "Add a random number suffix to the partition key values.",
      "Option4": "Add a global secondary index to the DynamoDB table.",
      "Correct Answer": 3
    },
    "Question55": {
      "Question": "A developer is writing a serverless application that requires an AWS Lambda function to be invoked every 10 minutes. <br>What is an automated and serverless way to invoke the function?",
      "Option1": "Deploy an Amazon EC2 instance based on Linux, and edit its /etc/crontab file by adding a command to periodically invoke the Lambda function.",
      "Option2": "Configure an environment variable named PERIOD for the Lambda function. Set the value to 600.",
      "Option3": "Create an Amazon EventBridge rule that runs on a regular schedule to invoke the Lambda function.",
      "Option4": "Create an Amazon Simple Notification Service (Amazon SNS) topic that has a subscription to the Lambda function with a 600-second timer.",
      "Correct Answer": 3
    },
    "Question56": {
      "Question": "A developer maintains applications that store several secrets in AWS Secrets Manager. The applications use secrets that have changed over time. The developer needs to identify required secrets that are still in use. The developer does not want to cause any application downtime. <br>What should the developer do to meet these requirements?",
      "Option1": "Configure an AWS CloudTrail log file delivery to an Amazon S3 bucket. Create an Amazon CloudWatch alarm for the GetSecretValue Secrets Manager API operation requests.",
      "Option2": "Create a secretsmanager-secret-unused AWS Config managed rule. Create an Amazon EventBridge rule to initiate notifications when the AWS Config managed rule is met.",
      "Option3": "Deactivate the applications secrets and monitor the applications error logs temporarily.",
      "Option4": "Configure AWS X-Ray for the applications. Create a sampling rule to match the GetSecretValue Secrets Manager API operation requests.",
      "Correct Answer": 2
    },
    "Question57": {
      "Question": "A company uses a custom root certificate authority certificate chain (Root CA Cert) that is 10 KB in size to generate SSL certificates for its on-premises HTTPS endpoints. One of the company's cloud-based applications has hundreds of AWS Lambda functions that pull data from these endpoints. A developer updated the trust store of the Lambda execution environment to use the Root CA Cert when the Lambda execution environment is initialized. The developer bundled the Root CA Cert as a text file in the Lambda deployment bundle. <br>After 3 months of development, the Root CA Cert is no longer valid and must be updated. The developer needs a more efficient solution to update the Root CA Cert for all deployed Lambda functions. The solution must not include rebuilding or updating all Lambda functions that use the Root CA Cert. The solution must also work for all development, testing, and production environments. Each environment is managed in a separate AWS account. Which combination of steps should the developer take to meet these requirements MOST cost-effectively? (Choose two.)",
      "Option1": "Store the Root CA Cert as a secret in AWS Secrets Manager. Create a resource-based policy. Add IAM users to allow access to the secret.",
      "Option2": "Store the Root CA Cert as a SecureString parameter in AWS Systems Manager Parameter Store. Create a resource-based policy. Add IAM users to allow access to the policy.",
      "Option3": "Store the Root CA Cert in an Amazon S3 bucket. Create a resource-based policy to allow access to the bucket.",
      "Option4": "Refactor the Lambda code to load the Root CA Cert from the Root CA Cert's location. Modify the runtime trust store inside the Lambda function handler.",
      "Option5": "Refactor the Lambda code to load the Root CA Cert from the Root CA Cert's location. Modify the runtime trust store outside the Lambda function handler.",
      "Correct Answer": 1
    },
    "Question58": {
      "Question": "A company has multiple Amazon VPC endpoints in the same VPC. A developer needs to configure an Amazon S3 bucket policy so users can access an S3 bucket only by using these VPC endpoints. Which solution will meet these requirements?",
      "Option1": "Create multiple S3 bucket polices by using each VPC endpoint ID that have the aws:SourceVpce value in the StringNotEquals condition.",
      "Option2": "Create a single S3 bucket policy that has the aws:SourceVpc value and in the StringNotEquals condition to use VPC ID.",
      "Option3": "Create a single S3 bucket policy that has the aws:SourceVpce value and in the StringNotEquals condition to use vpce*",
      "Option4": "Create a single S3 bucket policy that has multiple aws:sourceVpce value in the StringNotEquals condition. Repeat for all the VPC endpoint IDs.",
      "Correct Answer": 4
    },
    "Question59": {
      "Question": "A team of developers is using an AWS CodePipeline pipeline as a continuous integration and continuous delivery (CI/CD) mechanism for a web application. A developer has written unit tests to programmatically test the functionality of the application code. The unit tests produce a test report that shows the results of each individual check. The developer now wants to run these tests automatically during the CI/CD process. <br>Which solution will meet this requirement with the LEAST operational effort?",
      "Option1": "Write a Git pre-commit hook that runs the tests before every commit. Ensure that each developer who is working on the project has the pre-commit hook installed locally. Review the test report and resolve any issues before pushing changes to AWS CodeCommit.",
      "Option2": "Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage after the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.",
      "Option3": "Add a new stage to the pipeline. Use AWS CodeBuild as the provider. Add the new stage before the stage that deploys code revisions to the test environment. Write a buildspec that fails the CodeBuild stage if any test does not pass. Use the test reports feature of CodeBuild to integrate the report with the CodeBuild console. View the test results in CodeBuild. Resolve any issues.",
      "Option4": "Add a new stage to the pipeline. Use Jenkins as the provider. Configure CodePipeline to use Jenkins to run the unit tests. Write a Jenkinsfile that fails the stage if any test does not pass. Use the test report plugin for Jenkins to integrate the report with the Jenkins dashboard. View the test results in Jenkins. Resolve any issues.",
      "Correct Answer": 3
    },
    "Question60": {
      "Question": "A developer is planning to migrate on-premises company data to Amazon S3. The data must be encrypted, and the encryption keys must support automatic annual rotation. The company must use AWS Key Management Service (AWS KMS) to encrypt the data. <br>Which type of keys should the developer use to meet these requirements?",
      "Option1": "Amazon S3 managed keys",
      "Option2": "Symmetric customer managed keys with key material that is generated by AWS",
      "Option3": "Asymmetric customer managed keys with key material that is generated by AWS",
      "Option4": "Symmetric customer managed keys with imported key material",
      "Correct Answer": 2
    },
    "Question61": {
      "Question": "An organization is using Amazon CloudFront to ensure that its users experience low-latency access to its web application. The organization has identified a need to encrypt all traffic between users and CloudFront, and all traffic between CloudFront and the web application. <br>How can these requirements be met? (Choose two.)",
      "Option1": "Use AWS KMS to encrypt traffic between CloudFront and the web application.",
      "Option2": "Set the Origin Protocol Policy to 'HTTPS Only'.",
      "Option3": "Set the Origin's HTTP Port to 443.",
      "Option4": "Set the Viewer Protocol Policy to 'HTTPS Only' or 'Redirect HTTP to HTTPS'.",
      "Option5": "Enable the Cloud Front option Restrict Viewer Access.",
      "Correct Answer": 2
    },
    "Question62": {
      "Question": "A developer is trying to get data from an Amazon DynamoDB table called demoman-table. The developer configured the AWS CLI to use a specific IAM user's credentials and ran the following command: <br>aws dynamodb get-item --table-name demoman-table --key '{'id': {'N':'1993'}}' <br>The command returned errors and no rows were returned. <br>What is the MOST likely cause of these issues?",
      "Option1": "The command is incorrect; it should be rewritten to use put-item with a string argument.",
      "Option2": "The developer needs to log a ticket with AWS Support to enable access to the demoman-table.",
      "Option3": "Amazon DynamoDB cannot be accessed from the AWS CLI and needs to be called via the REST API.",
      "Option4": "The IAM user needs an associated policy with read access to demoman-table.",
      "Correct Answer": 4
    },
    "Question63": {
      "Question": "A developer is building an application that gives users the ability to view bank accounts from multiple sources in a single dashboard. The developer has automated the process to retrieve API credentials for these sources. The process invokes an AWS Lambda function that is associated with an AWS CloudFormation custom resource. <br>The developer wants a solution that will store the API credentials with minimal operational overhead. Which solution will meet these requirements in the MOST secure way?",
      "Option1": "Add an AWS Secrets Manager GenerateSecretString resource to the CloudFormation template. Set the value to reference new credentials for the CloudFormation resource.",
      "Option2": "Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter type to SecureString.",
      "Option3": "Add an AWS Systems Manager Parameter Store resource to the CloudFormation template. Set the CloudFormation resource value to reference the new credentials. Set the resource NoEcho attribute to true.",
      "Option4": "Use the AWS SDK ssm:PutParameter operation in the Lambda function from the existing custom resource to store the credentials as a parameter. Set the parameter value to reference the new credentials. Set the parameter NoEcho attribute to true.",
      "Correct Answer": 4
    },
    "Question64": {
      "Question": "A developer is building an application that uses AWS API Gateway APIs, AWS Lambda functions, and AWS DynamoDB tables. The developer uses the AWS Serverless Application Model (AWS SAM) to build and run serverless applications on AWS. Each time the developer pushes changes for only to the Lambda functions, all the artifacts in the application are rebuilt. <br>The developer wants to implement AWS SAM Accelerate by running a command to only redeploy the Lambda functions that have changed. <br>Which command will meet these requirements?",
      "Option1": "sam deploy --force-upload",
      "Option2": "sam deploy --no-execute-changeset",
      "Option3": "sam package",
      "Option4": "sam sync --watch",
      "Correct Answer": 4
    },
    "Question65": {
      "Question": "A developer is creating an AWS Lambda function that searches for items from an Amazon DynamoDB table that contains customer contact information. The DynamoDB table items have the customer's email_address as the partition key and additional properties such as customer_type, name and job_title. <br>The Lambda function runs whenever a user types a new character into the customer_type text input. The developer wants the search to return partial matches of all the email_address property of a particular customer_type. The developer does not want to recreate the DynamoDB table. <br>What should the developer do to meet these requirements?",
      "Option1": "Add a global secondary index (GSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the GSI by using the begins with key condition expression with the email_address property.",
      "Option2": "Add a global secondary index (GSI) to the DynamoDB table with email_address as the partition key and customer_type as the sort key. Perform a query operation on the GSI by using the begins with key condition expression with the email_address property.",
      "Option3": "Add a local secondary index (LSI) to the DynamoDB table with customer_type as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins with key condition expression with the email_address property.",
      "Option4": "Add a local secondary index (LSI) to the DynamoDB table with job_title as the partition key and email_address as the sort key. Perform a query operation on the LSI by using the begins with key condition expression with the email_address property.",
      "Correct Answer": 1
    },
    "Question66": {
      "Question": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. <br>Which combination of steps will resolve the latency issue? (Choose two.)",
      "Option1": "Double the Auto Scaling group's maximum number of servers.",
      "Option2": "Host the application code on AWS Lambda.",
      "Option3": "Scale vertically by resizing the EC2 instances.",
      "Option4": "Create an Amazon CloudFront distribution to cache the static content.",
      "Option5": "Store the application's static content in Amazon S3.",
      "Correct Answer": 2
    },
    "Question67": {
        "Question": "A company's website runs on an Amazon EC2 instance and uses Auto Scaling to scale the environment during peak times. Website users across the world are experiencing high latency due to static content on the EC2 instance, even during non-peak hours. <br>Which combination of steps will resolve the latency issue? (Choose two.)",
        "Option1": "Double the Auto Scaling group's maximum number of servers.",
        "Option2": "Host the application code on AWS Lambda.",
        "Option3": "Scale vertically by resizing the EC2 instances.",
        "Option4": "Create an Amazon CloudFront distribution to cache the static content.",
        "Option5": "Store the application's static content in Amazon S3.",
        "Correct Answer": 4
    },
    "Question68": {
      "Question": "An online food company provides an Amazon API Gateway HTTP API to receive orders for partners. The API is integrated with an AWS Lambda function. The Lambda function stores the orders in an Amazon DynamoDB table. <br>The company expects to onboard additional partners. Some of the partners require additional Lambda functions to receive orders. The company has created an Amazon S3 bucket. The company needs to store all orders and updates in the S3 bucket for future analysis. <br>How can the developer ensure that all orders and updates are stored to Amazon S3 with the LEAST development effort?",
      "Option1": "Create a new Lambda function and a new API Gateway API endpoint. Configure the new Lambda function to write to the S3 bucket. Modify the original Lambda function to post updates to the new API endpoint.",
      "Option2": "Use Amazon Kinesis Data Streams to create a new data stream. Modify the Lambda function to publish orders to the data stream. Configure the data stream to write to the S3 bucket.",
      "Option3": "Enable DynamoDB Streams on the DynamoDB table. Create a new Lambda function. Associate the stream's Amazon Resource Name (ARN) with the Lambda function. Configure the Lambda function to write to the S3 bucket as records appear in the table's stream.",
      "Option4": "Modify the Lambda function to publish to a new Amazon Simple Notification Service (Amazon SNS) topic as the Lambda function receives orders. Subscribe a new Lambda function to the topic. Configure the new Lambda function to write to the S3 bucket as updates come through the topic.",
      "Correct Answer": 3
    },
    "Question69": {
      "Question": "A developer wants to add request validation to a production environment Amazon API Gateway API. The developer needs to test the changes before the API is deployed to the production environment. For the test, the developer will send test requests to the API through a testing tool. Which solution will meet these requirements with the LEAST operational overhead?",
      "Option1": "Export the existing API to an OpenAPI file. Create a new API. Import the OpenAPI file. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.",
      "Option2": "Modify the existing API to add request validation. Deploy the updated API to a new API Gateway stage. Perform the tests. Deploy the updated API to the API Gateway production stage.",
      "Option3": "Create a new API. Add the necessary resources and methods, including new request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production",
      "Option4": "Clone the existing API. Modify the new API to add request validation. Perform the tests. Modify the existing API to add request validation. Deploy the existing API to production.",
      "Correct Answer": 2
    },
    "Question70": {
      "Question": "A company has an application that uses AWS CodePipeline to automate its continuous integration and continuous delivery (CI/CD) workflow. The application uses AWS CodeCommit for version control. A developer who was working on one of the tasks did not pull the most recent changes from the main branch. A week later, the developer noticed merge conflicts. <br>How can the developer resolve the merge conflicts in the developer's branch with the LEAST development effort?",
      "Option1": "Clone the repository. Create a new branch. Update the branch with the changes.",
      "Option2": "Create a new branch. Apply the changes from the previous branch.",
      "Option3": "Use the Commit Visualizer view to compare the commits when a feature was added. Fix the merge conflicts.",
      "Option4": "Stop the pull from the main branch to the feature branch. Rebase the feature branch from the main branch.",
      "Correct Answer": 4
    },
    "Question71": {
      "Question": "A developer is creating an application for a company. The application needs to read the file doc.txt that is placed in the root folder of an Amazon S3 bucket that is named DOC-EXAMPLE-BUCKET. The company's security team requires the principle of least privilege to be applied to the application's IAM policy. <br>Which IAM policy statement will meet these security requirements?",
      "Option1": "{<br>'Action': ['s3:GetObject'], <br>'Effect': 'Allow',<br>'Resource': 'arn:aws: 53:::DOC-EXAMPLE-BUCKET/doc.txt'<br>}",
      "Option2": "{<br>'Action': ['s3'], <br>'Effect': 'Allow',<br>'Resource': '*'<br>}",
      "Option3": "{<br>'Action':['s3:'], <br>'Effect': 'Allow', <br>'Resource': 'arn:aws: :::DOC-EXAMPLE-BUCKET/doc.txt' <br>}",
      "Option4": "{<br>'Action':['s3:'], <br> 'Effect': 'Allow', <br> 'Resource': 'arn:aws: s3:::DOC-EXAMPLE-BUCKET/*' <br>}",
      "Correct Answer": 1
    },
    "Question72": {
      "Question": "Users are reporting errors in an application. The application consists of several microservices that are deployed on Amazon Elastic Container Service (Amazon ECS) with AWS Fargate. <br>Which combination of steps should a developer take to fix the errors? (Choose two.)",
      "Option1": "Deploy AWS X-Ray as a sidecar container to the microservices. Update the task role policy to allow access to the X-Ray API.",
      "Option2": "Deploy AWS X-Ray as a daemonset to the Fargate cluster. Update the service role policy to allow access to the X-Ray API.",
      "Option3": "Instrument the application by using the AWS X-Ray SDK. Update the application to use the PutXrayTrace API call to communicate with the X-Ray API.",
      "Option4": "Instrument the application by using the AWS X-Ray SDK. Update the application to communicate with the X- Ray daemon.",
      "Option5": "Instrument the ECS task to send the stdout and stderr output to Amazon CloudWatch Logs. Update the task role policy to allow the cloudwatch:PullLogs action.",
      "Correct Answer": 4
    },
    "Question73": {
      "Question": "A company is developing a serverless multi-tier application on AWS. The company will build the serverless logic tier by using Amazon API Gateway and AWS Lambda. <br>While the company builds the logic tier, a developer who works on the frontend of the application must develop integration tests. The tests must cover both positive and negative scenarios, depending on success and error HTTP status codes. <br>Which solution will meet these requirements with the LEAST effort?",
      "Option1": "Set up a mock integration for API methods in API Gateway. In the integration request from Method Execution, add simple logic to return either a success or error based on HTTP status code. In the integration response, add messages that correspond to the HTTP status codes.",
      "Option2": "Create two mock integration resources for API methods in API Gateway. In the integration request, return a success HTTP status code for one resource and an error HTTP status code for the other resource. In the integration response, add messages that correspond to the HTTP status codes.",
      "Option3": "Create Lambda functions to perform tests. Add simple logic to return either success or error, based on the HTTP status codes. Build an API Gateway Lambda integration. Select appropriate Lambda functions that correspond to the HTTP status codes.",
      "Option4": "Create a Lambda function to perform tests. Add simple logic to return either success or error-based HTTP status codes. Create a mock integration in API Gateway. Select the Lambda function that corresponds to the HTTP status codes.",
      "Correct Answer": 1
    },
    "Question74": {
      "Question": "A developer is setting up a deployment pipeline. The pipeline includes an AWS CodeBuild build stage that requires access to a database to run integration tests. The developer is using a buildspec.yml file to configure the database connection. Company policy requires automatic rotation of all database credentials. <br>Which solution will handle the database credentials MOST securely?",
      "Option1": "Retrieve the credentials from variables that are hardcoded in the buildspec.yml file. Configure an AWS Lambda function to rotate the credentials.",
      "Option2": "Retrieve the credentials from an environment variable that is linked to a SecureString parameter in AWS Systems Manager Parameter Store. Configure Parameter Store for automatic rotation.",
      "Option3": "Retrieve the credentials from an environment variable that is linked to an AWS Secrets Manager secret. Configure Secrets Manager for automatic rotation.",
      "Option4": "Retrieve the credentials from an environment variable that contains the connection string in plaintext. Configure an Amazon EventBridge event to rotate the credentials.",
      "Correct Answer": 3
    },
    "Question75": {
      "Question": "A company created four AWS Lambda functions that connect to a relational database server that runs on an Amazon RDS instance. A security team requires the company to automatically change the database password every 30 days. <br>Which solution will meet these requirements MOST securely?",
      "Option1": "Store the database credentials in the environment variables of the Lambda function. Deploy the Lambda function with the new credentials every 30 days.",
      "Option2": "Store the database credentials in AWS Secrets Manager. Configure a 30-day rotation schedule for the credentials.",
      "Option3": "Store the database credentials in AWS Systems Manager Parameter Store secure strings. Configure a 30-day schedule for the secure strings.",
      "Option4": "Store the database credentials in an Amazon S3 bucket that uses server-side encryption with customer- provided encryption keys (SSE-C). Configure a 30-day key rotation schedule for the customer key.",
      "Correct Answer": 1
    }
  }
}
